%!TEX root = ../PhDthesis.tex

\acused{SNR}

\chapter{Discussion}
\label{ch:discussion}

In this thesis, we have applied information theoretic techniques to study the activity of populations of neurons within visual cortices \ac{V1} and \ac{V4}.
Here, we summarise and discuss our findings, and propose future research directions.


\section{Perceptual learning}

\subsection{Summary}

In \autoref{ch:pl}, we investigated the neural correlates of a perceptual learning task in which monkeys had to discriminate between stimuli of varying contrast.
Together, our results show the most informative signal about the contrast of the stimulus within the cortex is contained in the initial response to the stimulus onset within \ac{V1}, and this does not rise with training.
The lack of increase in this information may be because it is not a trainable property of the adult visual system.

The population activity in \ac{V4} rises with training, in line with the rise in behavioural performance of the subject.
This indicates that \ac{V4} is trained to be better at reading out the information in \ac{V1} relevant to the task, and information from \ac{V4} may subsequently be read out by higher-order cortices involved in decision making.
If the higher cortex must read information from \ac{V4} without direct access to \ac{V1}, this presents an information bottleneck, since \ac{V4} contains fewer neurons than \ac{V1}.
Our results also indicate that feedback signals from higher cortical regions into both \ac{V1} and \ac{V4} become more pronounced with training.


\subsection{Open directions for future research}

We identified the narrow beginning of the \ac{V1} stimulus-onset response as the most informative cortical signal conveying information about the contrast of the stimulus, and concluded this was perhaps because the latency of the signal reaching the cortex was sensitive to the contrast of the stimulus presented \citep{Albrecht2002}.
Consequently, it would be useful to investigate the amount of information encoded in the latency of the first spike in response to the stimulus onset.
This would help us determine whether the latency of the signal to \ac{V1} is truly the most informative aspect of the response, and not the total number of spikes in the onset-response.
That said, the spontaneous firing rate before the stimulus is around \SI{7}{Hz} (shown in \autoref{fig:fr_hm}), which implies a spontaneously generated spike will occur in the first \SI{50}{\milli\second} around $35\%$ of the time.
With this in mind, the time of the second spike after stimulus onset may prove even more informative.

Typical spontaneous firing rates for pyramid neurons in \ac{L2/3} are around \SI{0.03}{Hz} \citep{Lutcke2015}.
Consequently, the spontaneous firing rate of \SI{7}{Hz} which we report for our recording channels may be erroneously high, considering our \ac{MUA} contains spikes from around \num{5} neurons neighbouring the site of the recording contact.
% http://neuroelectro.org/ephys_prop/18/
That said, other neuronal cell types within \ac{V1} such as stellate cells \citep{Iurilli2012,Iurilli2013} and even pyramid neurons in other layers \citep{Manns2004,Dani2005,Maffei2006,Hromadka2008}, do have higher rates of spontaneous activity, typically around \SIrange{0.5}{3}{Hz}, and the distribution of spontaneous firing rates is approximately lognormal \citep{Mizuseki2017}.
Furthermore, fast-spiking basket neurons \citep{Chadderton2009} and various types of interneurons \citep{Hanganu2009,Lutcke2015} can have even higher spontaneous firing rates of around \SI{8}{Hz}.%
\footnote{Many interneurons have their activity suppressed instead of enhanced by stimulation, hence their high spontaneous firing rate.}
% \citep{Baddeley1997,Seki2003} \cite{Barral2016}
However, pyramidal neurons are the most common neuronal cell type within the cortical microcircuit, constituting around \SI{60}{\percent} by cell count within \ac{V1} \citep{Binzegger2004}, and \ac{L2/3} pyramids the most common of these.
Consequently, it is possible that our spike detection thresholds are too low, yielding an erroneously high spontaneously firing rate, and this could be re-evaluated.

As described in \autoref{sec:pl_san}, spike extraction thresholds were first selected manually for each session, and then a single session was selected to define a target spontaneous activity rate for each recording channel.
Then, for each session, we determined the threshold (for each channel) which would yield the same spontaneous activity as the target.
This technique provides greater consistency in the firing rate across recording sessions, which would otherwise vary greatly session to session.
However, due to a decline in recording quality over time, as evidenced by our sensitivity analysis in \autoref{sec:pl_dprime}, the firing rate which we extracted during stimulus presentation periods consistently declined over the course of the experiment for \ac{V1} recordings, as shown in \autoref{fig:fr_hm}.
For \ac{V4}, this decline is not observed, either because these recordings (which were completed sooner after the electrode array was implanted than the \ac{V1} recordings) had a more consistent recording quality, or because an increase in selectivity of the cortical response outweighed a decline in recording signal.

Another potential side-effect of the spontaneous activity normalisation is a change in the set of neurons which are included in the measured \ac{MUA} over the course of the experiment.
As the \ac{SNR} falls, the spike extraction threshold rises relative to the measured voltage of spiking events.
Consequently, more distal neurons which had signals strong enough to be recorded at the start of the experiment may no longer exceed the detection threshold in later experimental sessions.

Some, but not all, of these issues could be alleviated through a different choice of extraction threshold.
For instance, we could select one of the final recording sessions, with the lowest instead of an intermediate \ac{SNR}, to define the spontaneous activity rate.
From this, the threshold should be high enough to eliminate the incorrect detection of background noise as spiking activity throughout all sessions, and more distal neurons which could not be recorded at end of the experiment may be removed from all sessions.
Essentially, the amount of signal extracted would be capped at the worst level throughout all sessions, yielding consistency through forced degradation.
Alternatively, these issues could be addressed by using a more sophisticated action potential extraction procedure.
If we applied cell sorting techniques, we could remove noise-derived events falsely detected as spikes based on their (lack of) spiking waveform.
In the ideal scenario, we would cross-reference the spike waveforms between sessions and restrict our analysis to only consider the neurons which could be consistently detected and isolated throughout the experiment.
Unfortunately, any small movement of the recording apparatus will change the set of neurons neighbouring the electrode contacts from which recordings are taken; as such it is impossible to guarantee that the same neurons are recorded from over multiple days, even if their action potential waveforms are similar.

We used a Fisher linear discriminant classifier to decode information in the population activity, and alternatives to this could be explored.
Linear models, such as linear regression or support vector machines would likely give similar performance to the Fisher linear discriminant which we employed.
Non-linear models such as a multi-layered perceptron neural network may be able to capture information in the population activity which was lost when we made the assumption of monotonic tuning curves, however the difference in effect which would result is not likely to be very large.
If using a non-linear model to decode the activity does increase the performance, this would show that non-linearities in the tuning curves are much more important than we currently believe.

In our study, we trained the classifier on trials originating during an individual session, and evaluated it against the performance from held out trials from the same session.
Consequently, it is possible for the model which we construct to deviate between sessions --- if the structure of the population activity changes over time the classifier built for the final session might be quite different from the classifier trained on the data from the first session.
Allowing the model built by the classifier to change over time corresponds with the implicit assumption that the higher-cortical areas can, at will, change the mapping they employ to decode the results of lower-cortical areas.
Instead, we could consider the implications of a fixed mapping from low to high cortical regions, for instance by training a decoder on data from the initial sessions, then fixing the decoder when evaluating the amount of information present in the later sessions.
If there is little difference in performance between the two methods, this would suggest that the cortical region under consideration is directed to improve its encoding of the data by higher cortical regions, or is under the constraint of a certain decoding model employed by higher-cortical regions.

Instead of training a decoder to classify the stimulus and investigating the agreement between the output of this classifier and the behavioural response, we could train a decoder to predict the behavioural response directly.
Such a procedure would be similar to that used for a brain-machine interface.
This would be useful because there could be information in the population activity pertaining to the behavioural response which we are not currently seeing due to the decoder ignoring this information.
Such a scenario is quite plausible, since the decoder is not directly trained to optimise the amount of information about the behavioural response.

The decoder-based population analysis from \autoref{sec:dec-meth-lin} and \autoref{sec:pl_agreement} could also be applied to the population activity collected over shorter windows, such as the few tens of milliseconds surrounding stimulus onset response.
In doing so, we could repeat the results of our information latency breakdown from \autoref{sec:pl_info_latency}, but for the information encoded in the population activity instead of the average information encoded by individual channels.
The final outcome of this would be a heatmap similar to \autoref{fig:info_offset_vs_winlen_dif} showing when the population activity becomes more or less informative over time.
However, we anticipate that the results would be similar to the ones we already have, just with a larger effect size (since the population is more informative than any individual channel) and without statistics (since we have many channels but only one neural population), and would not yield any more insight into the neural changes relating to perceptual learning.

Similarly, we could apply the population activity decoder to the activity during the stimulus-off period, as we performed in \autoref{sec:pl_poststim_info} for individual channels.
Again, we expect this would corroborate the results we have already reported.
But since the effect size for post-stimulus information about the stimulus contained in individual channels was low, it would be useful to repeat this analysis using the population activity.
This section of the analysis could also benefit from computing the conditional mutual information between the neural activity and the behavioural response, conditioned on the true stimulus group.

We could compute the redundancy between pairs of channels for the information they encode about the stimulus, and see how the redundancy changes with training.
The methodology would be similar to that used in later chapters to analyse the redundancy between different \ac{CSD} frequencies across the cortical depth (in \autoref{sec:lam_redundancy}, for instance).
This would have to be reported with care, since the absolute amount of information encoded in the channels changes (typically increasing, but not always) with training.
For instance, if the information encoded in each channel increases and some of the increase is the same information for each channel, this will cause the redundancy to rise.
Consequently, it may be more interesting to consider the relative redundancy, normalised against the total information encoded in one or both of the channels, instead.
Measuring the pairwise redundancy and how it changes with training would help us understand how changes in the noise structure relate to changes in the information content.
We already found that shuffling the responses over trials gave a similar increase in performance of the decoder throughout training, suggesting that the redundancy at the population level remains the same.
However the pairwise redundancy could decrease (or increase) from changes in the pairwise correlation structure even while the population-level redundancy is unchanged.

In this study, we only have data from two individuals.
To be more confident in our conclusions, it would be useful to collect and analyse the neural correlates of perceptual learning for more subjects, especially since the measured effect size differed between our two subjects.
It would be particularly beneficial if we could record from \ac{V1} and \ac{V4} simultaneously, from neurons with the same \ac{RF} location in each brain region.
With such a dataset, we could test our hypothesis about \ac{V4} reading out information from \ac{V1}.


\section{Laminar distribution of information}

\subsection{Summary}

In Chapters \ref{ch:lam} and \ref{ch:plam}, we investigated the distribution, over cortical depth and frequency, of visual information encoded in the power and phase of cortical oscillations of the \ac{CSD} in \ac{V1}.
Our results show there are two independent frequency bands, \SIrange{4}{16}{Hz} and \SIrange{60}{170}{Hz}, whose power encodes information about the visual stimulus.
The \SIrange{4}{16}{Hz} power is most informative in \ac{G} and \ac{IG}, and its phase is also informative.
These encode information about scene cuts and other fast and coarse changes in the stimulus.
The \SIrange{60}{170}{Hz} power is redundant with the \ac{MUA}, both of which encode information about higher spatial frequency components of the stimulus, complementary to that encoded in \SIrange{4}{16}{Hz}.

In \autoref{sec:lam_discussion}, we speculated that these signals could correspond to the M- and P-pathways of visual information which originate in the retina, since these pathways are known to contain information about similar spatiotemporal frequencies.
Alternatively, these frequency ranges could correspond to the feedforward output of \ac{V1} (for the \SIrange{60}{170}{Hz} band) and a feedback signal from higher visual cortices including \ac{V4} (for the \SIrange{4}{16}{Hz} band), which would corroborate related research \citep{VanKerkoerle2014}.

In \autoref{ch:plam}, we discovered that different information about the stimulus was encoded in the \SIrange{4}{16}{Hz} phase for laminae below and above the layer 4/5 boundary.
Furthermore, the phase of the oscillations either side of this division was not synchronised (but was well phase-locked for laminae within a single compartment).
The most likely explanation for this is two independently generated \SIrange{4}{16}{Hz} oscillations.
This opens up the possibility of an additional frequency band at the same frequency, one encoding feedback from \ac{V4} and another encoding a feedforward signal from \ac{LGN}, corresponding to the M-pathway.


\subsection{Open directions for future research}

Firstly, multi-unit spiking activity has frequency components extending into the high-gamma range at around \SI{100}{Hz} \citep{Einevoll2013}.
In addition to this, recent work by \citet{Zanos2011} has indicated that low-frequency components of the sharp changes in voltage in the broadband signal which associated with spikes are retained in \ac{LFP} extracted from the broadband signal.
As a consequence, there are spurious correlations between the \ac{LFP} and \ac{MUA}.
These spurious correlations may impact our results, and it would be prudent to remove the waveforms of the spikes from the broadband signal before extracting the power of \ac{LFP} and \ac{CSD} oscillations \citep{Zanos2011} and confirm that the information about the stimulus in the \SIrange{60}{170}{Hz} power is still redundant with that of the \ac{MUA}.

We determined the \ac{CSD} from the \ac{LFP} using the inverse \ac{CSD} method (iCSD; \citealp{Pettersen2006}).
However, the authors have since detailed a more advanced procedure for estimating the \ac{CSD} from \acp{LFP}.
This, the kernel \acl{CSD} method (kCSD; \citealp{Potworowski2012}), is non-parametric and uses Gaussian kernels with regularisation to estimate the ground truth \ac{CSD}.
In particular, kCSD provides a native handling for unevenly spaced signal samples, which is useful since we had a small number of faulty electrode contacts, leaving holes in our sampling grid.
Re-extracting the \ac{CSD} using kCSD would be more accurate, but is unlikely to perturb our results by a large amount.

When discussing the results for information encoded in the power of cortical oscillations, we speculated that the power of the \SIrange{60}{170}{Hz} range may encode the output of the cortical column.
Typically, neurons in \ac{V1} are tuned to respond to the movement of oriented bars with specific properties, such as orientation, spatial frequency, direction of motion, and colour.
We could test this hypothesis by computing the spatiotemporal receptive field of the power of cortical oscillations by reverse correlating it with the movie frames \citep{Theunissen2001}.
If the spatiotemporal receptive field corresponds to such a stimulus, and in particular if it is similar to that of the \ac{MUA}, that would be evidence in support of the hypothesis.

When determining which spatiotemporal components of the stimulus corresponded to the changes in cortical power and phase, we focused on the rate of change of luminance.
However, we did not find information about any spatiotemporal scales present in the phase of oscillations.
Consequently, it would be prudent to widen our search and consider colour-opponent changes in the stimulus, as is provided to the visual cortex through the P-pathway and K-pathway.
One could even go so far as to model the transformations to the raw visual input performed by each of the \ac{RGC} types.
In doing so, we would simulate the full effects of processing in the retina and be able to investigate the structure of information in \ac{V1} with respect to its actual input.
However, such an undertaking would be quite significant, since our understanding of the computational processing within the retina remains incomplete and is actively researched.

We hypothesised that the phase of multiple cortical frequency components encoded synergistic information about the stimulus because scene changes induce stereotypical, transient waveforms and pairs of phase enable the determination of maxima and minima in such shapes.
To investigate this hypothesis further, there are several directions we could consider.
Firstly, we filtered signal using an \ac{IIR} Butterworth filter before using the Hilbert transform to determine the instantaneous power and phase.
Since such events are temporally isolated, it would be more prudent to use a \ac{FIR} filter instead, so that transient waveforms remain isolated and do not have effects on the reported power and phase across all time, into both the past and future.
Alternatively, we could use a wavelet transform to decompose the \ac{CSD} signal into frequency components each considering isolated temporal periods.
Secondly, we could use the characteristic shape of the stimulus-onset response to search for similar events throughout the stimulus presentation.
From this, we can investigate how such waveforms relate to scene changes and other aspects of the visual stimulus.

% what do oscillations at other depths encode

For this project, we principally investigated the population activity by considering the \ac{LFP} and \ac{CSD}.
However, the process through which each of the different types of neuron within \ac{V1} manifest \acp{CSD} and how each frequency component in the signal is generated is not yet well understood.
Compartmental models of the morphology of cortical neurons can be used to fill in such gaps of understanding \citep{Leski2013}.
If we were to reconstruct the morphology of each cell type within \ac{V1} and derive the \ac{CSD} generated by each, we would be much better equipped to understand which neurons generate the information-encoding oscillations which we have described and localised in this thesis.
