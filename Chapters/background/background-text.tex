%!TEX root = ../../ClassicThesis.tex

%------------------------------------------------------------------------------
\section{Information Theory, and its applications within Neuroscience}
\label{sec:bgit}

A common experimental methodology used in neuroscience is to record the extracellular activity of individual neurons under different conditions.
From this, we can compare the activity of the neuron under different conditions to examine whether it is dependent on this set of conditions, and if so investigate the nature of the relationship between the two.

Frequently, the approach used is to take many recordings of the same neuron for the same condition, and then take the average across these repetitions (``trials'') to reduce the effects of neuronal variability, producing a \ac{PSTH}, for instance.
This neuronal variability is often referred to as ``noise'', however it is debatable as to whether differences in the behaviour of individual neurons between trials are due to noise within the system or are in fact representative of changes in other, as-yet unknown, hidden or latent variables within the system (see \autoref{sec:bg-noisecorr} for further discussion).

Such a simple treatment of the data --- averaging over the response over repetitions --- is fundamentally flawed, since this is not the manner in which brains process stimuli.
At any moment in time, the brain has access to the activity of many neurons simultaneously (not a single neuron in isolation), but only has a single sample of each one (not multiple instantiations of the same neuron).

If we instead use information theory to study the neuronal activity, we can consider how much information there is across a system containing multiple neurons during an isolated period of time, for instance a single trial.
By using an information theoretic technique, we can overcome the limitations of the more simple methods; but no method is perfect and there are other limitations which arise when using information theory instead.
% CITE no free lunch theorem
In this section, I will first outline the analytic procedure through which information theoretic analysis is applied to neuroscientific data, some of the problems which arise, and how to try to overcome them.


\subsection{Neuroscientific context}

In the context of trying to experimentally investigate properties of the sensory cortex of the brain, one typically uses an experimental set-up with a finite collection of discrete experimental stimuli.
These stimuli are then repeatedly presented to the sensory organ in an appropriate fashion, and the responses during each presentation are recorded.

% Can cut the Fisher information, since it isn't actually information theoretic
Even when investigating the responses to stimulus features which vary continuously, such as line orientation for the visual stimulation and frequency for auditory stimulation, one has two options.
Firstly, the features can be preserved in a continuous space and the information about the stimulus estimated using Fisher information. The inverse of the Fisher information provides a lower bound on the mean squared error which any decoder can achieve \citep{Quiroga2009}.
Alternatively, the stimulus space can be discretized into a finite subset of stimuli from which we can draw samples with repetition.
Once the samples are discretized and presented repeatedly, we can use Shannon information to compute the amount of information about the stimulus identity contained in the neuronal response.
If the stimulus set is intrinsically discrete, Fisher information can not be used and an information theoretic analysis can only be performed using Shannon information.

For such an experimental set-up, let us assume that on each trial the stimulus $s$ is selected at random with probability $p(s)$ from a set of discrete stimuli $\SET{S}$, containing $S$ unique stimuli.
The neuronal response could be one (or more than one) of several data types, such as a spike train from one or more neurons, the \ac{LFP}, \ac{CSD}, \ac{BOLD} signal, a calcium indicator, \ac{EEG}, or others \citep{Magri2009,Quiroga2009}.
The principles of information theory can be applied whichever neural signal is taken to be the response.
In \autoref{ch:pl}, we will work with information encoded in \ac{MUA} and spike trains, whilst in Chapters~\ref{ch:lam} and \ref{ch:plam} we will be considering the \ac{LFP} and \ac{CSD}.

With regards to the analysis of sensory recordings (with which this thesis will be concerned), the different conditions used on the trial are typically different stimuli, and the extracellular recordings provide us with the neuron's response to the stimuli.
When applying information theory to neuronal data, we treat the brain as a communication channel, transmitting information about sensory input.
We are hence interested in how much information the response in the brain contains about which stimulus was presented to it.

However, it should be noted that we frame the problem in the context of a \textit{communication channel} simply because this is the framework around which Shannon information is formulated \citep{mackay2003information}.
Within information theory, systems are modelled with information passing between a transmitter and receiver through a communication channel.
The message passing between them in modified as it passes through the channel, and the receiver must attempt to decipher which message was originally sent.

In some ways, some functions of the brain are similar to the process of a compression algorithm.
The initial encoding of the stimulus as transcribed by the appropriate sensory organ contains a large amount of information about the precise input stimulus --- for example the individual pixel values with an image stimulus --- which has a large amount of redundancy if one is interested only in detecting, classifying, and reacting to stimuli.
A binary image of only $17 \times 17$ pixels can express \num{9.9e86} different states --- around a million times more than there are atoms in the visible universe, thought to be around \num{1e80}.
However the vast majority of these images (for this, or equally true for a larger image with more intensity levels and colours) resemble unstructured random noise.
The set of images which are of interest for interacting with a real world environment is vastly smaller, and with an appropriate high-level statistical model of the appropriate subset of the class of all potential stimuli can be compressed down to a much smaller number of bytes.
For instance, whether a given visual stimulus contains the face of familiar person.

After a stimulus has been processed by the brain, information about the exact intensities of individual pixels is lost, but salient information about the environment is preserved.
We can hence investigate how stimuli are encoded within the brain by computing the amount of information about properties of the stimulus contained within the neural recordings.
Here, we make the following assumption: if the neuronal activity is observed to contain information about the stimulus, we can assume this information is present due to the manner within which information is encoded by the brain, and that this information can be drawn upon to inform decisions taken with regard to the stimulus.
We rationalise this assumption on the basis that we know the brain contains information about stimuli (otherwise it would be functionally blind/deaf), and it would be wasteful expend resources encoding stimuli accurately but in a non-functional manner.

The neural data which can be collected with modern experimental equipment is very dense and rich in content.
For instance, individual spikes can be recorded with the precision of fraction of a millisecond, and broadband \acp{LFP} allow for many frequency components to be analysed from the same recording.
Typically, it is not possible to compute the information about the stimulus contained in the entire data stream all at once.
The reason for this is the relatively small number of trials which can be collected for any given dataset.

% Mark dislikes this paragraph I guess?
The repetitions of presenting the same stimulus and recording the neural response must be performed with the experimental setup the same, and recording taken from the same neurons.
However, there is a maximum duration for any \invivo{} experiment of a few hours, after which the experimenters and subjects will be fatigued.
This, naturally, leads to a maximum number of repetitions of an experimental protocol which can be completed within this timeframe, and that is in the order of 100.
Should more trials be undertaken in a different experimental session, there is no guarantee that the neurons recorded from will be the same, so the response structure may be different and can't be combined with that of the prior session.

Using information theory, we can investigate the nature of the neural code used by individual neurons and populations of neurons \citep{Optican1987}.
For example, if our dataset consists of recordings of neuronal spiking activity, we can consider the amount of information contained in the spike train coincident with a \SI{40}{\milli\second} stimulus, say.
First, we can consider our response vector to be the total number of spikes over the \SI{40}{\milli\second} window and compute the information contained in these about the identity of the presented stimulus.
Second, we can consider our response vector to be the number of spikes in each quarter of the stimulus presentation period (four \SI{10}{\milli\second} windows).
This step could equally be performed with more windows of finer granularity, so in general we would have a response vector $r = [r_1, \ldots, r_L]$, with $L$ windows each of length $\nicefrac{T}{L}$ and $r_i$ the number of spikes during the $i$-th window\footnote{In our example, $T = \SI{40}{\milli\second}$.}.
Since the information contained in single \SI{40}{\milli\second} window approach is, by construction, contained in the vector of responses within the shorter windows, we can investigate amount of information contained within the timing of the spikes.
If there is no significant difference between the amount of information about the stimulus contained in the two vectors, it seems reasonable to conclude that the stimulus, or some attributes which distinguish it, are encoded in the firing rate, whilst the exact timing of the spikes is unimportant.

% Typically \citep{Quiroga2009,Brasselet2012,Panzeri2007,Arabzadeh2006,Strong1998}, a certain post-stimulus time window of duration $t$ in \SIrange{20}{40}{\milli\second} is chosen and a neural code is constructed which forms a discrete, multi-dimensional array $r = \{r_1, \ldots, r_L\}$ of dimension $L$, because a discrete response of this form is appropriate for performing an information theoretic analysis on.
% To look at the information given by the firing rate of a single neuron, we might use a spike-count code where $L=1$ and $r$ is equal to the number of spikes elicited in the window $t$.
% Similarly, to look at the information contained in the firing rate of a many neurons, we would use a spike-count code where $r_i$ is equal to the number of spikes elicited in the window $t$ for spike train of the \nth{i} neuron, and let $L$ equal the number of neurons to be studied.
% In comparison, to look at the information contained in the millisecond level spike timing of a single neurons, we would divide the time window into $L$ bins of length $\Delta t = \nicefrac{t}{L}$ such that $\Delta t$ is the assumed time precision of the code, and set $r_i$ to be the number of spikes elicited in \nth{i} time-bin.

In general, we will choose some framework through which the raw data is reduced to a manageable finite ensemble of possible states, $\SET{R}$.
Having constrained both our encoding of the stimulus and the response to a finite set of states, we can investigate the relationship between them using Shannon information \citep{Shannon1948}.


\subsection{Theoretical background to information theory}

Within the understanding of Shannon information, information is quantified in a manner analogous to how ``surprised'' a receiver would be if they were to reveal the contents of a message sent by the transmitter.
Unless there is only one possible message, there is uncertainty over what will be sent, potentially with some messages more likely than others.
If an \textit{a priori} likely message is received, this confirms the expectations so the receiver, so they are less ``surprised''.
If an unlikely message is received, the receiver is more ``surprised''.
Intuitively, the amount of information gained on receipt of the message is related to how much the uncertainty in the message was reduced upon its arrival.

Rigorously, we define the \textbf{Shannon information} content of an outcome or result $x$ to be
\begin{equation}
\label{eq:shannon-information}
\operatorname{h}( x ) = \log_2 \frac{1}{p(x)}
.\end{equation}
This corresponds to how ``surprised'' we would be to observe the result $x$ being produced by the system in question.
Note that $h(x)=0$ if $p(x)=1$ (if an event is certain, we are never surprised and gain no information observing it), and $h(x) \to \infty$ as $p(x) \to 0^+$ (we gain more information --- we are increasingly surprised --- when a diminishingly unlikely event occurs).

The \textbf{entropy} of a system is a measure of amount of uncertainty we have about its state.
We define this as the expected amount of information we will gain when we observe it,
\begin{align}
\HH( \SET{X} )
  &= \EE_{x \in \SET{X}} \left[ \log_2 \frac{1}{p(x)} \right] \notag
\\&= \sum_{x \in \SET{X}} p(x) \log_2 \frac{1}{p(x)} \notag
\\&= - \sum_{x \in \SET{X}} p(x) \log_2 p(x)
,\end{align}
where $\SET{X}$ is the ensemble of possible states of the system in question.

When studying neural recordings using information theory, we will need to take note of the uncertainty in which stimulus is presented, $\HH(\SET{S})$, and the uncertainty in the response, $\HH(\SET{R})$.
In particular, the amount of information about the stimulus contained in the response is their \textbf{mutual information}, $\I(\SET{S};\SET{R})$.
This is the amount by which our uncertainty in the stimulus is reduced when we discover the value of the response to that stimulus, which is equivalent to the amount by which our uncertainty in the response decreases when we discover the identity of the stimulus
\begin{align}
\I(\SET{X};\SET{Y})
  &= \EE_{x \in \SET{X}, \, y \in \SET{Y}} \left[ \log_2 \frac{p(x,y)}{p(x)p(y)} \right] \notag
\\&= \sum_{x \in \SET{X}, \, y \in \SET{Y}} p(x,y) \, \log_2 \frac{p(x,y)}{p(x)p(y)} \notag
\\&= \HH(\SET{X}) - \HH(\SET{X} | \SET{Y}) \notag
\\&= \HH(\SET{Y}) - \HH(\SET{Y} | \SET{X}) \label{eq:info}
.\end{align}
Here, we make use of the conditional entropy (also known as noise entropy), so named because it is the entropy of one variable when conditioned on the state of another.
Analogously to \autoref{eq:shannon-information}, this is defined as
\begin{align}
\HH(\SET{X} | \SET{Y})
  &= \EE_{x \in \SET{X}, \, y \in \SET{Y}} \left[ \log_2 \frac{1}{p(x|y)} \right] \notag
\\&= \sum_{x \in \SET{X}, \, y \in \SET{Y}} p(x,y) \log_2 \frac{1}{p(x|y)} \notag
\\&= \sum_{y \in \SET{Y}} p(y) \sum_{x \in \SET{X}} p(x|y) \log_2 \frac{1}{p(x|y)} \notag
\\&= - \sum_{y \in \SET{Y}} p(y) \sum_{x \in \SET{X}} p(x|y) \log_2 p(x|y)
.\end{align}
% The mutual information is zero if and only if responses are completely independent of stimuli.
% For brevity, we will refer to {mutual information} to as \textbf{information} in the remainder of this thesis.
The Venn diagram relating the entropies of $\SET{X}$ and $\SET{Y}$, to their joint entropy, conditional entropies, and mutual information shown in \autoref{fig:bg_info_venn} may assist the reader in conceptualising the relationship between these terms.

\begin{figure}[htbp]
\centering
\includegraphics[scale=.5]{Entropy-mutual-information-relative-entropy-relation-diagram.pdf}
\caption{
\textit{Venn diagram of mutual information between $\SET{X}$ and $\SET{Y}$.}
The two black circles represent the entropies of $\SET{X}$ and $\SET{Y}$, $\HH(\SET{X})$ and $\HH(\SET{Y})$, and their total area (outlined in green) is the total joint uncertainty, $\HH(\SET{X}, \SET{Y})$.
In the scenario depicted, $\HH(\SET{X})$ and $\HH(\SET{Y})$ are partially but incompletely redundant.
Consequently, the uncertainty of $X$ is reduced (but not expected to be zero) when $Y$ is known: the conditional entropy $\HH(\SET{X}|\SET{Y})$ (red region) is smaller than $\HH(\SET{X})$, but is not empty.
The amount by which our expected uncertainty in $X$ is reduced, $\HH(\SET{X}) - \HH(\SET{X}|\SET{Y})$, is equivalent to the mutual information between $\SET{X}$ and $\SET{Y}$, denoted $\I(\SET{X};\SET{Y})$ and represented by the purple region.
We can reason similarly about the other conditional entropy, $\HH(\SET{Y}|\SET{X})$ (blue region).
% Reproduced (with modifications) from \href{https://commons.wikimedia.org/wiki/File:Entropy-mutual-information-relative-entropy-relation-diagram.svg}{Wikimedia Commons} (public domain).
}
\label{fig:bg_info_venn}
\end{figure}


\subsection{Applying information theory in practice}

Computing the mutual information between stimulus and response requires us to estimate $p(s)$, $p(r)$, and either $p(s|r)$ or $p(r|s)$.
The requirement to know $p(s)$ renders applying mutual information outside of a controlled environment all-but impossible.
If the subject is free moving, a prior over the set of potential stimuli it could be exposed to is very challenging to define.
However, within an experimental setting we can control the stimulus presentation such that there is only a finite set of unique stimuli, and the probability of each of them, $p(s)$, is defined by our experimental protocol.
In practice, $p(r|s)$ is much easier to derive than $p(s|r)$, and so we estimate $p(r)$ and $p(r|s)$.
As mentioned earlier, we must repeatedly present each stimulus so it is possible to estimate the response distribution $p(r|s)$ for each stimulus condition.

However, estimating these probabilities from the data can cause problems with our estimated mutual information.
Since we have only a finite number of samples, there will inevitably be inaccuracies in our probability estimates (the ``limited sampling'' problem).
Should we repeat the experiment, the natural variation in the samples we collect will result in statistical variance in our measured mutual information.
Moreover, the variation due to finite sampling may cause our response distributions to appear different for different stimuli, even when the underlying response generation process is the same for each stimulus.
Such problems produce an over-estimation bias in the computed mutual information compared with the ground truth.
For instance, if a particular response never occurs for given stimulus presentation, a na{\"i}ve frequentist estimate of its probability would be $0$.
This would lead us to mistakenly conclude that it is impossible a certain stimulus was presented if we observe this response, even though we could have observed this combination had we taken more samples.

Of even greater concern, the bias to the estimated mutual information can vary greatly depending on the choice of experiment or analysis framework.
One cannot draw comparisons between na{\"i}vely estimated mutual information values under different experimental criteria because the changes in the bias can completely dwarf the changes in the ground truth information value.
It is therefore necessary to estimate the bias on the na{\"i}ve mutual information value and make a correction to counteract it.


\subsection{Bias correction}
\label{sec:info-bias}

A number of techniques exist to correct for the bias in the mutual information estimation.
The simplest of these is to shuffle the data so that responses are paired with stimuli at random \citep{Optican1991}.
Unfortunately, this will often be a poor estimate of the bias \citep{Panzeri1996}, because there may be responses which never occur with certain stimuli.
Pairing stimuli and responses together at random inflates the set of unique responses to each stimulus above what is possible in practice, and as a consequence an estimate of the bias determined in this manner will be a pessimistic overestimate.

However, for a multi-dimensional response (where each stimulus presentation produces a response vector), shuffling provides an invaluable bias-correction technique.
Using the methodology of \citet{Montemurro2007}, we add an additional step to compute the noise entropy under the simplifying assumption that each dimension of $r$ is independent of the others.
Exploiting this, we have
\begin{equation}
P_\text{ind}([r_1,r_2,r_3,\cdots]|s) = p(r_1|s)\,p(r_2|s)\,p(r_3|s)\,\cdots
\end{equation}
and can can compute $\HH_\text{ind}( \SET{R} | \SET{S} )$ directly from estimates of each $p(r_i|s)$ derived from the data.
This has very little bias compared with $\HH( \SET{R} | \SET{S} )$ there are so many more samples --- the ratio of samples for unique response vectors to individual response elements rises exponentially with the dimension of the response vector.
One can alternatively estimate this entropy from pseudo-response arrays by shuffling each element in the response vector conditioned on the stimulus, producing $\HH_\text{sh}( \SET{R} | \SET{S} )$.
Since this shuffling destroys information contained in the dependencies between elements in the response vector, this is an estimate of the same entropy value as $\HH_\text{ind}( \SET{R} | \SET{S} )$.
Except the bias on $\HH_\text{sh}( \SET{R} | \SET{S} )$ will be similar to the bias of $\HH( \SET{R} | \SET{S} )$ because each computation uses the same number of samples.
Consequently, we can estimate the mutual information between $\SET{S}$ and $\SET{R}$ using
\begin{align}
\I_{\text{sh}}(\SET{S};\SET{R})
   &= \HH( \SET{R} ) - \left( \HH( \SET{R} | \SET{S} ) - \left( \HH_\text{sh}( \SET{R} | \SET{S} ) - \HH_\text{ind}( \SET{R} | \SET{S} ) \right) \right) \notag
\\ &= \HH( \SET{R} ) - \HH( \SET{R} | \SET{S} ) + \HH_\text{sh}( \SET{R} | \SET{S} ) - \HH_\text{ind}( \SET{R} | \SET{S} )
,\end{align}
which has a much smaller bias than $\I_{\text{uncorrected}}(\SET{S};\SET{R})$.

An alternative method to correct for the bias is to decompose the measured mutual information as a power series in terms of $\nicefrac{1}{N}$, where $N$ is the number of trials recorded.
The $\nicefrac{1}{N}$ coefficient in the expansion depends only on the number of stimuli and number of possible responses \citep{Miller1955,Treves1995}.
This dominant term is a good estimate of the bias, and subtracting it from our uncorrected information value greatly improves its accuracy \citep{Treves1995}.
This works for a single-dimensional or multi-dimensional response, and is more accurate than shuffling for a single-dimensional response \citep{Panzeri1996}.
However, this term is dependent on the on the total number of potential responses for each stimulus.
Since some stimuli may not be able to elicit every response, this is smaller than the number of theoretically possible responses.
However as described above, some responses may be possible to produce but unobserved in the limited set of samples.
Consequently, \ac{PT} bias-correction method of \citet{Panzeri1996} uses Bayesian statistics to estimate the actual number of potential responses.
This method was observed to be accurate provided there are at least 4 times as many repetitions of each stimulus as there are possible responses \citep{Panzeri2007}.

A second method of correcting the bias which uses a power series expansion is the \ac{QE} method of \citet{Strong1998}.
Here, the bias on the mutual information is assumed to be well approximated by a second order $\nicefrac{1}{N}$ expression,
\begin{equation}
\I_{\text{uncorrected}}(\SET{S};\SET{R}) =
\I_{\text{true}}(\SET{S};\SET{R}) + \frac{a}{N} + \frac{b}{N^2}
,\end{equation}
and the two free parameters, $a$ and $b$, are found by computing the information content with fractions of the full available dataset (\ie{} using $\nicefrac{N}{2}$ and $\nicefrac{N}{4}$ trials).
Since the two are built on the same assumptions, \ac{QE} gives similar performance to \ac{PT}, but with because it is computationally instead of analytically derived it requires more computational processing.

% Consider discussing Best Universal Bound (BUB) method (Paninski, 2003)

The \ac{NSB} entropy estimation method \citep{Nemenman2004} provides an alternative framework through which the bias can minimised.
This method begins with a uniform prior and uses Bayesian inference to update the probability distribution given each sample in turn.
The result has less residual bias than the \ac{PT} or \ac{QE} methods, but at higher computational cost \citep{Panzeri2007}.

Each of these bias correction methods make a trade off between variability and bias.
Introducing more terms in order to reduce the bias invariably increases variability, but this is a price worth paying since the uncorrected bias is so prominent in the results.
Unless indicated otherwise, we will be using the \ac{PT} bias correction method when computing mutual information with a single dimensional response, and $\I_{\text{sh}}$ with \ac{PT} when using multi-dimensional response vector.
In addition to this, we will repeat the mutual information calculation with shuffled stimulus-response pairing multiple times (typically 20 different shuffled pairings) with bias correction and use the average of the bootstraps to estimate the residual bias uncorrected by \ac{PT}.
The estimated residual bias is also removed from our reported mutual information between stimulus and response.


%------------------------------------------------------------------------------
\section{Neural Correlations}
\label{sec:bg-corr}

Since neurons do not operate in isolation and the neural code is distributed across many neurons, it is often important to consider how the behaviour of multiple neurons relate to one-another.
A simple way to do this is to measure the correlation between the outputs of pairs of neurons.

Although this is a much less nuanced technique than using Shannon information to study the relationship between the neurons, measuring the correlation provides us with a much easier to use metric.
In particular, the amount of data needed to measure the mutual information between stimulus and response increases exponentially in the dimensionality of the response.
This means it is impossible to compute the amount of information conveyed by in the response of more than a handful of neurons.


\subsection{Signal Correlations}
\label{sec:bg-sigcorr}

Some neurons behave similarly to each other in response to stimulation across a range of potential stimuli.
These neurons have correlated responses with respect to the input signal.

From an information theoretic perspective, neurons with high signal correlation have high redundancy.
Of course, a redundant neural code is useful as a method of error correction.
Neural responses to repeated stimuli have high-variance, indicating a large amount of noise in the system.
Repetition is an inefficient method of error correction though \citep[Chapter~1]{mackay2003information}, and neuroscientists do not typically interpret groups of neurons to be duplicated instantiations of the same function of the stimulus.

To compute signal correlation, typically one first takes the average response for each neuron in response to many presentations of the same stimulus.
This removes the effect of correlated noise, which we assume averages out to $0$ when we take the mean.
The signal correlation is then the Pearson correlation between the two neural responses, found by treating each unique stimulus as a sample of the underlying relationship between the two neurons.


\subsection{Noise Correlations}
\label{sec:bg-noisecorr}

When an individual is repeatedly presented with the same stimulus, a representation of the stimulus is formed within the brain of the individual.
One might expect that, should we eliminate variations in the environment such that an identical audio track is played without any background stimulus or a visual image is presented with the eyes held in place, the activity within the associated sensory cortex would be identical on each repetition of the stimulus presentation.

Whilst the information encoded across the whole population of neurons may indeed be the same, the activity of each individual neuron varies with each presentation of the stimulus.
Both the number of spikes evoked (or firing rate) and the timing of these spikes varies for each neuron. 

One can imagine the activity of each neuron fluctuating around a mean (though not with a Gaussian distribution).
Each neuron has a certain expected value for its activity in response to any stimulus which could be presented.
For classes of stimuli for which the neurons are tuned, such as gratings of different orientations or different contrasts, we can plot a tuning curve mapping the parameter space describing the stimuli to a particular response activity, specific to each neuron.

Noise correlations are observed when the responses to fixed stimuli co-vary for two neurons.
That is to say, positive noise correlations are found when two neurons tend to have higher-than-expected activity on the same trials as one another (and lower-than-expected on the same trials too).

Intuitively, one can see that such noise correlations between pairs of neurons can inhibit the accuracy with which the stimulus is encoded in their activities.
Suppose that two neurons both respond monotonically more to stimuli of higher contrast.
Knowing their tuning curves and their current activity, we can decode the contrast of the current stimulus with some level of accuracy.
If the two neurons are independent of one another, knowing the activity of both will give us a more accurate and more precise estimate of the actual contrast of the stimulus.
But if the activity between the pair of neurons is positively correlated, the information conveyed from the pair of neurons is reduced --- when one gives an overestimate of the contrast from a by-chance elevated activity level, so does the other.
In contrast, negative correlations would enhance our decoding accuracy, for an overestimate from one neuron would more frequently be mitigated by an underestimate from the other.

For a long period of time, neuroinformatians had argued that positive noise correlations are always detrimental to the encoding of stimuli.
However, more recent theoretical work has found that, when considering a non-homogeneous population of neurons --- a population where the tuning curve is not the same for each neuron --- positive noise correlations can in fact be beneficial to the encoding of information about the stimulus.

This can be envisioned by extending the 1-D mapping between a stimulus parameter and the activity of a single neuron to a 2-D plane of pairwise activity levels which is traversed as the stimulus parameter is adjusted.
For orientation tuning (where the angular parametrisation of the stimulus is cyclic), tracing out the expected activity of a pair of neurons in response to the stimulus class will result in a closed loop in the 2-D plane.
For other stimuli, which are non-cyclic, the trace is an open curve.

Deviations to the response of the pair of neurons which move in the direction of the curve is detrimental to stimulus decoding, whereas deviations which are tangential to the curve are beneficial (better even than independence).
Whether these directions correspond to positive or negative correlations depends on the direction of the line.
