%==============================================================================
\section{Sensitivity analysis}
\label{sec:pl_dprime}
%------------------------------------------------------------------------------

One simple method of comparing how the encoding of stimuli changes over time is to use the sensitivity index, $d'$.
This gives a measure of how separable the signal and the noise are, by comparing the difference in their means with the overall standard deviation.
As such, it is one of several methods to measure the \ac{SNR} of a communication channel.
% For a classifier, this is defined as the difference between the hit rate and the false alarm rate,
% \begin{equation}
% d' = P(A | A) - P(A | \bar{A})
% ,\end{equation}

For Gaussian distributed data, the sensitivity index is defined as
\begin{equation}
\label{eq:dprime}
d' = \frac{\mu_\text{stim} - \mu_\text{noise}}{\sigma_\text{joint}}
,\end{equation}
where the joint standard deviation is the root mean square of the standard deviation for each of two distributions,
\begin{equation}
% \sigma_\text{joint} = \sqrt
%     \frac{ (n_\text{stim}-1) \, \sigma_\text{stim}^2 + (n_\text{noise}-1) \, \sigma_\text{noise}^2 }
%     { n_\text{stim} + n_\text{noise} - 2}
\sigma_\text{joint} = \sqrt \frac{\sigma_\text{stim}^2 + \sigma_\text{noise}^2}{2}
.\end{equation}
For our analysis, the noise is the spiking activity during periods of spontaneous activity.
With the sample stimulus and \num{14} test stimuli with differing contrast levels, we have \num{15} possible signals to choose from for each dataset.
Since it has the most presentations and lies in the middle of the range of the contrasts, we will just consider $d'$ with respect to the response signal when presenting the sample stimulus.

The number of spikes over a finite duration, which cannot be negative, is typically Poisson distributed instead of Gaussian distributed.
However, the two distributions do converge for large $n$, and so we disregard this and use the Gaussian form of the definition of $d'$.

%------------------------------------------------------------------------------
\subsection{Methods for sensitivity analysis}
\label{sec:violin_plot_method}

To compute $d'$, we used the number of spikes occurring during a \SI{1050}{\milli\second} period of activity.
The spontaneous (noise) activity was defined as the number of spikes detected during the \SI{525}{\milli\second} immediately preceding the sample stimulus onset.
The signal activity was the number of spikes during the \SI{525}{\milli\second} immediately following the sample stimulus onset.
From this, $d'$ was computed using \autoref{eq:dprime}.

To investigate whether $d'$ changed significantly during the course of our experiments, we compared the average $d'$ during the first and final three experimental sessions (intervals which we denote \zonename{A} and \zonename{B}, respectively).
A paired $t$-test (two-tailed) was used to study whether $d'$ consistently increased or decreased for the channels.

The violin plots (see, for instance, the upper-right panel of \autoref{fig:dprime_v1_blanco}) show the Gaussian kernel density estimation of the distribution over channels of $d'$ before and after training (intervals \zonename{A} and \zonename{B}).
This bandwidth of the Gaussian kernel was determined using the rule of thumb bandwidth estimator,
\begin{equation}
h = \hat{\sigma} \left( \frac{4}{3 n} \right) ^ \frac{1}{5}
,\label{eq:estimate-bw}\end{equation}
where $n$ is the number of samples and $\hat{\sigma}$ is the estimated standard deviation for the population determined from these samples.
We applied the bandwidth estimator to the set of $d'$ averaged over the first three sessions of training, $\SET{\zonename{A}}$, and averaged over final three sessions, $\SET{\zonename{B}}$, to find $h_\zonename{A}$ and $h_\zonename{B}$.
In each plot, the same kernel bandwidth of
$H = \min(h_\zonename{A}, h_\zonename{B}) / 2$
is used when estimating the density at \zonename{A} and at \zonename{B}.
This ensures sufficient detail about the distribution is preserved for each, and the two are comparable with each other.

%------------------------------------------------------------------------------
\subsection{Results for sensitivity analysis}
\label{sec:pl_dprime_v4}

% blanco v1
% same bandwidth bw = 0.26027 used for all cols
% h=1.000000 p=0.021169=2.116899e-02 delta=-0.322850
% jack v1
% same bandwidth bw = 0.21865 used for all cols
% h=1.000000 p=0.000000=3.274440e-07 delta=-0.418598

% blanco v4
% same bandwidth bw = 0.17898 used for all cols
% h=0.000000 p=0.463346=4.633457e-01 delta=+0.052346
% jack v4
% same bandwidth bw = 0.064737 used for all cols
% h=1.000000 p=0.000000=6.946514e-08 delta=+0.491173

For \ac{V1}, we found $d'$ decreased with training (see \autoref{fig:dprime_v1}).
A similar result was observed for each subject.
The average change in the sensitivity index was $\Delta d' = -0.323$ ($p=0.02$, paired $t$-test) for \ac{M1} and $\Delta d' = -0.419$ ($p < 4 \times 10 ^{-7}$, paired $t$-test) for \ac{M2}.

\begin{figure}[htbp]
    \centering
    \hspace*{\fill}
    \subfloat[\ac{M1} \ac{V1}\label{fig:dprime_v1_blanco}]{
        \centering
        \includegraphics[scale=.45]{%
figs/dprime/dprime_sample_hm_hotcold_blanco_v1_1_rmon2_rmvet2.eps}
    }
    \hspace*{\fill}\hspace{.2cm}\hspace*{\fill}
    \subfloat[\ac{M2} \ac{V1}\label{fig:dprime_v1_jack}]{
        \centering
        \includegraphics[scale=.45]{%
figs/dprime/dprime_sample_hm_hotcold_jack_v1_1_rmon2_rmvet2.eps}
    }
    \hspace*{\fill}
    \\
    \hspace*{\fill}
    \subfloat[\ac{M1} \ac{V4}\label{fig:dprime_v4_blanco}]{
        \centering
        \includegraphics[scale=.45]{%
figs/dprime/dprime_sample_hm_hotcold_blanco_v4_1_rmon2_rmvet2.eps}
    }
    \hspace*{\fill}\hspace{.2cm}\hspace*{\fill}
    \subfloat[\ac{M2} \ac{V4}\label{fig:dprime_v4_jack}]{
        \centering
        \includegraphics[scale=.45]{%
figs/dprime/dprime_sample_hm_hotcold_jack_v4_1_rmon2_rmvet2.eps}
    }
    \hspace*{\fill}
    \caption{\captionemph{Change in sensitivity index, $d'$, over training sessions.}
\protect\subref{fig:dprime_v1_blanco}: $d'$ for \ac{M1} \ac{V1}, shown for each recording channel, with channels ordered according to average $d'$ over all sessions.
Above, traces of $d'$ for each channel (colours), and average over channels (black).
Below, heatmap showing $d'$ for each channel.
Right top, violin plots showing distribution over channels of the average $d'$ in the first three sessions (\zonename{A}) and last (\zonename{B}) three sessions, with mean (solid black line) and median (dashed green line) over channels indicated.
The violin plot shows a Gaussian kernel density using a bandwidth determined automatically as described in \autoref{sec:violin_plot_method}.
\protect\subref{fig:dprime_v1_jack}: Same as \protect\subref{fig:dprime_v1_blanco}, but for \ac{M2}.
\protect\subref{fig:dprime_v4_blanco} and \protect\subref{fig:dprime_v4_jack}: Same as \protect\subref{fig:dprime_v1_blanco} and \protect\subref{fig:dprime_v1_jack}, but for \ac{V4}.
}
\label{fig:dprime}
\label{fig:dprime_v1}
\label{fig:dprime_v4}
\end{figure}

The results for \ac{V4} contrast with our findings for \ac{V1}.
For \ac{M1}, some \ac{V4} channels marginally increased and others marginally decreased their $d'$ with training (\autoref{fig:dprime_v4_blanco}).
Overall, there was on average a small increase in $d'$, with $\Delta d' = +0.052$, which was not a statistically significant change ($p=0.46$).

For \ac{M2}, many \ac{V4} channels were either indifferent to the stimulus, $d'=0$, or were suppressed by it, $d'<0$ (\autoref{fig:dprime_v4_jack}) on the first day of the experiment.
There was a significant increase of $\Delta d' = +0.491$ ($p < 7 \times 10 ^{-8}$) over training.
However the final $d'$ for almost all channels recorded for \ac{M2} was still lower than the average $d'$ for \ac{M1}.


\subsection{Discussion of sensitivity}
\label{sec:pl_dprime_discuss}

By analysing the sensitivity index, $d'$, we can see whether channels become more or less responsive to our stimulus class over time.
Since \ac{V1} is an early step in the visual processing hierarchy, its neurons respond strongly to simple stimuli such as the sinusoidal gratings we present.
Consequently, neurons have large responses to our stimuli even from the first session of the experimental training.
Over time, we found a decrease in sensitivity in \ac{V1} for both subjects.
We suspect this decrease in sensitivity of the neural response in \ac{V1} to the sample stimulus is due to unpreventable deterioration in the recording quality of the implanted chronic electrodes over time.
Over time, the noise increases and the \ac{SNR} falls, which leads to a reduction in the distinguishability of the two activity distributions.

On the other hand, \ac{V4} is higher up the visual hierarchy and in general responds to more a complex stimulus class.
For \ac{M1}, many of the neurons we recorded from were responsive to the primitive Gabor stimulus from the beginning of training.
But for \ac{M2}, this was not the case --- on the contrary, many neurons were suppressed by the Gabor stimulus.
With training, neurons recorded in \ac{M1} did not notably change their sensitivity to the sample stimulus, whereas $d'$ did increase for \ac{M2}.

We make particular note of the fact that $d'$ in \ac{V4} increased for \ac{M2} from initially mostly negative values.
In principle, a decrease in activity in response to a stimulus can provide as much information about the presence of the stimulus as increase in activity.
However, it is difficult for neurons to increase their spontaneous activity due to the constraining effects of homeostasis, and it would be energetically inefficient for them to do so.
Therefore, since the firing rate of a neuron cannot fall below $0$ there is a smaller limit to the amount by which firing rates can differ if the information about the stimulus is conveyed by a reduction in activity compared to the background rate.
To provide more sensitivity for the response to our experimental stimuli, it thus makes sense for neurons which are suppressed by the stimulus class to increase their responses such that they are enhanced by its presence.
In practice, the de-suppression of the responses may arise not from the need of many individual neurons to encode the stimulus, but from a small number increasing the magnitude of their responses and then the connected neurons (which are positively correlated) increase their responses also.

From these results, we hypothesise that the sensitivity of the response to the experimental stimuli increases for the local network retinotopic to the stimulus location if it is too low for the network overall.
If the neurons are sufficiently sensitive to the stimulus to begin with (if $d'$ is high enough) then the sensitivity remains the same and does not increase with training.
Of course, the recorded sensitivity may decrease due to the decline in the recording quality.

With this measure, we can determine which channels contain neurons which change their relative responsiveness to the stimulus class, but we do not know how the distribution of responses change across the 14 different stimuli.
It is certainly plausible for neurons which begin their training already responsive to the stimuli to change their distribution of activity with respect to the contrast of the stimulus to provide more pertinent information for the experimental task.
For instance, this would be achieved if the absolute activity in response to the sample stimulus remains the same but the rate of change of activity with respect to the contrast of the stimulus increases.


%==============================================================================
\section{Neural correlations}

To provide a simple measure of the similarity in the neural responses given by the recording channels, we computed the correlation in their responses.
As described in \autoref{sec:bg-corr}, we can consider both the signal correlation and the noise correlation.

To measure the signal correlation, we first averaged the response (over all repetitions) elicited by each stimulus for each recording channel.
Then, for each pair of channels we took the correlation in the average responses to each stimulus.
Channels which respond to the set of stimuli in a similar manner will have a high signal correlation, irrespective of how the response curve is shaped.

To determine the noise correlation, we measured the correlation in responses from a pair of channels obtained over all presentations of single stimulus.
This was repeated for each stimulus class, and then averaged over the stimuli.
Channels whose responses vary in a similar manner for a simultaneously recorded trial will have a high noise correlation.

In both cases, we measured the correlation between the responses from the two channels using the Pearson correlation coefficient.
If we let the responses observed from our two recording channels be denoted by the random variables $X$ and $Y$, their Pearson correlation coefficient is given by
\begin{equation}
\label{eq:pearson}
r(X,Y) = \frac{\operatorname{cov}(X,Y)}{\operatorname{var}(X) \, \operatorname{var}(Y)}
.\end{equation}
This provides a measure of the covariance between $X$ and $Y$ which is normalised again their standard deviations, meaning that $-1 \le r \le 1$ and $r$ is robust against linear rescaling of either $X$ or $Y$ (or both).
If $r=\pm1$, there is a perfect linear relationship between $X$ and $Y$, whereas $r=0$ when $X$ and $Y$ are completely independent of one another.

To investigate whether the signal and noise correlations rose or fell during the experiments, we compared the average correlation over the first and last three sessions (intervals \zonename{A} and \zonename{B}).
We used a paired $t$-test to measure whether the correlations changed significantly over all pairs of channels.


%------------------------------------------------------------------------------
\subsection{Results for neural correlations}

% \subsubsection(Signal correlation}

For both brain regions, the signal correlation between pairs channels is shown in \autoref{fig:pl_sigcor}.
For \ac{V1}, the signal correlations significantly increased for both \ac{M1} and \ac{M2} ($p < 1 \times 10^{-12}$ and $p < 3 \times 10^{-25}$, respectively).
With \ac{M1}, the signal correlations rose on average by \num{0.107\pm0.014}.
The signal correlation was very high for \ac{M2} from the start of the experiment, and consequently the increase was only a tenth of the magnitude (\num{0.010\pm0.0009}).
For \ac{V4}, the signal correlations decreased for \ac{M1} ($p=0.00054$), but there was no significant change for \ac{M2} ($p=0.73$).

% blanco v1  signal correlation
% ttest A vs Gaussian distributed around 0
% n=253  h=1.000000  p=0.000000=3.281036e-80   mean = +0.540652+/-0.019104
% ttest B vs Gaussian distributed around 0
% n=253  h=1.000000  p=0.000000=1.208655e-134   mean = +0.647349+/-0.012713
% paired ttest (B-A) vs Gaussian distributed around 0
% n=253  h=1.000000  p=0.000000=9.116294e-13   delta = +0.106697+/-0.014172 = +19.734980%+/-3.243615%
% rule of thumb:  bandwidth=0.106217 bandwidth=0.070680
% same bandwidth bw = 0.03534 used for all cols
% YLIM4 = [-0.506128344655849 1.14595591946254];
%
% jack v1  signal correlation
% ttest A vs Gaussian distributed around 0
% n=300  h=1.000000  p=0.000000=0.000000e+00   mean = +0.968895+/-0.001118
% ttest B vs Gaussian distributed around 0
% n=300  h=1.000000  p=0.000000=0.000000e+00   mean = +0.978874+/-0.000855
% paired ttest (B-A) vs Gaussian distributed around 0
% n=300  h=1.000000  p=0.000000=2.530927e-25   delta = +0.009979+/-0.000874 = +1.029929%+/-0.143603%
% rule of thumb:  bandwidth=0.006542 bandwidth=0.005003
% same bandwidth bw = 0.0025016 used for all cols
% YLIM4 = [0.873646862981458 1.00765225159413];
%
% blanco v4  signal correlation
% ttest A vs Gaussian distributed around 0
% n=435  h=1.000000  p=0.000000=3.823194e-64   mean = +0.463776+/-0.023036
% ttest B vs Gaussian distributed around 0
% n=435  h=1.000000  p=0.000000=7.456894e-40   mean = +0.401404+/-0.027364
% paired ttest (B-A) vs Gaussian distributed around 0
% n=435  h=1.000000  p=0.000538=5.375265e-04   delta = -0.062371+/-0.017885 = -13.448596%+/-4.492001%
% rule of thumb:  bandwidth=0.150814 bandwidth=0.179149
% same bandwidth bw = 0.075407 used for all cols
% YLIM4 = [-1.14206409217235 1.18223119416355];
%
% jack v4  signal correlation
% ttest A vs Gaussian distributed around 0
% n=190  h=1.000000  p=0.000000=2.461716e-120   mean = +0.730780+/-0.012932
% ttest B vs Gaussian distributed around 0
% n=190  h=1.000000  p=0.000000=1.697457e-97   mean = +0.735099+/-0.017571
% paired ttest (B-A) vs Gaussian distributed around 0
% n=190  h=0.000000  p=0.728931=7.289309e-01   delta = +0.004319+/-0.012444 = +0.590992%+/-2.138241%
% rule of thumb:  bandwidth=0.065938 bandwidth=0.089591
% same bandwidth bw = 0.032969 used for all cols
% YLIM4 = [-0.23931881602164 1.09905730731623];

\begin{figure}[htbp]%
    \centering
    \hspace*{\fill}
    \subfloat[][\ac{M1} \ac{V1}.\label{fig:pl_sigcor_v1_blanco}]{%
        \includegraphics[scale=.45]{%
figs/correlations/signal_correlation_sessionwise_blanco_v1_23chn_s343-359.eps}}
    \hspace*{\fill}\hspace{.2cm}\hspace*{\fill}
    \subfloat[][\ac{M2} \ac{V1}.\label{fig:pl_sigcor_v1_jack}]{%
        \includegraphics[scale=.45]{%
figs/correlations/signal_correlation_sessionwise_jack_v1_25chn_s51-72.eps}}
    \hspace*{\fill}
    \\
    \hspace*{\fill}
    \subfloat[][\ac{M1} \ac{V4}.\label{fig:pl_sigcor_v4_blanco}]{%
        \includegraphics[scale=.45]{%
figs/correlations/signal_correlation_sessionwise_blanco_v4_30chn_s307,308,311,313,314,317,318,320,321,329-341.eps}}
    \hspace*{\fill}\hspace{.2cm}\hspace*{\fill}
    \subfloat[][\ac{M2} \ac{V4}.\label{fig:pl_sigcor_v4_jack}]{%
        \includegraphics[scale=.45]{%
figs/correlations/signal_correlation_sessionwise_jack_v4_20chn_s24,25,27-38,40-49.eps}}
    \hspace*{\fill}
    \caption{\captionemph{Signal correlation between pairs of recording channels.}
The correlation in the average firing rate in response to each stimulus condition was computed for each pair of channels (\protect\subref{fig:pl_sigcor_v1_blanco}~\num{253} pairs of channels, \protect\subref{fig:pl_sigcor_v1_jack}~\num{300} pairs, \protect\subref{fig:pl_sigcor_v4_blanco}~\num{435} pairs, \protect\subref{fig:pl_sigcor_v4_jack}~\num{190} pairs).
Main panels: average across all pairs of channels, with standard deviation indicated by the shaded region.
Right hand panels: the Gaussian kernel density for the distribution over channel pairs of the average signal correlation during the first (\zonename{A}) and last (\zonename{B}) three sessions, with mean (solid black line) and median (dashed green line) indicated.
The bandwidth for the Gaussian kernel density estimate was determined as described in \autoref{sec:info-methods}.
}
    \label{fig:pl_sigcor}
\end{figure}


% \subsubsection(Noise correlation}

The noise correlation between pairs of channels is shown in \autoref{fig:pl_noisecor}.
For \ac{V1}, the noise correlations increased for \ac{M1} ($p < 4 \times 10^{-6}$) but decreased for \ac{M2} ($p < 4 \times 10^{-34}$).
For \ac{V4}, noise correlations increased for both subjects ($p < 3 \times 10^{-22}$ and $p=0.0020$ respectively).

% blanco v1  noise correlation
% ttest A vs Gaussian distributed around 0
% n=253  h=1.000000  p=0.000000=5.562834e-61   mean = +0.060580+/-0.002739
% ttest B vs Gaussian distributed around 0
% n=253  h=1.000000  p=0.000000=2.047604e-72   mean = +0.076415+/-0.002972
% paired ttest (B-A) vs Gaussian distributed around 0
% n=253  h=1.000000  p=0.000004=3.608360e-06   delta = +0.015835+/-0.003342 = +26.139404%+/-5.523726%
% rule of thumb:  bandwidth=0.015226 bandwidth=0.016522
% same bandwidth bw = 0.0076131 used for all cols
% YLIM4 = [-0.106577858192329 0.222497958237928];
%
% jack v1  noise correlation
% ttest A vs Gaussian distributed around 0
% n=300  h=1.000000  p=0.000000=2.669581e-140   mean = +0.194049+/-0.004122
% ttest B vs Gaussian distributed around 0
% n=300  h=1.000000  p=0.000000=6.193732e-136   mean = +0.163128+/-0.003601
% paired ttest (B-A) vs Gaussian distributed around 0
% n=300  h=1.000000  p=0.000000=3.121784e-34   delta = -0.030922+/-0.002224 = -15.934934%+/-1.218124%
% rule of thumb:  bandwidth=0.024129 bandwidth=0.021076
% same bandwidth bw = 0.010538 used for all cols
% YLIM4 = [-0.124694762088965 0.489870431813113];
%
% blanco v4  noise correlation
% ttest A vs Gaussian distributed around 0
% n=435  h=1.000000  p=0.000000=3.563376e-45   mean = +0.033228+/-0.002090
% ttest B vs Gaussian distributed around 0
% n=435  h=1.000000  p=0.000000=1.109380e-79   mean = +0.062977+/-0.002672
% paired ttest (B-A) vs Gaussian distributed around 0
% n=435  h=1.000000  p=0.000000=2.377835e-22   delta = +0.029748+/-0.002892 = +89.527284%+/-8.706995%
% rule of thumb:  bandwidth=0.013684 bandwidth=0.017495
% same bandwidth bw = 0.0068421 used for all cols
% YLIM4 = [-0.19407640230239 0.332462621568585];
%
% jack v4  noise correlation
% ttest A vs Gaussian distributed around 0
% n=190  h=1.000000  p=0.000000=5.747164e-60   mean = +0.131589+/-0.005423
% ttest B vs Gaussian distributed around 0
% n=190  h=1.000000  p=0.000000=1.793436e-60   mean = +0.142534+/-0.005826
% paired ttest (B-A) vs Gaussian distributed around 0
% n=190  h=1.000000  p=0.001985=1.985220e-03   delta = +0.010945+/-0.003490 = +8.317907%+/-2.707093%
% rule of thumb:  bandwidth=0.027650 bandwidth=0.029708
% same bandwidth bw = 0.013825 used for all cols
% YLIM4 = [-0.0604309666950958 0.522881761936691];

\begin{figure}[htbp]%
    \centering
    \hspace*{\fill}
    \subfloat[][\ac{M1} \ac{V1}.\label{fig:pl_noisecor_v1_blanco}]{%
        \includegraphics[scale=.45]{%
figs/correlations/noise_correlation_sessionwise_blanco_v1_23chn_s343-359.eps}}
    \hspace*{\fill}\hspace{.2cm}\hspace*{\fill}
    \subfloat[][\ac{M2} \ac{V1}.\label{fig:pl_noisecor_v1_jack}]{%
        \includegraphics[scale=.45]{%
figs/correlations/noise_correlation_sessionwise_jack_v1_25chn_s51-72.eps}}
    \hspace*{\fill}
    \\
    \hspace*{\fill}
    \subfloat[][\ac{M1} \ac{V4}.\label{fig:pl_noisecor_v4_blanco}]{%
        \includegraphics[scale=.45]{%
figs/correlations/noise_correlation_sessionwise_blanco_v4_30chn_s307,308,311,313,314,317,318,320,321,329-341.eps}}
    \hspace*{\fill}\hspace{.2cm}\hspace*{\fill}
    \subfloat[][\ac{M2} \ac{V4}.\label{fig:pl_noisecor_v4_jack}]{%
        \includegraphics[scale=.45]{%
figs/correlations/noise_correlation_sessionwise_jack_v4_20chn_s24,25,27-38,40-49.eps}}
    \hspace*{\fill}
    \caption{\captionemph{Noise correlation between pairs of recording channels.}
The correlation in the average firing rate in response to each stimulus condition was computed for each pair of channels (\protect\subref{fig:pl_noisecor_v1_blanco}~\num{253} pairs of channels, \protect\subref{fig:pl_noisecor_v1_jack}~\num{300} pairs, \protect\subref{fig:pl_noisecor_v4_blanco}~\num{435} pairs, \protect\subref{fig:pl_noisecor_v4_jack}~\num{190} pairs).
Main panels: average across all pairs of channels, with standard deviation indicated by the shaded region.
Right hand panels: the Gaussian kernel density for the distribution over channel pairs of the average noise correlation during the first (\zonename{A}) and last (\zonename{B}) three sessions, with mean (solid black line) and median (dashed green line) indicated.
The bandwidth for the Gaussian kernel density estimate was determined as described in \autoref{sec:info-methods}.
}
    \label{fig:pl_noisecor}
\end{figure}


\subsection{Discussion of neural correlations}

Signal correlation provides a measure of the heterogeneity of the responses.
For \ac{M2} \ac{V1}, all recording channels responded to the stimuli strongly and with a similar stimulus-response tuning curve, and so the signal correlation was very high.
Other data sets had a more diverse set of neurons, and hence a lower signal correlation.

As described in \autoref{sec:pl_response_curves}, the majority of neurons have a contrast-response curve which increases monotonically.
Under such an encoding regime, the amount of information encoded by a pair of neurons will be higher if their responses are anti-correlated.
(See \autoref{sec:bg-noisecorr} for discussion of this).
Consequently, we might expect noise correlations to decrease with training, since this provides one potential mechanism for the performance of the network to improve.
However, we instead found that noise correlations increased with training for \ac{M1} in both \ac{V1} and \ac{V4}, and only decreased significantly for \ac{M2} \ac{V1}.


%==============================================================================
\section{Information in individual channels}
%------------------------------------------------------------------------------

We now apply the principles of Shannon information, as described in \autoref{sec:bgit}, to the perceptual learning data.
We are interested in how easy it is to determine which contrast the stimulus was presented with by observing the neural activity in response to the stimulus.
Since the subject's performance increases with training, we expect to find the amount of information encoded in the neural activity to increase with training.
This much is trivial, since perception occurs within the neural activity of an individual.
What will be interesting to uncover is \textemph{where} the neural changes take place --- in \ac{V1}, in \ac{V4}, neither, or both?

To make its decision, the subject potentially has access to all the neurons we have recorded and all the neurons in the brain from which we have not recorded.
For the best idea of how much information the brain has access to from the recordings we have available, we could evaluate how much information is contained in the vector of neuronal responses for every recording channel.
However, this is problematic.
As the number of data streams combined into the response vector increases, the number of possible unique response vectors increases exponentially.
However, the number of trials recorded is fixed, and the number of possible response vectors must be constrained to prevent the estimated amount of information diverging to infinity (see \autoref{sec:bgit}).

Therefore, in this section we consider the information about the contrast of the stimulus encoded in the firing rate detected from only a single channel at once.
In doing so, we will ignore the possible redundancy or synergy in the information encoded by the response of multiple channels.
Later, in \autoref{sec:dec-meth-lin}, we will consider the total information encoded in the population response.
It should be noted that, since the spikes detected from each channel have been left unsorted and not resolved into clusters corresponding to individual neurons, this will be a multi-unit analysis, but only in the sense of neighbouring neurons being detected by the same electrode contact.


%------------------------------------------------------------------------------
\subsection{Methods for computing information}
\label{sec:info-methods}

The mutual information between the spiking activity during the presentation of the test stimulus and the identity of that stimulus was computed using the \textit{Information Breakdown Toolbox} for MATLAB \citep{Magri2009}.
Bias correction was performed using the \ac{PT} method (see \autoref{sec:bgit}) unless indicated otherwise.

To test the significance of changes in information over time, we used a paired Student's $t$-test to compare the difference in information values in $\SET{\zonename{A}}$ and $\SET{\zonename{B}}$ against the null-hypothesis of no change between points \zonename{A} and \zonename{B}.
Although the distribution of information values is evidently non-Gaussian (it is bounded below at \SI{0}{bits}), the distribution in differences in information is close to Gaussian.
We could instead have used the Mann--Whitney $U$ test to compare the two distributions $\SET{\zonename{A}}$ and $\SET{\zonename{B}}$.
This test does not assume the two distributions are Gaussian, but makes the additional assumption that all samples are independent.
Since we record from the same set of channels for both $\SET{\zonename{A}}$ and $\SET{\zonename{B}}$, we are violating the independence assumption, and so the paired Student's $t$-test is a more appropriate choice.

We show the Gaussian kernel estimation of the distribution of information over channels (a ``violin plot'', right-hand panel of \autoref{fig:info_sess_1x527_v1_blanco}, for instance) at the start (\zonename{A}) and end (\zonename{B}) of training.
These were found using the same method as described in \autoref{sec:violin_plot_method}.
Again, the kernel bandwidth was selected as
$H = \min(h_\zonename{A}, h_\zonename{B}) / 2$
to ensure sufficient detail was captured and the two density estimates are comparable.


%------------------------------------------------------------------------------
\subsection{Initial analysis}
\label{sec:pl_initial}

First, we will consider the amount of information about the stimulus contained in a simple firing rate encoding.
For each test stimulus presentation, our response is the total number of spikes which were detected from a single channel during the first \SI{527}{\milli\second} of the stimulus presentation.%
\footnote{This duration is chosen because there is slight variation in the stimulus presentation time, and \SI{527}{\milli\second} slightly shorter than the shortest presentation duration.}

For each recording channel, we computed how much information was contained in this overall firing response about the identity of which stimulus had been presented.
The results of this initial analysis are shown in \autoref{fig:info_sess_1x527}.
We found that information in the overall firing rate of \ac{V1} channels increased with training for \ac{M2} (\SI{+0.069\pm0.017}{bits}, or \SI{+16\pm5}{\percent} relative change; $p=0.0004$) but not for \ac{M1} (\SI{-0.051\pm0.029}{bits} or \SI{-34\pm19}{\percent} relative change; $p=0.09$).
For \ac{V4}, there was an increase in information for both subjects, however this increase was significant for \ac{M2} (\SI{+0.056\pm0.013}{bits} or \SI{+87\pm21}{\percent} relative change; $p=0.0005$) but was not significant for \ac{M1} (\SI{+0.028\pm0.020}{bits} or \SI{+22\pm16}{\percent} relative change; $p=0.17$).


\begin{figure}[htbp]%
    \centering
    \hspace*{\fill}
    \subfloat[][\ac{M1} \ac{V1}.\label{fig:info_sess_1x527_v1_blanco}]{%
        \includegraphics[scale=.45]{%
figs/info2/initial/I_sessionwise_blanco_v1_chmean23_s343-359_oc0_G_1bins_of_527ms_dr_pt_rmvet2_rmvms2_imscn_clhot.eps}}
    \hspace*{\fill}\hspace{.2cm}\hspace*{\fill}
    \subfloat[][\ac{M2} \ac{V1}.\label{fig:info_sess_1x527_v1_jack}]{%
        \includegraphics[scale=.45]{%
figs/info2/initial/I_sessionwise_jack_v1_chmean25_s51-72_oc0_G_1bins_of_527ms_dr_pt_rmvet2_rmvms2_imscn_clhot.eps}}
    \hspace*{\fill}
    \\
    \hspace*{\fill}
    \subfloat[][\ac{M1} \ac{V4}.\label{fig:info_sess_1x527_v4_blanco}]{%
        \includegraphics[scale=.45]{%
figs/info2/initial/I_sessionwise_blanco_v4_chmean30_s307,308,311,313,314,317,318,320,321,329-341_oc0_G_1bins_of_527ms_dr_pt_rmvet2_rmvms2_imscn_clhot.eps}}
    \hspace*{\fill}\hspace{.2cm}\hspace*{\fill}
    \subfloat[][\ac{M2} \ac{V4}.\label{fig:info_sess_1x527_v4_jack}]{%
        \includegraphics[scale=.45]{%
figs/info2/initial/I_sessionwise_jack_v4_chmean20_s24,25,27-38,40-49_oc0_G_1bins_of_527ms_dr_pt_rmvet2_rmvms2_imscn_clhot.eps}}
    \hspace*{\fill}
    \caption{\captionemph{Information about the test stimulus contained in the firing rate during test presentation and its progression over training sessions.}
% The mutual information with the test stimulus is taken for a spike timing based code for a \SI{20}{ms} window of spiking activity, sampled with the start of the window offset ($y$-axis) from \SI{0}{ms} up to \SI{500}{ms} after test stimulus onset.
% The sampling is in intervals of \SI{5}{ms}, so any 4 adjacent squares within each session are highly correlated.
% The recording session number for the data is given along the $x$-axis, and the number of days the animal has been trained for increases from left to right.
% Average mutual information across all the channels is denoted by the pseudo-colour of each of the rectangular patches, centred around the $(x,y)$ co-ordinate to which the measurement relates.
Main panels: information, averaged over channels (\protect\subref{fig:info_sess_1x527_v1_blanco}~\num{23} channels, \protect\subref{fig:info_sess_1x527_v1_jack}~\num{25} channels, \protect\subref{fig:info_sess_1x527_v4_blanco}~\num{30} channels, \protect\subref{fig:info_sess_1x527_v4_jack}~\num{20} channels), with standard error across channels indicated by the shaded region.
Right hand panels: distribution over channels of the information contained in the first three sessions (\zonename{A}) versus last three sessions (\zonename{B}), with mean (solid black line) and median (dashed green line) over channels indicated.
The violin plot shows a Gaussian kernel density, using a bandwidth determined as described in \autoref{sec:info-methods}.
The \ac{PT} bias correction method was used, without further correction to the residual bias.
}
    \label{fig:info_sess_1x527}
\end{figure}


For some channels, the measured information was a \textemph{negative} value.
Consequently, the violin plots in \autoref{fig:info_sess_1x527} showing the distribution of information values across channels extend below \num{0}.
This is not because these channels contain a negative amount of information about the stimulus --- in fact it is mathematically impossible for there to be less than \num{0} mutual information between two random variables (see \autoref{eq:info} and its discussion).
Instead, this observed negative value is due to the inherent uncertainty of our measurement of mutual information, which we corrected against the finite-sampling upward bias using the \ac{PT} method.
If we were to measure two completely independent events and perfectly correct for the bias due to finite sampling, our measurements of the information would be distributed around \num{0}.

As described in \autoref{sec:pl_dprime_discuss}, the non-significant reduction of information witnessed for \ac{M1} \ac{V1} is most likely explained by the unavoidable reduction of recording signal quality over time.
However, one channel had a large increase in information content against the trend observed for other channels on this electrode array (see \autoref{fig:info_sess_1x527_v1_blanco}, right panel).
This channel is one of a minority whose response profile changes completely between consecutive sessions, and so the sudden large increase in information is most likely due to a small movement in the electrode contact changing which neurons are measured in the data.
We address this discrepancy next.


%------------------------------------
\subsection{Removing inconsistent channels}

We noted that some channels were moving between sessions.
In general, it is just as likely for electrode contacts to move into locations where they are more informative as to move such that they are less informative.
However, to make the results more comparable across sessions, we chose to remove channels whose raster profile (such as those shown in \autoref{sec:pl_rasters}) and overall firing rate in response to the \SI{30}{\percent} sample stimulus changed clearly and suddenly from one session to the next.
We manually selected a small number of channels on this basis, and removed them from the analysis.
For each dataset, the number of channels included afterwards is indicated in \autoref{tab:nchannels_restricted}.


\begin{table}[bthp]
\begin{center}
\begin{tabular}{ccrr}
\toprule
Region  & Animal    & Channels before   & Channels after \\
\midrule
V1      & M1        & 23                & 14 \\
        & M2        & 25                & 20 \\
V4      & M1        & 30                & 25 \\
        & M2        & 20                & 18 \\
\bottomrule
\end{tabular}
\end{center}
\caption{
\captionemph{Number of channels before and after restriction on the basis of consistent or smoothly changing firing rates across sessions.}
}
\label{tab:nchannels_restricted}
\end{table}


\begin{figure}[htbp]%
    \centering
    \hspace*{\fill}
    \subfloat[][\ac{M1} \ac{V1}.\label{fig:info_sess_1x527_restrictchn_v1_blanco}]{%
        \includegraphics[scale=.45]{%
figs/info2/initial/I_sessionwise_blanco_v1_chmean14_s343-359_oc0_G_1bins_of_527ms_dr_pt_rmvet2_rmvms2_imscn_clhot.eps}}
    \hspace*{\fill}\hspace{.2cm}\hspace*{\fill}
    \subfloat[][\ac{M2} \ac{V1}.\label{fig:info_sess_1x527_restrictchn_v1_jack}]{%
        \includegraphics[scale=.45]{%
figs/info2/initial/I_sessionwise_jack_v1_chmean20_s51-72_oc0_G_1bins_of_527ms_dr_pt_rmvet2_rmvms2_imscn_clhot.eps}}
    \hspace*{\fill}
    \\
    \hspace*{\fill}
    \subfloat[][\ac{M1} \ac{V4}.\label{fig:info_sess_1x527_restrictchn_v4_blanco}]{%
        \includegraphics[scale=.45]{%
figs/info2/initial/I_sessionwise_blanco_v4_chmean25_s307,308,311,313,314,317,318,320,321,329-341_oc0_G_1bins_of_527ms_dr_pt_rmvet2_rmvms2_imscn_clhot.eps}}
    \hspace*{\fill}\hspace{.2cm}\hspace*{\fill}
    \subfloat[][\ac{M2} \ac{V4}.\label{fig:info_sess_1x527_restrictchn_v4_jack}]{%
        \includegraphics[scale=.45]{%
figs/info2/initial/I_sessionwise_jack_v4_chmean18_s24,25,27-38,40-49_oc0_G_1bins_of_527ms_dr_pt_rmvet2_rmvms2_imscn_clhot.eps}}
    \hspace*{\fill}
    \caption{\captionemph{Information, after removing inconsistent channels, about the test stimulus contained in the firing rate during test presentation and its progression over training sessions.}
Main panels: the average over channels (\protect\subref{fig:info_sess_1x527_restrictchn_v1_blanco}~\num{14} channels, \protect\subref{fig:info_sess_1x527_restrictchn_v1_jack}~\num{20} channels, \protect\subref{fig:info_sess_1x527_restrictchn_v4_blanco}~\num{25} channels, \protect\subref{fig:info_sess_1x527_restrictchn_v4_jack}~\num{18} channels) with standard error across channels indicated by the shaded region.
Right hand panels: distribution over channels of the information contained in the first three sessions (\zonename{A}) versus last three sessions (\zonename{B}), with mean (solid black line) and median (dashed green line) over channels indicated.
The \ac{PT} bias correction method was used, without further correction to the residual bias.
}
    \label{fig:info_sess_1x527_restrictchn}
\end{figure}

% blanco v1 1x527.00ms
% dr pt
% same bandwidth bw = 0.018561 used for all cols
% h=1.000000  p=0.014856=1.485642e-02   delta = -0.049242+/-0.017549 = -40.514232%+/-14.587530%
%
% jack v1 1x527.00ms
% dr pt
% same bandwidth bw = 0.033931 used for all cols
% h=1.000000  p=0.000970=9.696090e-04   delta = +0.052784+/-0.013545 = +12.980690%+/-4.272728%
%
% blanco v4 1x527.00ms
% dr pt
% same bandwidth bw = 0.033252 used for all cols
% h=0.000000  p=0.556266=5.562658e-01   delta = +0.010819+/-0.018130 = +9.059702%+/-15.387211%
%
% jack v4 1x527.00ms
% dr pt
% same bandwidth bw = 0.012428 used for all cols
% h=1.000000  p=0.001046=1.046127e-03   delta = +0.056465+/-0.014315 = +91.889667%+/-23.318749%

Besides the channel for \ac{M1} \ac{V1} with an aberrantly large increase in information mentioned above, there is little impact on the results (\autoref{fig:info_sess_1x527_restrictchn}) compared with previously (\autoref{fig:info_sess_1x527}).
For this dataset, \ac{M1} \ac{V1}, the removal of the outlier means the reduction in information over time is now statistically significant (\SI{-0.049\pm0.018}{bits} or \SI{-41\pm15}{\percent}, $p=0.015$).
For the other datasets, there were no notable changes.


%------------------------------------
\subsection{Correcting stimulus class imbalance}
\label{sec:pl_class_imbalance}

As mentioned in \autoref{sec:pl_task}, the stimulus presentation procedure was to include a fixed number of repetitions of each stimulus in a block of trials and present them in a random order.
At the end of each block, additional trials were presented for stimuli which the subject responded to incorrectly.
Since stimuli with a contrast far from the pedestal contrast of \SI{30}{\percent} are much easier for the subject, trials which were repeated at the end of the block were not uniformly distributed across the stimuli.
Overall, this means that harder stimuli close to \SI{30}{\percent} contrast are presented more often than the easier stimuli, as depicted in \autoref{fig:class_balance}.


% blanco v4
% Outer stimuli: A->B 0.497413
% Inner stimuli: A->B 0.094376
% blanco v1
% Outer stimuli: A->B 1.537775
% Inner stimuli: A->B -0.292156
% jack v4
% Session 26 could not be found on disc for jack v4.
% Session 39 could not be found on disc for jack v4.
% Outer stimuli: A->B -2.775447
% Inner stimuli: A->B 5.471745
% jack v1
% Outer stimuli: A->B 2.413654
% Inner stimuli: A->B -2.481668

\begin{figure}[htbp]%
    \centering
    \hspace*{\fill}
    \subfloat[][\ac{M1} \ac{V1}.\label{fig:class_balance_v1_blanco}]{%
        \includegraphics[scale=.45]{%
figs/class_balance/ntrialscond_prop_blanco_v1_oc0_rmvet2_.eps}}
    \hspace*{\fill}\hspace{.2cm}\hspace*{\fill}
    \subfloat[][\ac{M2} \ac{V1}.\label{fig:class_balance_v1_jack}]{%
        \includegraphics[scale=.45]{%
figs/class_balance/ntrialscond_prop_jack_v1_oc0_rmvet2_.eps}}
    \hspace*{\fill}
    \\
    \hspace*{\fill}
    \subfloat[][\ac{M1} \ac{V4}.\label{fig:class_balance_v4_blanco}]{%
        \includegraphics[scale=.45]{%
figs/class_balance/ntrialscond_prop_blanco_v4_oc0_rmvet2_.eps}}
    \hspace*{\fill}\hspace{.2cm}\hspace*{\fill}
    \subfloat[][\ac{M2} \ac{V4}.\label{fig:class_balance_v4_jack}]{%
        \includegraphics[scale=.45]{%
figs/class_balance/ntrialscond_prop_jack_v4_oc0_rmvet2_.eps}}
    \hspace*{\fill}
    \caption{\captionemph{Proportion of trials in each stimulus class.}
Main panels: the proportion (\%) of trials which belong to each stimulus class, with colours indicated to the right, as a function of experimental session.
Above panels: the ``inner \num{6}'' contrasts closest to \SI{30}{\percent} (grey) and ``outer \num{6}'' contrasts furthest from \SI{30}{\percent} (purple).
See \autoref{tab:pl_stim} for the \num{6} contrasts in each group by brain region.
Right hand panels: proportion of trials presented during the first (\zonename{A}) and last (\zonename{B}) three sessions.
}
    \label{fig:class_balance}
\end{figure}


To compute the amount of information about the stimulus contained in the animal's response, we do not need to have a uniform distribution across stimuli.
However, the subject becomes better at the task with training, and the change in relative performance is necessarily not uniform across sessions.
For \ac{M1}, the proportion of trials which belong to each stimulus class was very similar throughout the experiment, as shown in Figures \ref{fig:class_balance_v1_blanco} and \ref{fig:class_balance_v4_blanco}.
However for \ac{M2}, this was not the case.
During training with the \ac{V1} stimulation protocol, there was a larger increase in performance for the harder contrast stimuli, which were consequently presented less frequently by the end of training --- the percentage of stimuli with a contrast in one of the hardest 6 categories (closest to \SI{30}{\percent} contrast) fell by \SI{2.5}{\percent} in absolute terms.
This change in stimulus class distribution may seem small, but the size of this change is comparable to the amount of change in information we previously computed.
When training \ac{M2} with the \ac{V4} stimuli, the overall performance was initially lower.
Consequently, the largest increase in performance was that attained for the easier stimuli, and the percentage of trials featuring one of the 6 easiest stimuli (furthest from \SI{30}{\percent} contrast) fell by \SI{5.4}{\percent} in absolute terms.

Changes in the distribution of classes between sessions can impact our analysis in two ways.
Firstly, as described \autoref{eq:info} the amount of information between stimulus, $S$, and response, $R$, is dependent on the entropy of the stimulus, $\HH(S)$.
As the distribution of stimulus classes moves closer to uniform, the stimulus entropy increases.
Since our stimulus distribution generally tends to become flatter after training, this may cause the measured information to be inflated as training progresses.
Secondly, as seen for \ac{M2} \ac{V1}, the proportion of trials which are in the easier categories is higher for later sessions.
These stimuli will have the most distinguishable responses, and their increasing prevalence in the dataset may also produce an artificial increase in information with training.

We corrected the class imbalance on a session-by-session basis by subsampling the trials for more frequent stimulus classes down to the frequency of the least common stimulus class.
The trials included in the subsample were selected at random across the set of trials for each stimulus, without replacement.


\begin{figure}[htbp]%
    \centering
    \hspace*{\fill}
    \subfloat[][\ac{M1} \ac{V1}.\label{fig:info_sess_1x527_balanced_v1_blanco}]{%
        \includegraphics[scale=.45]{%
figs/info2/initial/I_sessionwise_blanco_v1_chmean14_s343-359_oc0_Gbalanced_1bins_of_527ms_dr_pt_rmvet2_rmvms2_imscn_clhot.eps}}
    \hspace*{\fill}\hspace{.2cm}\hspace*{\fill}
    \subfloat[][\ac{M2} \ac{V1}.\label{fig:info_sess_1x527_balanced_v1_jack}]{%
        \includegraphics[scale=.45]{%
figs/info2/initial/I_sessionwise_jack_v1_chmean20_s51-72_oc0_Gbalanced_1bins_of_527ms_dr_pt_rmvet2_rmvms2_imscn_clhot.eps}}
    \hspace*{\fill}
    \\
    \hspace*{\fill}
    \subfloat[][\ac{M1} \ac{V4}.\label{fig:info_sess_1x527_balanced_v4_blanco}]{%
        \includegraphics[scale=.45]{%
figs/info2/initial/I_sessionwise_blanco_v4_chmean25_s307,308,311,313,314,317,318,320,321,329-341_oc0_Gbalanced_1bins_of_527ms_dr_pt_rmvet2_rmvms2_imscn_clhot.eps}}
    \hspace*{\fill}\hspace{.2cm}\hspace*{\fill}
    \subfloat[][\ac{M2} \ac{V4}.\label{fig:info_sess_1x527_balanced_v4_jack}]{%
        \includegraphics[scale=.45]{%
figs/info2/initial/I_sessionwise_jack_v4_chmean18_s24,25,27-38,40-49_oc0_Gbalanced_1bins_of_527ms_dr_pt_rmvet2_rmvms2_imscn_clhot.eps}}
    \hspace*{\fill}
    \caption{\captionemph{Information, after correcting for the stimulus class balance in each session, about the test stimulus contained in the firing rate during test presentation and its progression over training sessions.}
Subpanels are arranged as per \autoref{fig:info_sess_1x527_restrictchn}, with the same number of channels included.
The \ac{PT} bias correction method was used, without further correction to the residual bias.
}
    \label{fig:info_sess_1x527_balanced}
\end{figure}

% blanco v1 1x527.00ms
% dr pt
% same bandwidth bw = 0.02234 used for all cols
% h=1.000000  p=0.001794=1.794017e-03   delta = -0.089123+/-0.022797 = -50.472174%+/-13.226381%
%
% jack v1 1x527.00ms
% dr pt
% same bandwidth bw = 0.038202 used for all cols
% h=0.000000  p=0.179003=1.790031e-01   delta = +0.022181+/-0.015896 = +4.511570%+/-4.419345%
%
% blanco v4 1x527.00ms
% dr pt
% same bandwidth bw = 0.038581 used for all cols
% h=0.000000  p=0.779391=7.793914e-01   delta = +0.006273+/-0.022144 = +4.185196%+/-15.076193%
%
% jack v4 1x527.00ms
% dr pt
% same bandwidth bw = 0.018676 used for all cols
% h=1.000000  p=0.004131=4.130838e-03   delta = +0.060078+/-0.018145 = +61.470204%+/-18.627960%


Overall, we find the amount of information increases when the class imbalance is corrected for (compare the y-scales of \autoref{fig:info_sess_1x527_balanced} with those of \autoref{fig:info_sess_1x527_restrictchn}).
This is because the stimulus entropy, $\HH(S)$, has increased when the stimulus distribution became uniform.

As anticipated, correcting for changes in the class balance over time reduces the relative increase in information between the beginning and end of training.
For \ac{V1}, the change in information over training seen in \ac{M1} is reduced more (\SI{-0.089\pm0.023}{bits} or \SI{-50\pm13}{\percent}, $p=0.0018$) and the increase in information for \ac{M2} is no longer statistically significant (\SI{+0.022\pm0.016}{bits} or \SI{+4.5\pm4.4}{\percent}, $p=0.18$).
For \ac{V4}, the outcomes stand unchanged even though the relative change in information is reduced
(\ac{M1}: \SI{+0.006\pm0.022}{bits} or \SI{+4\pm15}{\percent}, $p=0.78$; \ac{M2}: \SI{+0.060\pm0.018}{bits} or \SI{+61\pm19}{\percent}, $p=0.004$).

This \textit{post-hoc} class rebalancing was applied throughout the rest of this chapter.
Moreover, the subset of trials which was selected was also maintained, to ensure comparability of results across sections.


%------------------------------------
\subsection{Defending against changes in session duration}

A substantial amount of session-to-session variability in the measurements was observed in our results, depicted in the time-course plots of \autoref{fig:info_sess_1x527}.
A large part of this variability was due to changes in the duration of each session --- some sessions contain \num{5} times as many trials as others.

% blanco v4
% Min # trials for single cond, single session: 17
% Max # trials for single cond, single session: 191
% Min # trials for all cond, single session: 291
% Max # trials for all cond, single session: 1889
% Min # trials for all cond, single rebalanced session: 238
% Max # trials for all cond, single rebalanced session: 1540
% blanco v1
% Min # trials for single cond, single session: 11
% Max # trials for single cond, single session: 147
% Min # trials for all cond, single session: 254
% Max # trials for all cond, single session: 1413
% Min # trials for all cond, single rebalanced session: 154
% Max # trials for all cond, single rebalanced session: 1120
% jack v4
% Min # trials for single cond, single session: 19
% Max # trials for single cond, single session: 125
% Min # trials for all cond, single session: 431
% Max # trials for all cond, single session: 1239
% Min # trials for all cond, single rebalanced session: 266
% Max # trials for all cond, single rebalanced session: 770
% jack v1
% Min # trials for single cond, single session: 18
% Max # trials for single cond, single session: 167
% Min # trials for all cond, single session: 371
% Max # trials for all cond, single session: 1440
% Min # trials for all cond, single rebalanced session: 252
% Max # trials for all cond, single rebalanced session: 1134

% blanco v1, onlycorrect=0 restrict_channels=2
% Min number of codes for single channel: 4
% Max number of codes for single channel: 24
% Min number of trials per code for single channel: 1.200000
% Max number of trials per code for single channel: 17.000000
% jack v1, onlycorrect=0 restrict_channels=2
% Min number of codes for single channel: 5
% Max number of codes for single channel: 30
% Min number of trials per code for single channel: 1.200000
% Max number of trials per code for single channel: 15.400000
% blanco v4, onlycorrect=0 restrict_channels=2
% Min number of codes for single channel: 3
% Max number of codes for single channel: 34
% Min number of trials per code for single channel: 1.285714
% Max number of trials per code for single channel: 26.500000
% jack v4, onlycorrect=0 restrict_channels=2
% Min number of codes for single channel: 5
% Max number of codes for single channel: 24
% Min number of trials per code for single channel: 1.461538
% Max number of trials per code for single channel: 13.888889

% blanco v1, onlycorrect=0 restrict_channels=2 FLAG_MATCH_NT=1
% Min number of codes for single channel: 4
% Max number of codes for single channel: 23
% Min number of trials per code for single channel: 1.100000
% Max number of trials per code for single channel: 13.333333
% jack v1, onlycorrect=0 restrict_channels=2 FLAG_MATCH_NT=1
% Min number of codes for single channel: 5
% Max number of codes for single channel: 30
% Min number of trials per code for single channel: 1.200000
% Max number of trials per code for single channel: 16.200000
% blanco v4, onlycorrect=0 restrict_channels=2 FLAG_MATCH_NT=1
% Min number of codes for single channel: 3
% Max number of codes for single channel: 32
% Min number of trials per code for single channel: 1.214286
% Max number of trials per code for single channel: 18.333333
% jack v4, onlycorrect=0 restrict_channels=2 FLAG_MATCH_NT=1
% Min number of codes for single channel: 5
% Max number of codes for single channel: 22
% Min number of trials per code for single channel: 1.315789
% Max number of trials per code for single channel: 8.833333

Although we were utilising the \ac{PT} bias correction technique, this typically requires \num{4} trials per response for each stimulus condition to be completely effective \citep{Panzeri2007}.
When analysing the amount of information contained in the overall firing rate, the cardinality of the set of spike counts per channel --- the number of possible numbers of spikes during the test stimulus presentation --- ranges from \num{3} to \num{50}.
The number of trials in one session for an individual stimulus varies from \num{11} to \num{191}, with the total number of trials per session ranging from \num{254} to \num{1889}.
Consequently, the number of trials per response to a single stimulus varies from \num{1.2} to \num{26.5}.
After correcting for the stimulus class imbalance, the number of trials we are considering from each session falls, ranging from \num{154} to \num{1540}, exasperating the problem.
With this, the number of trials per response ranges from \num{1.1} to \num{18.3}.
Not only is there a \num{20} fold difference in the number of trials per response, but some sessions have stimuli with only a quarter of the number of repetitions we should be using for the bias correction to be effective \citep{Panzeri2007}.

This shortage of trials per stimulus condition results means the \ac{PT} bias correction method underestimates the bias for the shorter sessions, leading to an overestimate in the reported information.
This is illustrated in \autoref{fig:I_vs_invN}, where we compare the estimated information with the reciprocal number of trials, $\nicefrac{1}{N}$, and find a linear correlation.
This is in keeping with the literature, since $\I_{\text{measured}}$ is known to be proportional to $\nicefrac{1}{N}$ if no bias correction is performed \citep{Treves1995}.

Without correcting for the bias due to finite sampling, the correlation between $\nicefrac{1}{N}$ and $\I_{\text{measured}}$ is large and significant.
For \ac{V1}, the Pearson's correlation coefficient between them was $R=0.99$ and $0.98$ for \ac{M1} and \ac{M2} respectively, which was a significant correlation ($p < 2 \times 10^{-13}$ and $p < 8 \times 10^{-16}$).
For \ac{V4}, $R=0.98$ and $R=0.92$ with p-values $p < 2 \times 10^{-14}$ and $p < 2 \times 10^{-10}$.
But even if we correct for the bias with \ac{PT} or \ac{QE}, the correlation remains large ($R>0.4$) and significant ($p<0.04$) for all datasets except \ac{M2} \ac{V1} with \ac{PT}, where $R=+0.27$ and $p=0.23$.
The correlation is strongest for \ac{M1} \ac{V1}, with $R>0.89$ and $p < 1 \times 10^{-6}$ with either \ac{PT} or \ac{QE} bias correction.

% NvsI labels=balanced, with 0 bootstraps
% blanco v1  Uncorrected      R=+0.9885  p=0.0000=1.024875e-13
% blanco v1  PT               R=+0.8975  p=0.0000=1.033385e-06
% blanco v1  QE               R=+0.9102  p=0.0000=3.978039e-07
% blanco v4  Uncorrected      R=+0.9760  p=0.0000=1.053752e-14
% blanco v4  PT               R=+0.7297  p=0.0001=1.161034e-04
% blanco v4  QE               R=+0.5219  p=0.0127=1.273388e-02
% jack   v1  Uncorrected      R=+0.9816  p=0.0000=7.413434e-16
% jack   v1  PT               R=+0.2669  p=0.2299=2.299408e-01
% jack   v1  QE               R=+0.4432  p=0.0389=3.885677e-02
% jack   v4  Uncorrected      R=+0.9210  p=0.0000=1.773235e-10
% jack   v4  PT               R=+0.6295  p=0.0010=9.804887e-04
% jack   v4  QE               R=+0.5349  p=0.0071=7.081659e-03

\begin{figure}[htbp]
    \centering
    \hspace*{\fill}
    \subfloat[][\ac{M1} \ac{V1}.\label{fig:I_vs_invN_v1_blanco}]{%
        \includegraphics[scale=.45]{%
figs/info2/bias/ntrials_I_vs_invN_combindivpap_leg_blanco_v1_14chn_Gbalanced_1bins_of_527ms.eps}}
    \hspace*{\fill}\hspace{.2cm}\hspace*{\fill}
    \subfloat[][\ac{M2} \ac{V1}.\label{fig:I_vs_invN_v1_jack}]{%
        \includegraphics[scale=.45]{%
figs/info2/bias/ntrials_I_vs_invN_combindivpap_blanco_v4_25chn_Gbalanced_1bins_of_527ms.eps}}
    \hspace*{\fill}
    \\
    \hspace*{\fill}
    \subfloat[][\ac{M1} \ac{V4}.\label{fig:I_vs_invN_v4_blanco}]{%
        \includegraphics[scale=.45]{%
figs/info2/bias/ntrials_I_vs_invN_combindivpap_jack_v1_20chn_Gbalanced_1bins_of_527ms.eps}}
    \hspace*{\fill}\hspace{.2cm}\hspace*{\fill}
    \subfloat[][\ac{M2} \ac{V4}.\label{fig:I_vs_invN_v4_jack}]{%
        \includegraphics[scale=.45]{%
figs/info2/bias/ntrials_I_vs_invN_combindivpap_jack_v4_18chn_Gbalanced_1bins_of_527ms.eps}}
    \hspace*{\fill}
    \caption{\captionemph{Distribution of measured information as a function of $\nicefrac{1}{N}$, where $N$ is the number of trials in the session.}
Results are shown both without correcting for the finite measurement bias (grey circles), using \ac{PT} bias correction (red squares), and using \ac{QE} bias correction (blue diamonds).
Information was computed after using subsampling to address the stimulus class imbalance (see \autoref{sec:pl_class_imbalance}), and this is reflected in the value of $N$.
}
    \label{fig:IvN}
    \label{fig:I_vs_invN}
\end{figure}


There are several potential ways we can correct for the change in bias incurred by the changes in number of trials.
\begin{itemize}
\item Subsample all sessions down to the same number of trials (rarefy).
\item Use bootstrapping, randomising the mapping between stimulus and response, to estimate the residual bias and subtract this from the reported information.
\item Group together stimuli above and below \SI{30}{\percent} contrast so we only have two stimulus classes, each with approximately \num{7} times more trials than before.
\item Group together trials across consecutive sessions so we have the same number of trials in each information computation step.
\end{itemize}

The first method is clearly undesirable, since we would be throwing away most of our data and knowingly operating in the regime where the bias correction method breaks down for all sessions instead of only a few.
In such a scenario, the bias on the estimated information would be larger than the actual information and our comparison across sessions would have little validity.
Instead, we focus on the three other --- more practical --- methods, whose outcomes are described below.


%------------------------------------
\subsubsection{Trial-wise analysis}

We now consider what happens if we group together trials from multiple sessions into a single block and analyse them together.
Doing so allows us to overcome the difference in bias between sessions, since the same number of trials would be used in each block and this can be set large enough to ensure we are in the correct domain for bias correction to perform adequately.
There are typically no more than \num{25} different firing rates for any single channel, so we grouped together \num{100} trials of each stimulus condition.

Using this methodology, we focus on the subject's performance as a function of the number of trials which they have completed since the beginning of the experiment, irrespective of how many training sessions these trials are spread across.
Therefore, such a technique makes sense if we consider learning to occur during sessions and not to occur between them.
However, such a view is in contrast with the hypothesis that one of the important functions of sleep is to facilitate consolidation of memories and learning accumulated during the day.
Should this be an important contributor towards perceptual learning, one would expect the breaks between sessions not to be irrelevant but to instead enable an increase in performance even without exposure to the training stimuli.


\begin{figure}[htbp]%
    \centering
    \hspace*{\fill}
    \subfloat[][\ac{M1} \ac{V1}.\label{fig:info_trial_1x527_balanced_v1_blanco}]{%
        \includegraphics[scale=.45]{%
figs/info2/bias/I_trialwise_blanco_v1_chmean14_s343-354,355.1,355.2,356-359_tp4_1bins_of_527ms_dr_pt_oc0_Gbalanced_test_tc5-5-20,22-3-28,32,35-5-50,60,90_nt1400_ts350_rmvet2_rmvms2_imscn_clhot.eps}}
    \hspace*{\fill}\hspace{.2cm}\hspace*{\fill}
    \subfloat[][\ac{M2} \ac{V1}.\label{fig:info_trial_1x527_balanced_v1_jack}]{%
        \includegraphics[scale=.45]{%
figs/info2/bias/I_trialwise_jack_v1_chmean20_s51-72_tp4_1bins_of_527ms_dr_pt_oc0_Gbalanced_test_tc5-5-20,22-3-28,32,35-5-50,60,90_nt1400_ts350_rmvet2_rmvms2_imscn_clhot.eps}}
    \hspace*{\fill}
    \\
    \hspace*{\fill}
    \subfloat[][\ac{M1} \ac{V4}.\label{fig:info_trial_1x527_balanced_v4_blanco}]{%
        \includegraphics[scale=.45]{%
figs/info2/bias/I_trialwise_blanco_v4_chmean25_s307,308,311,313,314,317,318,320,321,329-341_tp4_1bins_of_527ms_dr_pt_oc0_Gbalanced_test_tc10-5-25,27-29,31-33,35,40-10-60_nt1400_ts350_rmvet2_rmvms2_imscn_clhot.eps}}
    \hspace*{\fill}\hspace{.2cm}\hspace*{\fill}
    \subfloat[][\ac{M2} \ac{V4}.\label{fig:info_trial_1x527_balanced_v4_jack}]{%
        \includegraphics[scale=.45]{%
figs/info2/bias/I_trialwise_jack_v4_chmean18_s24,25,27-38,40-49_tp4_1bins_of_527ms_dr_pt_oc0_Gbalanced_test_tc10-5-25,27-29,31-33,35,40-10-60_nt1400_ts350_rmvet2_rmvms2_imscn_clhot.eps}}
    \hspace*{\fill}
    \caption{\captionemph{Information about the test stimulus contained in the firing rate during test presentation and its progression over training sessions, estimated across blocks of \num{100} consecutive trials of each stimulus class taken by merging consecutive sessions together to accumulate sufficiently many trials.}
Main panels: the average over channels (\protect\subref{fig:info_trial_1x527_balanced_v1_blanco}~\num{14} channels, \protect\subref{fig:info_trial_1x527_balanced_v1_jack}~\num{20} channels, \protect\subref{fig:info_trial_1x527_balanced_v4_blanco}~\num{25} channels, \protect\subref{fig:info_trial_1x527_balanced_v4_jack}~\num{18} channels) with standard error across channels indicated by the shaded region.
Right hand panels: distribution over channels of the information contained in the first three blocks of \num{1400} trials (\zonename{A}) versus last three blocks (\zonename{B}), with mean (solid black line) and median (dashed green line) over channels indicated.
The violin plot shows a Gaussian kernel density, using a bandwidth determined as described in \autoref{sec:info-methods}.
The \ac{PT} bias correction method was used, without further correction to the residual bias.
The stimulus class imbalance was addressed on a session-by-session basis by subsampling as described previously (\autoref{sec:pl_class_imbalance}) before merging sessions together.
}
    \label{fig:info_trial_1x527_balanced}
\end{figure}


Since we performed the spike extraction such that the spontaneous firing rate is held constant across sessions for each channel, the firing rate during stimulus presentation is comparable between sessions.
This means it is plausible that, when decoding the information, the extracted firing rate corresponding to the stimuli could be similar across consecutive sessions.

We find that grouping trials together in this way smooths out the problems with inter-session changes in residual bias on the information estimate.
But because of both changes in neural connectivity and small movement in the electrode contacts between sessions, the neural code is not guaranteed to be the same between sessions.
Indeed, we observed a peak in the estimated information corresponding to longer sessions where the trial sample size is smaller than or a similar size to the number of trials grouped together in each block (not shown\footnote{This phenomena occurred when the analysis was repeated with a smaller number of trials grouped together, and is not present in \autoref{fig:info_trial_1x527_balanced} due to the smoothing effect of using such large blocks of \num{1400} trials.}).
For this reason, it is prudent not to proceed with such a methodology.


%------------------------------------
\subsubsection{Bootstrap correction}
\label{sec:pl_bootstrapping}

Shuffling the responses across stimuli destroys the information contained in the response about the stimulus.
By performing such shuffling and computing the amount of information between the randomly paired labels, we can estimate the bias \citep{Optican1991}.
Using this in conjunction with a bias correction technique such as \ac{PT} (applied both when performing the original and the bootstrapped information calculation) allows us to estimate the residual bias which is unaccounted for by the \ac{PT} correction.
As described in \autoref{sec:info-bias} and by \citet{Panzeri1996}, this will typically lead to an overestimate of the bias.
However, since our residual bias will be significantly reduced beforehand due to the \ac{PT} technique, the overestimation is on a much smaller residual bias and impacts the results less.

% NvsI labels=balanced, with 20 bootstraps
% blanco v1  Bootstrap only   R=-0.3902  p=0.1215=1.215061e-01
% blanco v1  PT+bootstrap     R=+0.2973  p=0.2466=2.465723e-01
% blanco v1  QE+bootstrap     R=+0.1933  p=0.4573=4.572829e-01
% blanco v4  Bootstrap only   R=-0.8344  p=0.0000=1.386421e-06
% blanco v4  PT+bootstrap     R=-0.5180  p=0.0135=1.354094e-02
% blanco v4  QE+bootstrap     R=-0.4462  p=0.0374=3.740192e-02
% jack   v1  Bootstrap only   R=-0.9191  p=0.0000=1.538829e-09
% jack   v1  PT+bootstrap     R=-0.7222  p=0.0001=1.473099e-04
% jack   v1  QE+bootstrap     R=-0.8153  p=0.0000=3.786844e-06
% jack   v4  Bootstrap only   R=+0.1556  p=0.4679=4.679280e-01
% jack   v4  PT+bootstrap     R=+0.3521  p=0.0915=9.150274e-02
% jack   v4  QE+bootstrap     R=+0.2892  p=0.1705=1.705225e-01

\begin{figure}[htbp]
    \centering
    \hspace*{\fill}
    \subfloat[][\ac{M1} \ac{V1}.\label{fig:I_vs_invN_btsp_v1_blanco}]{%
        \includegraphics[scale=.45]{%
figs/info2/bias/ntrials_I_vs_invN_combindivpap_leg_blanco_v1_14chn_Gbalanced_1bins_of_527ms_btsp20.eps}}
    \hspace*{\fill}\hspace{.2cm}\hspace*{\fill}
    \subfloat[][\ac{M2} \ac{V1}.\label{fig:I_vs_invN_btsp_v1_jack}]{%
        \includegraphics[scale=.45]{%
figs/info2/bias/ntrials_I_vs_invN_combindivpap_blanco_v4_25chn_Gbalanced_1bins_of_527ms_btsp20.eps}}
    \hspace*{\fill}
    \\
    \hspace*{\fill}
    \subfloat[][\ac{M1} \ac{V4}.\label{fig:I_vs_invN_btsp_v4_blanco}]{%
        \includegraphics[scale=.45]{%
figs/info2/bias/ntrials_I_vs_invN_combindivpap_jack_v1_20chn_Gbalanced_1bins_of_527ms_btsp20.eps}}
    \hspace*{\fill}\hspace{.2cm}\hspace*{\fill}
    \subfloat[][\ac{M2} \ac{V4}.\label{fig:I_vs_invN_btsp_v4_jack}]{%
        \includegraphics[scale=.45]{%
figs/info2/bias/ntrials_I_vs_invN_combindivpap_jack_v4_18chn_Gbalanced_1bins_of_527ms_btsp20.eps}}
    \hspace*{\fill}
    \caption{\captionemph{Distribution of measured information, with bootstrap bias correction, as a function of $\nicefrac{1}{N}$, where $N$ is the number of trials in the session.}
Results are shown with bias correction either achieved solely from subtracting the information contained in response-shuffled copies of the data (bootstraps; grey circles), or by combining this with a more principled bias correction technique (\ac{PT}, red squares; \ac{QE}, blue diamonds).
}
    \label{fig:I_vs_invN_btsp}
\end{figure}

We find that using bootstrapping for the bias correction does indeed overestimate the bias, resulting in a negative correlation between information and $\nicefrac{1}{N}$.
This effect is particularly problematic for the \ac{V1} dataset of \ac{M2}, where the correlation was $R<-0.72$ ($p < 2 \times 10^{-4}$; see \autoref{fig:I_vs_invN_btsp_v1_jack}), and the \ac{V4} \ac{M1} dataset, where the correlation was $R<-0.44$ ($p<0.038$; see \autoref{fig:I_vs_invN_btsp_v4_blanco}) even with bias correction with \ac{PT} or \ac{QE} in addition to using bootstrapping.


%------------------------------------
\subsubsection{Grouping stimuli together}
\label{sec:pl_bias_grouping}

During the experiment, the subject is tasked with determining whether the stimulus contrast is higher or lower than the \SI{30}{\percent} sample stimulus presented at the start of each trial.
As a consequence of this, the subject does not need to learn exactly what stimulus is on screen, only whether the stimulus is in the half above or below \SI{30}{\percent} contrast.
For instance, since the target output is the same for \SI{31}{\percent} and \SI{32}{\percent} contrast stimuli, there is no need for the subject to discriminate between them, but there is motivation for the subject to learn to discriminate between these and the \SI{29}{\percent} contrast stimulus.

We refer to the subset of information which assists in decoding whether the stimulus was higher or lower than the \SI{30}{\percent} threshold as the task-pertinent information, and discuss this in \autoref{sec:task-info}.
For now, we will only consider the impact on the residual information bias when we restrict ourselves to measuring only the task-pertinent information.
In this calculation, we determine how much information the firing rate conveys about which group the stimulus is in (either higher or lower than \SI{30}{\percent}) instead of the information about precisely which of the \num{14} stimuli was on screen.
Grouping the stimuli together in this way should reduce the residual bias, since there are only two class labels, and \num{7} times as many trials per class.

% NvsI labels=class-group-balanced, with 0 bootstraps
% blanco v1  Uncorrected      R=+0.8772  p=0.0000=3.781467e-06
% blanco v1  PT               R=+0.4219  p=0.0916=9.160507e-02
% blanco v1  QE               R=+0.3199  p=0.2107=2.107306e-01
% blanco v4  Uncorrected      R=+0.7099  p=0.0002=2.147909e-04
% blanco v4  PT               R=-0.2121  p=0.3432=3.432192e-01
% blanco v4  QE               R=-0.1467  p=0.5147=5.146635e-01
% jack   v1  Uncorrected      R=-0.0987  p=0.6622=6.622243e-01
% jack   v1  PT               R=-0.5068  p=0.0161=1.608558e-02
% jack   v1  QE               R=-0.4722  p=0.0265=2.650028e-02
% jack   v4  Uncorrected      R=+0.5166  p=0.0098=9.753770e-03
% jack   v4  PT               R=+0.3385  p=0.1056=1.056310e-01
% jack   v4  QE               R=+0.3779  p=0.0687=6.868195e-02

\begin{figure}[htbp]
    \centering
    \hspace*{\fill}
    \subfloat[][\ac{M1} \ac{V1}.\label{fig:I_vs_invN_target-group_v1_blanco}]{%
        \includegraphics[scale=.45]{%
figs/info2/bias/ntrials_I_vs_invN_combindivpap_leg_blanco_v1_14chn_Gclass-group-balanced_1bins_of_527ms.eps}}
    \hspace*{\fill}\hspace{.2cm}\hspace*{\fill}
    \subfloat[][\ac{M2} \ac{V1}.\label{fig:I_vs_invN_target-group_v1_jack}]{%
        \includegraphics[scale=.45]{%
figs/info2/bias/ntrials_I_vs_invN_combindivpap_blanco_v4_25chn_Gclass-group-balanced_1bins_of_527ms.eps}}
    \hspace*{\fill}
    \\
    \hspace*{\fill}
    \subfloat[][\ac{M1} \ac{V4}.\label{fig:I_vs_invN_target-group_v4_blanco}]{%
        \includegraphics[scale=.45]{%
figs/info2/bias/ntrials_I_vs_invN_combindivpap_jack_v1_20chn_Gclass-group-balanced_1bins_of_527ms.eps}}
    \hspace*{\fill}\hspace{.2cm}\hspace*{\fill}
    \subfloat[][\ac{M2} \ac{V4}.\label{fig:I_vs_invN_target-group_v4_jack}]{%
        \includegraphics[scale=.45]{%
figs/info2/bias/ntrials_I_vs_invN_combindivpap_jack_v4_18chn_Gclass-group-balanced_1bins_of_527ms.eps}}
    \hspace*{\fill}
    \caption{\captionemph{Distribution of task-pertinent information measured as a function of $\nicefrac{1}{N}$, where $N$ is the number of trials in the session.}
Results are shown both without correcting for the finite measurement bias (grey circles), using \ac{PT} bias correction (red squares), and using \ac{QE} bias correction (blue diamonds).
}
    \label{fig:I_vs_invN_target-group}
\end{figure}

% jack   v1  PT               R=-0.5068  p=0.0161=1.608558e-02
% jack   v1  QE               R=-0.4722  p=0.0265=2.650028e-02

As anticipated, using only two stimulus classes to increase the number of trials per stimulus class greatly reduces the residual bias after \ac{PT} bias correction.
This is witnessed in the reduced correlation between estimated information and $\nicefrac{1}{N}$ seen in \autoref{fig:I_vs_invN_target-group}.
Here we find the magnitude of the correlations between $\nicefrac{1}{N}$ and $\I_\text{measured}$ are reduced and no longer significant, with the exception of \ac{M2} \ac{V1}, where $R<-0.47$ for both \ac{PT} and \ac{QE} ($p < 0.027$).


% NvsI labels=class-group-balanced, with 20 bootstraps
% blanco v1  Bootstrap only   R=+0.1094  p=0.6761=6.760702e-01
% blanco v1  PT+bootstrap     R=+0.2521  p=0.3289=3.289116e-01
% blanco v1  QE+bootstrap     R=+0.3561  p=0.1606=1.605954e-01
% blanco v4  Bootstrap only   R=-0.5102  p=0.0153=1.527968e-02
% blanco v4  PT+bootstrap     R=-0.3781  p=0.0828=8.275556e-02
% blanco v4  QE+bootstrap     R=-0.3782  p=0.0827=8.269350e-02
% jack   v1  Bootstrap only   R=-0.6472  p=0.0011=1.129821e-03
% jack   v1  PT+bootstrap     R=-0.5479  p=0.0083=8.294715e-03
% jack   v1  QE+bootstrap     R=-0.5987  p=0.0032=3.240925e-03
% jack   v4  Bootstrap only   R=+0.2816  p=0.1825=1.824586e-01
% jack   v4  PT+bootstrap     R=+0.3061  p=0.1457=1.456950e-01
% jack   v4  QE+bootstrap     R=+0.3352  p=0.1094=1.093618e-01

\begin{figure}[htbp]
    \centering
    \hspace*{\fill}
    \subfloat[][\ac{M1} \ac{V1}.\label{fig:I_vs_invN_target-group_btsp_v1_blanco}]{%
        \includegraphics[scale=.45]{%
figs/info2/bias/ntrials_I_vs_invN_combindivpap_leg_blanco_v1_14chn_Gclass-group-balanced_1bins_of_527ms_btsp20.eps}}
    \hspace*{\fill}\hspace{.2cm}\hspace*{\fill}
    \subfloat[][\ac{M2} \ac{V1}.\label{fig:I_vs_invN_target-group_btsp_v1_jack}]{%
        \includegraphics[scale=.45]{%
figs/info2/bias/ntrials_I_vs_invN_combindivpap_blanco_v4_25chn_Gclass-group-balanced_1bins_of_527ms_btsp20.eps}}
    \hspace*{\fill}
    \\
    \hspace*{\fill}
    \subfloat[][\ac{M1} \ac{V4}.\label{fig:I_vs_invN_target-group_btsp_v4_blanco}]{%
        \includegraphics[scale=.45]{%
figs/info2/bias/ntrials_I_vs_invN_combindivpap_jack_v1_20chn_Gclass-group-balanced_1bins_of_527ms_btsp20.eps}}
    \hspace*{\fill}\hspace{.2cm}\hspace*{\fill}
    \subfloat[][\ac{M2} \ac{V4}.\label{fig:I_vs_invN_target-group_btsp_v4_jack}]{%
        \includegraphics[scale=.45]{%
figs/info2/bias/ntrials_I_vs_invN_combindivpap_jack_v4_18chn_Gclass-group-balanced_1bins_of_527ms_btsp20.eps}}
    \hspace*{\fill}
    \caption{\captionemph{Distribution of task-pertinent information measured with bootstrap correction as a function of $\nicefrac{1}{N}$, where $N$ is the number of trials in the session.}
Results are shown both without correcting for the finite measurement bias (grey circles), using \ac{PT} bias correction (red squares), and using \ac{QE} bias correction (blue diamonds).
}
    \label{fig:I_vs_invN_target-group_btsp}
\end{figure}

% blanco v1  sess_num vs num_trials R=+0.2160  p=0.4049=4.049432e-01
% blanco v4  sess_num vs num_trials R=+0.1177  p=0.6020=6.020201e-01
% jack   v1  sess_num vs num_trials R=+0.4183  p=0.0527=5.271421e-02
% jack   v4  sess_num vs num_trials R=-0.1010  p=0.6388=6.387740e-01

We can also consider applying the bootstrap correction from \autoref{sec:pl_bootstrapping} in addition to reducing the number of stimulus labels to the two groups, shown in \autoref{fig:I_vs_invN_target-group_btsp}.
Using all three bias reduction techniques (including either \ac{PT} or \ac{QE}), the correlation for \ac{M2} \ac{V1} was still significant ($p < 0.008$), with $R<-0.54$.
We believe this correlation, which only causes a small change in magnitude of the measured information, is because subject \ac{M2} had a tendency to train for longer as the sessions progressed, but only with the stimulus in the retinotopic location for \ac{V1}.
For this dataset, there was a correlation between the number of sessions elapsed and the number of trials in the session of $R=+0.42$, which was noteworthy but did not exceed our criteria for significance ($p=0.053$).
None of the other datasets had a comparable level of correlation between the number of the session and how many trials were collected ($|R|<0.22$ with $p > 0.4$).

Using bootstrapping to correct for residual bias, the correlations between $\nicefrac{1}{N}$ and $\I_\text{measured}$ are slightly smaller for \ac{PT} than \ac{QE}, though the values are very similar and no claim can justifiably be made about which technique gives superior bias correction.
Since the \ac{PT} method is faster to compute, we chose to use this for the rest of our analysis.


%------------------------------------------------------------------------------
\subsection{Final results}
\label{sec:pl_initial_final}

After removing channels with sudden changes in firing rate between consecutive sessions, correcting for the change in stimulus class balance by subsampling, restricting our analysis to only consider task-pertinent information about the grouping of the stimulus (whether it exceeds \SI{30}{\percent} contrast), and using both the \ac{PT} method and bootstrapping to correct for the finite sampling bias on the measured information, we can present our results concerning the amount of information contained in the firing rate collected during stimulus presentation from one channel at a time.
These results are shown in \autoref{fig:info_sess_1x527_final}.

% blanco v1 1x527.00ms
% dr pt
% Loaded all the Channel data
% Making channel-wise mean plots
% A = [0.0263513164741615;0.0492889293157723;0.0075803143388116;0.0508811816684652;0.181817477043575;0.0728036089830557;0.129834989773168;0.0661952513062295;0.0621892062745833;-0.00867177560800424;-0.00881375156631541;-0.000908324100121279;0.0200203334844756;0.00418077875488221]
% B = [0.00344224728918875;0.0336040302684011;0.0233970080545657;0.0113474056683913;0.0295709625247833;0.04559457388278;0.0559826504777502;0.106617803353748;0.107535179757936;-0.00204472151589122;-0.00210168368898357;-0.00199088866176536;0.0353139645451868;0.00222400068322364]
% ttest A vs Gaussian distributed around 0
% n=14  h=1.000000  p=0.007382=7.381796e-03   mean = +0.046625+/-0.014708
% ttest B vs Gaussian distributed around 0
% n=14  h=1.000000  p=0.006384=6.384010e-03   mean = +0.032035+/-0.009871
% paired ttest (B-A) vs Gaussian distributed around 0
% n=14  h=0.000000  p=0.298243=2.982432e-01   delta = -0.014590+/-0.013465 = -31.291788%+/-28.915818%
% rule of thumb:  bandwidth=0.033135 bandwidth=0.022238
% same bandwidth bw = 0.011119 used for all cols
% YLIM4 = [-0.0278768744273044 0.200880599904564];
%
% jack v1 1x527.00ms
% dr pt
% Loaded all the Channel data
% Making channel-wise mean plots
% A = [0.234261876394671;0.244258770875817;0.253119355560483;0.252321488621297;0.263152107090386;0.0776136546137419;0.234176820567147;0.270455344041832;0.204247530979219;0.186820197640031;0.330754313457156;0.284278786257535;0.207208154880328;0.237082380942939;0.142624822526156;0.117505612586168;0.24076879605944;0.171910341429034;0.190791427465506;0.23839791717482]
% B = [0.267382526237437;0.314850628620244;0.372019102689498;0.320479276784213;0.346050692478794;0.0855907194301428;0.303656705456826;0.358222369097515;0.274134236266089;0.234856045872157;0.376928924925895;0.305946701986191;0.346550003749037;0.276845317550644;0.0628678657966066;0.189602067052242;0.311071685108738;0.25370066699549;0.204869541660158;0.248930255870547]
% ttest A vs Gaussian distributed around 0
% n=20  h=1.000000  p=0.000000=9.437089e-13   mean = +0.219087+/-0.013222
% ttest B vs Gaussian distributed around 0
% n=20  h=1.000000  p=0.000000=1.371835e-11   mean = +0.272728+/-0.019155
% paired ttest (B-A) vs Gaussian distributed around 0
% n=20  h=1.000000  p=0.000056=5.575874e-05   delta = +0.053640+/-0.010397 = +24.483499%+/-4.926184%
% rule of thumb:  bandwidth=0.033531 bandwidth=0.048577
% same bandwidth bw = 0.016766 used for all cols
% YLIM4 = [0.0314617598836777 0.408335030838824];
%
% blanco v4 1x527.00ms
% dr pt
% Loaded all the Channel data
% Making channel-wise mean plots
% A = [0.124379420736147;0.0680105400549035;0.0113903175984155;0.0842354305154156;0.112078755529876;0.0244515660835699;0.0120463387884198;-0.00311321051266301;0.199107396467802;0.00425727214051637;0.0918216678863861;0.00825279555130151;0.00100051631684192;0.0303046125040112;0.0102896954470163;0.0360698242657946;-0.00271069522065233;0.200258687708227;0.0520111002082111;0.0394563766285597;0.00742444680336003;0.00559675757124126;-0.00107963951971073;0.164378997862584;0.126326267998808]
% B = [0.128855275471535;0.0370267606692066;0.0191039799255678;0.0340572675788458;0.208430337904543;0.0158328441692709;0.00523091741002646;0.0101154545271706;0.210442309599915;0.00392932810073314;0.187264326212089;0.0470884685003672;0.0105670494241102;0.000147758068998901;0.00959884041155736;0.00602912566322126;0.0550594838807562;0.031876079284514;0.0679872007975889;0.109195758078887;0.0672766310669681;0.0610152398117247;0.00137323657222497;0.200373327450308;0.152106035032291]
% ttest A vs Gaussian distributed around 0
% n=25  h=1.000000  p=0.000207=2.067409e-04   mean = +0.056250+/-0.012875
% ttest B vs Gaussian distributed around 0
% n=25  h=1.000000  p=0.000097=9.679818e-05   mean = +0.067199+/-0.014398
% paired ttest (B-A) vs Gaussian distributed around 0
% n=25  h=0.000000  p=0.314715=3.147148e-01   delta = +0.010950+/-0.010663 = +19.465865%+/-18.999943%
% rule of thumb:  bandwidth=0.035096 bandwidth=0.039248
% same bandwidth bw = 0.017548 used for all cols
% YLIM4 = [-0.0244687625239208 0.231797861611172];
%
% jack v4 1x527.00ms
% dr pt
% Loaded all the Channel data
% Making channel-wise mean plots
% A = [0.0332347928500231;0.00692838691906155;0.00710946491673007;0.000136315350772127;0.0397484351682831;0.0527835600228851;0.0272081086523695;0.00305198735316775;0.00231284078159238;-0.00665026320837837;0.000964565694984376;0.0299409819635785;0.00255415087931287;-0.00132249571631523;0.00765476893492079;0.0290948543829351;-0.00280585886621814;0.00518731172187263]
% B = [0.0768076699705184;0.0593229144042642;0.00272109129353949;0.073760620063407;0.0948807545387933;0.215886138191114;0.116355246903916;0.0183276009114406;-0.00600566043816498;0.0124365699247398;0.0215646353035782;0.12519236507893;0.00548453901750598;0.00842432501039692;0.0443612292422077;0.200776668564082;0.0306734768138243;0.0664969828867837]
% ttest A vs Gaussian distributed around 0
% n=18  h=1.000000  p=0.004918=4.917723e-03   mean = +0.013174+/-0.004078
% ttest B vs Gaussian distributed around 0
% n=18  h=1.000000  p=0.000591=5.914894e-04   mean = +0.064859+/-0.015414
% paired ttest (B-A) vs Gaussian distributed around 0
% n=18  h=1.000000  p=0.000557=5.567694e-04   delta = +0.051685+/-0.012202 = +392.328164%+/-92.620292%
% rule of thumb:  bandwidth=0.009992 bandwidth=0.037763
% same bandwidth bw = 0.004996 used for all cols
% YLIM4 = [-0.0289039033483276 0.238139778331063];

\begin{figure}[htbp]%
    \centering
    \hspace*{\fill}
    \subfloat[][\ac{M1} \ac{V1}.\label{fig:info_sess_1x527_final_v1_blanco}]{%
        \includegraphics[scale=.45]{%
figs/info2/bias/I_sessionwise_blanco_v1_chmean14_s343-359_oc0_Gclass-group-balanced_1bins_of_527ms_dr_pt_btsp20_rmvet2_rmvms2_imscn_clhot.eps}}
    \hspace*{\fill}\hspace{.2cm}\hspace*{\fill}
    \subfloat[][\ac{M2} \ac{V1}.\label{fig:info_sess_1x527_final_v1_jack}]{%
        \includegraphics[scale=.45]{%
figs/info2/bias/I_sessionwise_jack_v1_chmean20_s51-72_oc0_Gclass-group-balanced_1bins_of_527ms_dr_pt_btsp20_rmvet2_rmvms2_imscn_clhot.eps}}
    \hspace*{\fill}
    \\
    \hspace*{\fill}
    \subfloat[][\ac{M1} \ac{V4}.\label{fig:info_sess_1x527_final_v4_blanco}]{%
        \includegraphics[scale=.45]{%
figs/info2/bias/I_sessionwise_blanco_v4_chmean25_s307,308,311,313,314,317,318,320,321,329-341_oc0_Gclass-group-balanced_1bins_of_527ms_dr_pt_btsp20_rmvet2_rmvms2_imscn_clhot.eps}}
    \hspace*{\fill}\hspace{.2cm}\hspace*{\fill}
    \subfloat[][\ac{M2} \ac{V4}.\label{fig:info_sess_1x527_final_v4_jack}]{%
        \includegraphics[scale=.45]{%
figs/info2/bias/I_sessionwise_jack_v4_chmean18_s24,25,27-38,40-49_oc0_Gclass-group-balanced_1bins_of_527ms_dr_pt_btsp20_rmvet2_rmvms2_imscn_clhot.eps}}
    \hspace*{\fill}
    \caption{\captionemph{Task-pertinent information about the stimulus contained in the firing rate during \SI{527}{\milli\second} of stimulus presentation.}
Only task-pertinent information (whether the stimulus was higher or lower than \SI{30}{\percent} contrast) was included.
The finite sampling bias was corrected for by using both the \ac{PT} method and by subtracting the average of \num{20} bootstrapped information measurements obtained by randomly pairing responses and stimulus labels.
Main panels: the average over channels (\protect\subref{fig:info_sess_1x527_final_v1_blanco}~\num{14} channels, \protect\subref{fig:info_sess_1x527_final_v1_jack}~\num{20} channels, \protect\subref{fig:info_sess_1x527_final_v4_blanco}~\num{25} channels, \protect\subref{fig:info_sess_1x527_final_v4_jack}~\num{18} channels) with standard error across channels indicated by the shaded region.
Right hand panels: distribution over channels of the information contained in the first three sessions (\zonename{A}) versus last three sessions (\zonename{B}), with mean (solid black line) and median (dashed green line) over channels indicated.
The stimulus class imbalance was corrected using subsampling, as described in \autoref{sec:pl_class_imbalance}.
}
    \label{fig:info_sess_1x527_final}
\end{figure}

We found there was no significant change during training (comparing the first with the last three experimental sessions) in the information conveyed by the recording channels of \ac{V1} for \ac{M1} ($p=0.30$).
However there was for \ac{M2} ($p < 6 \times 10^{-5}$), with an increase of \SI{+0.054\pm0.010}{bits} from \zonename{A} to \zonename{B}.
For brain region \ac{V4}, there was also no significant change during training for \ac{M1} ($p=0.31$), but there was an increase of \SI{+0.052\pm0.012}{bits} for \ac{M2} ($p=0.00056$).


%==============================================================================
\section{Task-pertinent and nonpertinent information}
\label{sec:task-info}

Previously, we were computing the amount of information in the neural response (the firing rate over the stimulus presentation period) about the identity of the presented stimulus.
Computing the mutual information between these two tells us how much information we gain about which stimulus was presented when we are told how many spikes were detected on a given electrode contact.
However, the objective the subject is tasked with --- to identify whether the presented stimulus has a contrast higher or lower than the pedestal contrast --- is somewhat different.
To achieve this goal, it is not necessary to distinguish exactly which stimulus was presented.

We can separate the information given by the neural response into two parts: task-pertinent and task-nonpertinent information.
The task-pertinent information helps one tell whether the stimulus was in the half above or below the pedestal contrast of \SI{30}{\percent}.
However we also gain information about exactly which stimuli within the upper and lower half of the set of contrasts is more likely to have been presented.
Although this information helps one distinguish which stimulus was presented (and hence presumably helps the subject perceive the stimuli more accurately), it is not pertinent to the subject's task.

For instance, any information which helps one discriminate between whether a \SI{29}{\percent} or \SI{31}{\percent} contrast stimulus was more likely to have been presented is pertinent to the task.
Whereas if we gain information about the stimulus which updates the probability of it having a \SI{28}{\percent} versus a \SI{29}{\percent} contrast without changing the probability that it was one of \SI{28}{\percent} or \SI{29}{\percent} contrast, this is not pertinent to the task.

Although it is only a binary response (a choice of one of two saccade targets), it is still possible for the behavioural response to encode both task-pertinent and task-nonpertinent information.
For instance, let us assume that the subject performs the task at a rate higher than chance.
Then, a behavioural response of ``\textemph{test contrast is lower}'' tells us a contrast in the lower half was more likely to have been presented, providing task-pertinent information.
Additionally, since contrasts further from the \SI{30}{\percent} threshold are easier for the subject, we can empirically observe that a response of ``\textemph{test contrast is lower}'' is more likely to be elicited if the contrast was further below the threshold than if it was close to the threshold.\footnote{This trivially follows using Bayes' rule.}
This difference in relative likelihood supplies us with additional, task-nonpertinent, information about which stimulus was presented.


\subsection{Methods for decomposing task-pertinent information}
\label{sec:task-info-methods}

First, we computed the total information contained in the neural response as before, using the total spikes recorded by a single channel over \SI{527}{\milli\second} of stimulus presentation as the response on each trial.
The finite sampling bias on the estimated information was corrected for using the \ac{PT} method, and further residual bias removed using bootstrapping (see \autoref{sec:pl_bootstrapping}).
Stimulus class imbalance was corrected for using subsampling, as described in \autoref{sec:pl_class_imbalance}.

The amount of task-pertinent information contained in the response was estimated by shuffling the stimulus labels against the responses, whilst preserving which side of \SI{30}{\percent} contrast the stimulus label was on.
This destroys any information about the stimulus beyond that pertinent to the task --- choosing whether the stimulus was above or below \SI{30}{\percent} contrast --- but maintains the number of class labels and samples per class.
Consequently, the bias on the information will be similar to that when computing the total information, and the results will be more directly comparable.\footnote{However, the bias will not be the same for the two information values because after shuffling the range of possible values for the response will have increased. Consequently, it is still necessary to do individual bias correction with \ac{PT} and bootstrapping on each of the information computations.}
We repeated this with \num{20} permutations, each with their own set of \num{20} bootstraps, and took the average over them.
The amount of task-nonpertinent information was estimated by subtracting the task-pertinent information (found with shuffling) from the total information (found without shuffling).

To compute the proportion of information in the response which was pertinent to the task, we divided the estimated task-pertinent information by the total information (after correcting for the bias on each estimate).
To prevent channels whose responses contain negligible information about the stimulus contaminating the results with anomalously large (or small) outliers after the division, we excluded any channels whose total information was less than \num{1.5} times the standard deviation across the bootstrapped information values.
This threshold was determined empirically; \num{3} standard deviations unnecessarily removed too many channels, whereas \num{1} standard deviation retained channels with too little information whose task-pertinence proportion was unstable (at or beyond $0$ and $1$), which increased the overall variance.
Approximately half the channels were removed with this step (\ac{M1} \ac{V1}: $14\to4$, \ac{M2} \ac{V1}: $20\to20$, \ac{M1} \ac{V4}: $25\to13$, \ac{M2} \ac{V4}: $18\to7$).
Additionally, the proportional information reported for each channel was capped at $0$ and $1$ before taking the average over channels.
Although it is impossible for the proportion of information which is task-pertinent to fall outside the range $[0, 1]$, our measurements of the information are fuzzy.
In particular, this can arise from subtracting the average over bootstraps, since the bootstraps are stochastic samples and we subtract different bootstraps from the total and task-pertinent information.
With the \num{1.5} standard deviation threshold, we observed that only a single channel fell outside this cap.

To quantify the change over time, we again compared the information averaged over the first three sessions (\zonename{A}) with the information over the last three sessions (\zonename{B}).
For the relative information, only channels which had a significant amount of total information (exceeding \num{1.5} times the standard deviation over bootstraps) for both the average over \zonename{A} and also over \zonename{B} were included.
This step was included to ensure \zonename{A} and \zonename{B} were directly comparable; a paired $t$-test was used to compare the information at \zonename{A} with \zonename{B}.

Similarly, we considered the amount of information about the stimulus contained in the behavioural response of the animal --- a saccade to one of two targets indicating whether the subject believed the contrast to be higher or lower than \SI{30}{\percent} (two forced-choice).
The same procedure was used to decompose the total information in this response into task-pertinent and nonpertinent components, and find the proportion of the information which was task-pertinent.


\subsection{Results for \acs{V1} information pertinence}

We separated the total information about the stimulus contained in the neural response into task-pertinent and task-nonpertinent components as described in \autoref{sec:task-info-methods}.
For \ac{M1}, there was a non-significant decrease in the total information, task-pertinent information, and the task-nonpertinent information between \zonename{A} and \zonename{B} (paired Student's $t$-test; $p=0.20$, $p=0.38$, and $p=0.13$ respectively), as shown in \autoref{fig:info_taskpertinent_v1_ch_blanco}.
Correspondingly, there was no significant change in the fraction of the total information which was task-pertinent either ($p=0.60$; see \autoref{fig:info_taskpertinent_rel_v1_ch_blanco}).

For \ac{M2}, there was a small, non-significant, decrease in the task-nonpertinent information between \zonename{A} and \zonename{B} (\SI{-0.010\pm0.007}{bits}, $p=0.16$), but there was a significant increase in the task-pertinent information (\SI{+0.060\pm0.011}{bits}, $p = 2 \times 10^{-5}$; see \autoref{fig:info_taskpertinent_v1_ch_jack}).
Together, these give a combined increase in the total information of \SI{+0.050\pm0.015}{bits} ($p=0.004$).
Since the task-nonpertinent information was stable while the task-pertinent information increased with training, the proportion of encoded information which was task-pertinent increased by \SI{+7.0\pm1.3}{\percent} ($p = 4 \times 10^{-5}$), as shown in \autoref{fig:info_taskpertinent_rel_v1_ch_jack}.

% blanco v1 1x527.00ms
% dr pt
% For Total Info (bits)
% n=14  h=0.000000  p=0.205484=2.054842e-01   delta = -0.026854+/-0.020149 = -29.290339%+/-22.139211%
% For Task-pertinent Info (bits)
% n=14  h=0.000000  p=0.375025=3.750246e-01   delta = -0.010713+/-0.011662 = -25.593377%+/-27.886183%
% For Task-nonpertinent Info (bits)
% n=14  h=0.000000  p=0.133354=1.333535e-01   delta = -0.016142+/-0.010081 = -32.396084%+/-20.293906%
% selected bw  :  bandwidth=0.011217
%
% For Task-pertinent Info (%)
% n=4  h=0.000000  p=0.596176=5.961759e-01   delta = +4.414025+/-7.470531 = +10.618742%+/-533.852117%
% For Task-nonpertinent Info (%)
% n=4  h=0.000000  p=0.596176=5.961759e-01   delta = -4.414025+/-7.470531 = -7.554155%+/-533.702687%
% selected bw  :  bandwidth=2.813857
%
%
% jack v1 1x527.00ms
% dr pt
% For Total Info (bits)
% n=20  h=1.000000  p=0.003762=3.761940e-03   delta = +0.049989+/-0.015146 = +11.458962%+/-4.411886%
% For Task-pertinent Info (bits)
% n=20  h=1.000000  p=0.000020=2.022440e-05   delta = +0.060332+/-0.010732 = +28.392210%+/-5.205318%
% For Task-nonpertinent Info (bits)
% n=20  h=0.000000  p=0.162219=1.622189e-01   delta = -0.010343+/-0.007113 = -4.622742%+/-3.554708%
% selected bw  :  bandwidth=0.015976
%
% For Task-pertinent Info (%)
% n=20  h=1.000000  p=0.000036=3.596357e-05   delta = +7.049025+/-1.315612 = +14.317851%+/-97.552405%
% For Task-nonpertinent Info (%)
% n=20  h=1.000000  p=0.000036=3.596357e-05   delta = -7.049025+/-1.315612 = -13.884894%+/-97.550225%
% selected bw  :  bandwidth=1.236527

\begin{figure}[htbp]%
    \centering
    \hspace*{\fill}
    \subfloat[][\ac{M1} \ac{V1} Information.\label{fig:info_taskpertinent_v1_ch_blanco}]{%
        \includegraphics[scale=.45]{%
figs/info2/task-pertinent/I_sessionwise_blanco_v1_chmean14_s343-359_oc0_Gclass-shuffled-balanced_1bins_of_527ms_dr_pt_btsp20_rmvet2_rmvms2_info_leg.eps}}
    \hspace*{\fill}\hspace{.2cm}\hspace*{\fill}
    \subfloat[][\ac{M2} \ac{V1} Information.\label{fig:info_taskpertinent_v1_ch_jack}]{%
        \includegraphics[scale=.45]{%
figs/info2/task-pertinent/I_sessionwise_jack_v1_chmean20_s51-72_oc0_Gclass-shuffled-balanced_1bins_of_527ms_dr_pt_btsp20_rmvet2_rmvms2_info.eps}}
    \hspace*{\fill}
    \\
    \hspace*{\fill}
    \subfloat[][\ac{M1} \ac{V1} Relative information.\label{fig:info_taskpertinent_rel_v1_ch_blanco}]{%
        \includegraphics[scale=.45]{%
figs/info2/task-pertinent/I_sessionwise_blanco_v1_chmean14_s343-359_oc0_Gclass-shuffled-balanced_1bins_of_527ms_dr_pt_btsp20_rmvet2_rmvms2_relative-info.eps}}
    \hspace*{\fill}\hspace{.2cm}\hspace*{\fill}
    \subfloat[][\ac{M2} \ac{V1} Relative information.\label{fig:info_taskpertinent_rel_v1_ch_jack}]{%
        \includegraphics[scale=.45]{%
figs/info2/task-pertinent/I_sessionwise_jack_v1_chmean20_s51-72_oc0_Gclass-shuffled-balanced_1bins_of_527ms_dr_pt_btsp20_rmvet2_rmvms2_relative-info.eps}}
    \hspace*{\fill}
    \caption{\captionemph{Breakdown of task-pertinent and nonpertinent information contained in \ac{V1} recording channels.}
In \protect\subref{fig:info_taskpertinent_v1_ch_blanco} and \protect\subref{fig:info_taskpertinent_v1_ch_jack}, the total information about the stimulus (grey), task-pertinent information (green), and task-nonpertinent (red) contained in each of \num{14} and \num{20} channels respectively.
In \protect\subref{fig:info_taskpertinent_rel_v1_ch_blanco} and \protect\subref{fig:info_taskpertinent_rel_v1_ch_jack}, the relative information about the stimulus which is task-pertinent (green) and task-nonpertinent (red) contained in channels with a significant amount of total information (\num{4} and \num{20} respectively).
Main panels: across training sessions, the average information over channels, with standard error across channels indicated by the shaded region.
Right hand panels: distribution over channels of the information (or relative information) in the first three sessions (\zonename{A}) versus last three sessions (\zonename{B}), with mean (solid black line) and median (dashed blue line) over channels indicated.
The violin plot shows a Gaussian kernel density, using a bandwidth determined as described in \autoref{sec:info-methods}.
The \ac{PT} bias correction method was used, with the residual bias further reduced using bootstrapping (see \autoref{sec:pl_bootstrapping}).
The stimulus class imbalance was corrected using subsampling, as described in \autoref{sec:pl_class_imbalance}.
    \label{fig:info_taskpertinent_v1_ch}
}
\end{figure}


Over the same period of training, we examined the decomposition of the information contained in the behavioural response of the experimental subject.
Similar trends were found for \ac{M1} and \ac{M2}, as shown in \autoref{fig:info_taskpertinent_v1_behav}.
There was a vast increase in the amount of task-pertinent information between \zonename{A} and \zonename{B} of \SI{+0.32}{bits} and \SI{+0.34}{bits} respectively, which more than tripled the amount of task-pertinent information given in the subject's response between the beginning and end of the experiment.
The task-nonpertinent information in the response increased by a modest \SI{+0.06}{bits} and \SI{+0.03}{bits} respectively, which is a relative increase of \SI{71}{\percent} and \SI{32}{\percent} from \zonename{A} to \zonename{B}.
Collectively, this meant the proportion of information which was task-pertinent increased from near \SI{60}{\percent} to near \SI{80}{\percent} for both subjects, as shown in \autoref{fig:info_taskpertinent_rel_v1_behav_blanco} and \subref{fig:info_taskpertinent_rel_v1_behav_jack}.

% Behavioural info for blanco v1
% For Total Info (bits)
% n=1  h=NaN  p=NaN=NaN   delta = +0.381066+/-0.000000 = +172.797622%+/-0.000000%
% For Task-pertinent Info (bits)
% n=1  h=NaN  p=NaN=NaN   delta = +0.323136+/-0.000000 = +230.776949%+/-0.000000%
% For Task-nonpertinent Info (bits)
% n=1  h=NaN  p=NaN=NaN   delta = +0.057930+/-0.000000 = +71.956869%+/-0.000000%
% For Task-pertinent Info (%)
% n=1  h=NaN  p=NaN=NaN   delta = +13.494701+/-0.000000 = +21.253604%+/-0.000000%
% For Task-nonpertinent Info (%)
% n=1  h=NaN  p=NaN=NaN   delta = -13.494701+/-0.000000 = -36.965408%+/-0.000000%
%
% Behavioural info for jack v1
% For Total Info (bits)
% n=1  h=NaN  p=NaN=NaN   delta = +0.366698+/-0.000000 = +139.268115%+/-0.000000%
% For Task-pertinent Info (bits)
% n=1  h=NaN  p=NaN=NaN   delta = +0.335353+/-0.000000 = +201.184738%+/-0.000000%
% For Task-nonpertinent Info (bits)
% n=1  h=NaN  p=NaN=NaN   delta = +0.031345+/-0.000000 = +32.443197%+/-0.000000%
% For Task-pertinent Info (%)
% n=1  h=NaN  p=NaN=NaN   delta = +16.382229+/-0.000000 = +25.877507%+/-0.000000%
% For Task-nonpertinent Info (%)
% n=1  h=NaN  p=NaN=NaN   delta = -16.382229+/-0.000000 = -44.646533%+/-0.000000%

\begin{figure}[htbp]%
    \centering
    \hspace*{\fill}
    \subfloat[][\ac{M1} \ac{V1} Information.\label{fig:info_taskpertinent_v1_behav_blanco}]{%
        \includegraphics[scale=.45]{%
figs/info2/task-pertinent/I_behav_blanco_v1_s343-359_Gclass-shuffled-balanced_dr_pt_btsp20_rmvet2_info.eps}}
    \hspace*{\fill}\hspace{.2cm}\hspace*{\fill}
    \subfloat[][\ac{M2} \ac{V1} Information.\label{fig:info_taskpertinent_v1_behav_jack}]{%
        \includegraphics[scale=.45]{%
figs/info2/task-pertinent/I_behav_jack_v1_s51-72_Gclass-shuffled-balanced_dr_pt_btsp20_rmvet2_info.eps}}
    \hspace*{\fill}
    \\
    \hspace*{\fill}
    \subfloat[][\ac{M1} \ac{V1} Relative information.\label{fig:info_taskpertinent_rel_v1_behav_blanco}]{%
        \includegraphics[scale=.45]{%
figs/info2/task-pertinent/I_behav_blanco_v1_s343-359_Gclass-shuffled-balanced_dr_pt_btsp20_rmvet2_relative-info.eps}}
    \hspace*{\fill}\hspace{.2cm}\hspace*{\fill}
    \subfloat[][\ac{M2} \ac{V1} Relative information.\label{fig:info_taskpertinent_rel_v1_behav_jack}]{%
        \includegraphics[scale=.45]{%
figs/info2/task-pertinent/I_behav_jack_v1_s51-72_Gclass-shuffled-balanced_dr_pt_btsp20_rmvet2_relative-info.eps}}
    \hspace*{\fill}
    \caption{\captionemph{Breakdown of task-pertinent and nonpertinent information contained in behavioural responses during \ac{V1} recording.}
In \protect\subref{fig:info_taskpertinent_v1_behav_blanco} and \protect\subref{fig:info_taskpertinent_v1_behav_jack}, the total information about the stimulus (grey), task-pertinent information (green), and task-nonpertinent (red) contained the behavioural response on each trial.
In \protect\subref{fig:info_taskpertinent_rel_v1_behav_blanco} and \protect\subref{fig:info_taskpertinent_rel_v1_behav_jack}, the relative information about the stimulus which is task-pertinent (green) and task-nonpertinent (red).
The \ac{PT} bias correction method was used, with the residual bias further reduced using bootstrapping (see \autoref{sec:pl_bootstrapping}).
The stimulus class imbalance was corrected using subsampling, as described in \autoref{sec:pl_class_imbalance}.
    \label{fig:info_taskpertinent_v1_behav}
}
\end{figure}


\subsection{Results for \acs{V4} information pertinence}

For \ac{M1}, we found no significant change in the total, task-pertinent, or task-nonpertinent information about the stimulus encoded in \ac{V4} channels ($p=0.48$, $p=0.19$, and $p=0.94$ respectively; see \autoref{fig:info_taskpertinent_v4_ch_blanco}).
There was a small, but non-significant, increase of \SI{+0.014\pm0.010}{bits} in the average task-pertinent information between \zonename{A} and \zonename{B}.
Correspondingly, there was no significant change in the fraction of information which was task-pertinent either ($p=0.61$; see \autoref{fig:info_taskpertinent_rel_v4_ch_blanco}).

On the other hand, for \ac{M2} there was a significant ($p=0.0005$) increase in task-pertinent information from \zonename{A} to \zonename{B}, increasing by \SI{+0.054\pm0.013}{bits}, which is approximately \num{5} times its initial value.
Meanwhile, the amount of task-nonpertinent information did not notably change (\SI{+0.008\pm0.008}{bits}, $p=0.32$).
Accumulatively, these effects produced an increase in the total information of \SI{+0.062\pm0.018}{bits}, which was significant ($p=0.003$).
% Together, these effects accumulatively produced a significant increase in total information of (\num{+0.062} \num{\pm0.018})\hspace{.16667em}bits ($p=0.003$).
As a consequence of this, the proportion of information which is task-pertinent increased from under \SI{20}{\percent} to around \SI{50}{\percent}, with a swing from \zonename{A} to \zonename{B} of \SI{+33\pm3}{\percent} ($p=5 \times 10^{-5}$).

Most information is initially not pertinent to the task, which may relate to most channels initially being inhibited by sample stimulus, as described in \autoref{sec:pl_dprime_v4} (\autoref{fig:dprime_v4_jack}).
The largest increase in task-pertinent information occurs on the 5th experimental session.
This corresponds to a session where several channels changed from stimulus-inhibited (negative $d'$) to stimulus-excited (positive $d'$).

% blanco v4 1x527.00ms
% dr pt
% For Total Info (bits)
% n=25  h=0.000000  p=0.480089=4.800887e-01   delta = +0.014921+/-0.020800 = +12.563164%+/-17.729269%
% For Task-pertinent Info (bits)
% n=25  h=0.000000  p=0.192543=1.925430e-01   delta = +0.014002+/-0.010443 = +26.745305%+/-19.984138%
% For Task-nonpertinent Info (bits)
% n=25  h=0.000000  p=0.941701=9.417010e-01   delta = +0.000919+/-0.012434 = +1.383585%+/-18.794865%
% selected bw  :  bandwidth=0.016494
%
% For Task-pertinent Info (%)
% n=13  h=0.000000  p=0.613049=6.130492e-01   delta = -2.717323+/-5.233468 = -5.561730%+/-601.681813%
% For Task-nonpertinent Info (%)
% n=13  h=0.000000  p=0.613049=6.130492e-01   delta = +2.717323+/-5.233468 = +5.313240%+/-601.673483%
% selected bw  :  bandwidth=3.203598
%
% jack v4 1x527.00ms
% dr pt
% For Total Info (bits)
% n=18  h=1.000000  p=0.002821=2.821313e-03   delta = +0.062224+/-0.017844 = +108.817777%+/-31.227202%
% For Task-pertinent Info (bits)
% n=18  h=1.000000  p=0.000527=5.272562e-04   delta = +0.054160+/-0.012710 = +505.870407%+/-118.716410%
% For Task-nonpertinent Info (bits)
% n=18  h=0.000000  p=0.321069=3.210688e-01   delta = +0.008065+/-0.007890 = +17.352317%+/-17.000845%
% selected bw  :  bandwidth=0.004437
%
% For Task-pertinent Info (%)
% n=7  h=1.000000  p=0.000051=5.059743e-05   delta = +33.408297+/-3.262665 = +136.706215%+/-360.592804%
% For Task-nonpertinent Info (%)
% n=7  h=1.000000  p=0.000051=5.059743e-05   delta = -33.408297+/-3.262665 = -44.213106%+/-360.371435%
% selected bw  :  bandwidth=2.699929

\begin{figure}[htbp]%
    \centering
    \hspace*{\fill}
    \subfloat[][\ac{M1} \ac{V4} Information.\label{fig:info_taskpertinent_v4_ch_blanco}]{%
        \includegraphics[scale=.45]{%
figs/info2/task-pertinent/I_sessionwise_blanco_v4_chmean25_s307,308,311,313,314,317,318,320,321,329-341_oc0_Gclass-shuffled-balanced_1bins_of_527ms_dr_pt_btsp20_rmvet2_rmvms2_info_leg.eps}}
    \hspace*{\fill}\hspace{.2cm}\hspace*{\fill}
    \subfloat[][\ac{M2} \ac{V4} Information.\label{fig:info_taskpertinent_v4_ch_jack}]{%
        \includegraphics[scale=.45]{%
figs/info2/task-pertinent/I_sessionwise_jack_v4_chmean18_s24,25,27-38,40-49_oc0_Gclass-shuffled-balanced_1bins_of_527ms_dr_pt_btsp20_rmvet2_rmvms2_info.eps}}
    \hspace*{\fill}
    \\
    \hspace*{\fill}
    \subfloat[][\ac{M1} \ac{V4} Relative information.\label{fig:info_taskpertinent_rel_v4_ch_blanco}]{%
        \includegraphics[scale=.45]{%
figs/info2/task-pertinent/I_sessionwise_blanco_v4_chmean25_s307,308,311,313,314,317,318,320,321,329-341_oc0_Gclass-shuffled-balanced_1bins_of_527ms_dr_pt_btsp20_rmvet2_rmvms2_relative-info_leg.eps}}
    \hspace*{\fill}\hspace{.2cm}\hspace*{\fill}
    \subfloat[][\ac{M2} \ac{V4} Relative information.\label{fig:info_taskpertinent_rel_v4_ch_jack}]{%
        \includegraphics[scale=.45]{%
figs/info2/task-pertinent/I_sessionwise_jack_v4_chmean18_s24,25,27-38,40-49_oc0_Gclass-shuffled-balanced_1bins_of_527ms_dr_pt_btsp20_rmvet2_rmvms2_relative-info.eps}}
    \hspace*{\fill}
    \caption{\captionemph{Breakdown of task-pertinent and nonpertinent information contained in \ac{V4} recording channels.}
In \protect\subref{fig:info_taskpertinent_v4_ch_blanco} and \protect\subref{fig:info_taskpertinent_v4_ch_jack}, the total information about the stimulus (grey), task-pertinent information (green), and task-nonpertinent (red) contained in each of \num{25} and \num{18} channels respectively.
In \protect\subref{fig:info_taskpertinent_rel_v4_ch_blanco} and \protect\subref{fig:info_taskpertinent_rel_v4_ch_jack}, the relative information about the stimulus which is task-pertinent (green) and task-nonpertinent (red) contained in channels with a significant amount of total information (\num{13} and \num{7} respectively).
Main panels: across training sessions, the average information over channels, with standard error across channels indicated by the shaded region.
Right hand panels: distribution over channels of the information (or relative information) in the first three sessions (\zonename{A}) versus last three sessions (\zonename{B}), with mean (solid black line) and median (dashed blue line) over channels indicated.
The violin plot shows a Gaussian kernel density, using a bandwidth determined as described in \autoref{sec:info-methods}.
The \ac{PT} bias correction method was used, with the residual bias further reduced using bootstrapping (see \autoref{sec:pl_bootstrapping}).
The stimulus class imbalance was corrected using subsampling, as described in \autoref{sec:pl_class_imbalance}.
    \label{fig:info_taskpertinent_v4_ch}
}
\end{figure}


The behavioural information for \ac{V4} training sessions shows a similar trend to the behavioural information during \ac{V1} training sessions.
Namely, there is a larger increase in task-pertinent information and a smaller increase in task-nonpertinent information.

For \ac{M1}, the subject began training with a decent initial performance, and correspondingly a decent amount of task-pertinent information is given by the behavioural response, as shown in \autoref{fig:info_taskpertinent_v4_behav_blanco}.
Indeed, for \ac{M1} around \SI{75}{\percent} of the information contained in the behavioural response is task-pertinent at the beginning of training, and this percentage does not notably change throughout training (see \autoref{fig:info_taskpertinent_rel_v4_behav_blanco}).
The total information encoded in the neural response does increase with training, but most of this arises from an increase in task-pertinent information (\SI{+0.128}{bits}) as opposed to nonpertinent information (\SI{+0.034}{bits}).

Compared to \ac{M1}, subject \ac{M2} began training with very poor performance on the task.
Correspondingly, the behavioural response initially provides less information about which stimulus was presented (see \autoref{fig:info_taskpertinent_v4_behav_jack}) --- and over \SI{80}{\percent} of that is not pertinent to the task (see \autoref{fig:info_taskpertinent_rel_v4_behav_jack}).
The amount of task-pertinent information given by the behavioural response increases by \SI{0.238}{bits} from \zonename{A} to \zonename{B} (a 26-fold increase), whilst the task-nonpertinent information doubles, only increasing by \SI{0.057}{bits}.
Consequently, there is a massive swing of \SI{+54}{\percent} in the fraction of information encoded in the behavioural response which is task-pertinent.

% Behavioural info for blanco v4
% For Total Info (bits)
% n=1  h=NaN  p=NaN=NaN   delta = +0.162043+/-0.000000 = +44.813597%+/-0.000000%
% For Task-pertinent Info (bits)
% n=1  h=NaN  p=NaN=NaN   delta = +0.127796+/-0.000000 = +47.636289%+/-0.000000%
% For Task-nonpertinent Info (bits)
% n=1  h=NaN  p=NaN=NaN   delta = +0.034247+/-0.000000 = +36.698947%+/-0.000000%
% For Task-pertinent Info (%)
% n=1  h=NaN  p=NaN=NaN   delta = +1.446146+/-0.000000 = +1.949190%+/-0.000000%
% For Task-nonpertinent Info (%)
% n=1  h=NaN  p=NaN=NaN   delta = -1.446146+/-0.000000 = -5.603514%+/-0.000000%
%
% Behavioural info for jack v4
% For Total Info (bits)
% n=1  h=NaN  p=NaN=NaN   delta = +0.294209+/-0.000000 = +485.223076%+/-0.000000%
% For Task-pertinent Info (bits)
% n=1  h=NaN  p=NaN=NaN   delta = +0.237539+/-0.000000 = +2537.475948%+/-0.000000%
% For Task-nonpertinent Info (bits)
% n=1  h=NaN  p=NaN=NaN   delta = +0.056669+/-0.000000 = +110.525845%+/-0.000000%
% For Task-pertinent Info (%)
% n=1  h=NaN  p=NaN=NaN   delta = +54.141348+/-0.000000 = +350.678733%+/-0.000000%
% For Task-nonpertinent Info (%)
% n=1  h=NaN  p=NaN=NaN   delta = -54.141348+/-0.000000 = -64.026394%+/-0.000000%

\begin{figure}[htbp]%
    \centering
    \hspace*{\fill}
    \subfloat[][\ac{M1} \ac{V4} Information.\label{fig:info_taskpertinent_v4_behav_blanco}]{%
        \includegraphics[scale=.45]{%
figs/info2/task-pertinent/I_behav_blanco_v4_s307,308,311,313,314,317,318,320,321,329-341_Gclass-shuffled-balanced_dr_pt_btsp20_rmvet2_info.eps}}
    \hspace*{\fill}\hspace{.2cm}\hspace*{\fill}
    \subfloat[][\ac{M2} \ac{V4} Information.\label{fig:info_taskpertinent_v4_behav_jack}]{%
        \includegraphics[scale=.45]{%
figs/info2/task-pertinent/I_behav_jack_v4_s24,25,27-38,40-49_Gclass-shuffled-balanced_dr_pt_btsp20_rmvet2_info.eps}}
    \hspace*{\fill}
    \\
    \hspace*{\fill}
    \subfloat[][\ac{M1} \ac{V4} Relative information.\label{fig:info_taskpertinent_rel_v4_behav_blanco}]{%
        \includegraphics[scale=.45]{%
figs/info2/task-pertinent/I_behav_blanco_v4_s307,308,311,313,314,317,318,320,321,329-341_Gclass-shuffled-balanced_dr_pt_btsp20_rmvet2_relative-info.eps}}
    \hspace*{\fill}\hspace{.2cm}\hspace*{\fill}
    \subfloat[][\ac{M2} \ac{V4} Relative information.\label{fig:info_taskpertinent_rel_v4_behav_jack}]{%
        \includegraphics[scale=.45]{%
figs/info2/task-pertinent/I_behav_jack_v4_s24,25,27-38,40-49_Gclass-shuffled-balanced_dr_pt_btsp20_rmvet2_relative-info.eps}}
    \hspace*{\fill}
    \caption{\captionemph{Breakdown of task-pertinent and nonpertinent information contained in behavioural responses during \ac{V4} recording.}
In \protect\subref{fig:info_taskpertinent_v4_behav_blanco} and \protect\subref{fig:info_taskpertinent_v4_behav_jack}, the total information about the stimulus (grey), task-pertinent information (green), and task-nonpertinent (red) contained the behavioural response on each trial.
In \protect\subref{fig:info_taskpertinent_rel_v4_behav_blanco} and \protect\subref{fig:info_taskpertinent_rel_v4_behav_jack}, the relative information about the stimulus which is task-pertinent (green) and task-nonpertinent (red).
The \ac{PT} bias correction method was used, with the residual bias further reduced using bootstrapping (see \autoref{sec:pl_bootstrapping}).
The stimulus class imbalance was corrected using subsampling, as described in \autoref{sec:pl_class_imbalance}.
    \label{fig:info_taskpertinent_v4_behav}
}
\end{figure}


\subsection{Discussion of task-pertinence of encoded information}

We decomposed the information encoded in the firing rate detected by \ac{V1} and \ac{V4} recording channels into task-pertinent information and task-nonpertinent information.
The task-pertinent information is that which would help an observer to classify whether the stimulus was in the upper or lower half of all stimulus contrasts.
Task-nonpertinent information, which is also encoded in the firing rate, is that which would help an observer to narrow down which of the stimuli within the upper or lower half was more likely.
Although the task-nonpertinent information is useful when trying to decode exactly which stimulus was presented, it is not useful for the behavioural task which the subject needs to perform.
Consequently, there is an incentive for the subject's neocortex to increase the amount of task-pertinent information which is encoded so that the task can be completed more accurately, but no direct incentive to increase the amount of task-nonpertinent information.

We applied the same procedure whilst considering the subject's behavioural response.
Although the behavioural response is binary, differences in the success rate for each specific stimulus mean we gain task-nonpertinent information about the stimulus when observing the behavioural response.

Across \ac{V1} and \ac{V4} firing rates for both subjects, there was never a significant change in the amount of task-nonpertinent information between the beginning (\zonename{A}) and end (\zonename{B}) of training.
For \ac{M2}, the firing rate from both \ac{V1} and \ac{V4} channels showed a significant increase in the task-pertinent information between beginning and end of training.
Consequently, the total information encoded also increased significantly, and the proportion of information which was task-pertinent increased significantly.
For \ac{M1}, the firing rate from \ac{V1} and \ac{V4} channels did not show a significant increase in task-pertinent information.
Similarly, there was no significant change in the total information, nor in the proportion of information which was task-pertinent.
These results are consistent with the neocortex learning to optimise the reward signal given from the behavioural task --- the encoded information which is not pertinent to the task is held constant throughout training whilst the task-pertinent information increases with training.

There was an increase in both task-pertinent and task-nonpertinent information contained in the behavioural response for both subjects during training with both \ac{V1} and \ac{V4} recordings.
However, the increase in task-pertinent information was always larger than the increase in task-nonpertinent information.

Arguably, changes in amount of task-pertinent information are more interesting to consider than the amount of task-nonpertinent information, since this directly relates to the performance of the subject.
But even if this were not the case, there is no significant change in the task-nonpertinent information; consequently, for the rest of this chapter we will only consider the amount of information about the stimulus which is task-pertinent.
We will do so by collapsing the stimulus labels together into two groups which, as described in \autoref{sec:pl_bias_grouping}, reduces the residual bias on the computed information since having \num{2} classes instead of \num{14} provides us with \num{7} times more samples per class.


%==============================================================================
\section{Information latency}
\label{sec:pl_info_latency}

So far, we have only been considering the amount of information about the stimulus encoded in the firing rate during the entire stimulation period.
But is it truly best to use the entire \SI{527}{\milli\second} period of stimulation?
Due to environmental pressures such as predation, perception occurs in notably less than half a second.
It is possible that the signal encoding which stimulus is on screen is only transiently emitted by visually responsive neurons, in which case a shorter window will give just as much information about the stimulus.
In this section, we investigate when the firing rate of the neurons is most informative about the stimulus.


\subsection{Methods and results for information latency}

We considered the firing rate of each multi-unit channel as measured within windows of varying lengths, logarithmically spaced from \SI{2.5}{\milli\second} to \SI{501}{\milli\second}.
Since we are using windows shorter than the stimulation period, we also varied the latency of the window with respect to the time of the stimulus onset.
For each window duration, we varied the latency of the window from the very start to the very end of the stimulus presentation period, at linear intervals equal to either \SI{10}{\milli\second} or one quarter of the window duration (whichever was shorter).

\begin{figure}[htbp]%
    \centering
    \hspace*{\fill}
    \subfloat[][\ac{M1} \ac{V1}.\label{fig:info_winlen_v1_blanco}]{%
        \includegraphics[scale=.4]{%
figs/info2/binlen/I_binlength_blanco_v1_chmean14_s343-359_oc0_Gclass-group-balanced_1bins_4-fold-sampling_dr_pt_btsp20_rmvet2_rmvms2_imscn_clhot.eps}}
    \hspace*{\fill}\hspace{.2cm}\hspace*{\fill}
    \subfloat[][\ac{M2} \ac{V1}.\label{fig:info_winlen_v1_jack}]{%
        \includegraphics[scale=.4]{%
figs/info2/binlen/I_binlength_jack_v1_chmean20_s51-72_oc0_Gclass-group-balanced_1bins_4-fold-sampling_dr_pt_btsp20_rmvet2_rmvms2_imscn_clhot.eps}}
    \hspace*{\fill}
    \\
    \hspace*{\fill}
    \subfloat[][\ac{M1} \ac{V4}.\label{fig:info_winlen_v4_blanco}]{%
        \includegraphics[scale=.4]{%
figs/info2/binlen/I_binlength_blanco_v4_chmean25_s307,308,311,313,314,317,318,320,321,329-341_oc0_Gclass-group-balanced_1bins_4-fold-sampling_dr_pt_btsp20_rmvet2_rmvms2_imscn_clhot.eps}}
    \hspace*{\fill}\hspace{.2cm}\hspace*{\fill}
    \subfloat[][\ac{M2} \ac{V4}.\label{fig:info_winlen_v4_jack}]{%
        \includegraphics[scale=.4]{%
figs/info2/binlen/I_binlength_jack_v4_chmean18_s24,25,27-38,40-49_oc0_Gclass-group-balanced_1bins_4-fold-sampling_dr_pt_btsp20_rmvet2_rmvms2_imscn_clhot.eps}}
    \hspace*{\fill}
    \caption{\captionemph{Duration of the window over which firing rate is measured influences the measured information.}
For each recording channel and window duration, we took the maximum information over all latencies, then averaged the information over channels.
Main panels: heatmap showing information against experimental session and window duration.
For each information value, we took \num{20} bootstrapped information values by randomly pairing stimuli and responses.
After taking the maximum over latencies, the mean of the bootstraps was subtracted from the reported information, and if the value did not exceed \num{3} standard deviations over the bootstrapped information values it was deemed insignificant (shown in white; median significance threshold indicated by a line across the colour bar).
Above: maximum information over all window durations.
The average over channels is shown (black line), along with the standard error over channels (grey shaded region).
Right: for each window duration, the average information over the first (\zonename{A}; blue) and last (\zonename{B}; purple) three sessions.
The average over channels is shown, along with the standard error over channels (shaded region).
Above right: violin plots for \zonename{A} and \zonename{B} showing the Gaussian kernel density estimate over channels of the maximum information.
Note that window durations were sampled logarithmically, but are shown here on a linear scale.
    \label{fig:info_winlen}
}
\end{figure}

First, we consider the question of which window duration provides the most information about the stimulus.
Since a longer window duration means a more accurate sample of the firing rate and therefore a higher \ac{SNR}, we would expect longer windows to provide more task-pertinent information about the stimulus.
Taking the maximum information across all latencies, as shown in \autoref{fig:info_winlen}, we find that longer windows are not always more informative.

For \ac{V1} (\autoref{fig:info_winlen_v1_blanco} and \autoref{fig:info_winlen_v1_jack}), shorter windows with a duration around \SI{50}{\milli\second} can capture the most informative firing rate.
Measuring the firing rate with windows around \SI{250}{\milli\second} yields the least information, with an increase as windows become longer than this.
For both subjects, there is no notable change between the start and end of training (\zonename{A} and \zonename{B}) in the amount of information encoded in windows shorter than \SI{250}{\milli\second}, but there does seem to be a change for longer windows.
However, this change is different for the two subjects, with information measured for longer windows decreasing after training for \ac{M1} but increasing for \ac{M2}.

For \ac{V4} (\autoref{fig:info_winlen_v4_blanco} and \autoref{fig:info_winlen_v4_jack}), using a longer window to measure the firing rate is always more informative.
There seems to be an increase in information after training for all window durations for \ac{M2}, but only when the firing rate window is longer than \SI{350}{\milli\second} for \ac{M1}.

Our results are parametrised in three dimensions --- experimental session (number of days of training), window duration, and window latency --- which is too many to portray at once in a single figure.
The results in \autoref{fig:info_winlen} are a summary over two of these dimensions, collapsing the window latency dimension by taking the maximum.
To understand the results better, we next collapse along the ``session'' dimension instead.

\begin{figure}[htbp]%
    \centering
    \hspace*{\fill}
    \subfloat[][\ac{M1} \ac{V1}.\label{fig:info_offset_vs_winlen_v1_blanco}]{%
        \includegraphics[scale=.4]{%
figs/info2/binlen/I_offsetVwinlen_blanco_v1_chmean14_s343-359_oc0_Gclass-group-balanced_1bins_4-fold-sampling_dr_pt_btsp20_rmvet2_rmvms2_imscn_clhot.eps}}
    \hspace*{\fill}\hspace{.2cm}\hspace*{\fill}
    \subfloat[][\ac{M2} \ac{V1}.\label{fig:info_offset_vs_winlen_v1_jack}]{%
        \includegraphics[scale=.4]{%
figs/info2/binlen/I_offsetVwinlen_jack_v1_chmean20_s51-72_oc0_Gclass-group-balanced_1bins_4-fold-sampling_dr_pt_btsp20_rmvet2_rmvms2_imscn_clhot.eps}}
    \hspace*{\fill}
    \\
    \hspace*{\fill}
    \subfloat[][\ac{M1} \ac{V4}.\label{fig:info_offset_vs_winlen_v4_blanco}]{%
        \includegraphics[scale=.4]{%
figs/info2/binlen/I_offsetVwinlen_blanco_v4_chmean25_s307,308,311,313,314,317,318,320,321,329-341_oc0_Gclass-group-balanced_1bins_4-fold-sampling_dr_pt_btsp20_rmvet2_rmvms2_imscn_clhot.eps}}
    \hspace*{\fill}\hspace{.2cm}\hspace*{\fill}
    \subfloat[][\ac{M2} \ac{V4}.\label{fig:info_offset_vs_winlen_v4_jack}]{%
        \includegraphics[scale=.4]{%
figs/info2/binlen/I_offsetVwinlen_jack_v4_chmean18_s24,25,27-38,40-49_oc0_Gclass-group-balanced_1bins_4-fold-sampling_dr_pt_btsp20_rmvet2_rmvms2_imscn_clhot.eps}}
    \hspace*{\fill}
    \caption{\captionemph{Information, encoded as firing rate, as a function of window latency.}
For a given latency and window duration, the information value reported is the average over all windows of this duration which include that latency (see text for more details).
Results are averaged over experimental sessions
(\protect\subref{fig:info_offset_vs_winlen_v1_blanco}: \num{17}, \protect\subref{fig:info_offset_vs_winlen_v1_jack}: \num{22}, \protect\subref{fig:info_offset_vs_winlen_v4_blanco}: \num{22}, \protect\subref{fig:info_offset_vs_winlen_v4_jack}: \num{24}).
Values which are not significant (defined as \num{3} standard deviations of the bootstrapped information measurements) are shown in white, with a typical threshold for significance indicated by a black line across the colour bar.
Note that the scale for the window durations is logarithmic, differing from \autoref{fig:info_winlen}.
Above: maximum over all latencies, with standard error over channels indicated by the shaded region.
This curve is different from those shown in \autoref{fig:info_winlen} due to the smoothing effect of averaging across coincident windows before taking the maximum value.
    \label{fig:info_offset_vs_winlen}
}
\end{figure}

As the set of window latencies considered is necessarily different for each window duration,%
\footnote{
One cannot reasonably examine the information encoded in the \SI{400}{\milli\second} of stimulus-driven activity starting from a \SI{200}{\milli\second} latency, since the stimulus presentation has finished within \SI{530}{\milli\second}.
}
we cannot simply average the data over the experimental session dimension.
Since we wish to understand \textemph{when} the firing rate is most informative about the stimulus, we reparametrised the results over latencies with a very high sampling frequency and, for each window duration, took the average over all information measurements containing this latency.
These steps were repeated for bootstrapped information values, and their average was subtracted from the information estimate.
Information values less than \num{3} times the standard deviation of the bootstraps were considered non-significant (indicated in white in \autoref{fig:info_offset_vs_winlen}).

These results, shown in \autoref{fig:info_offset_vs_winlen}, corroborate the findings discussed for \autoref{fig:info_winlen}.
Namely, firing rates evaluated over longer durations always give more information about the stimulus for \ac{V4}, but not \ac{V1}.

Examining the data as a function of latency, we can see \textemph{when} it is possible to estimate the \ac{V1} firing rate using only a very short window and still gain a large amount of information about the stimulus.
As shown in \autoref{fig:info_offset_vs_winlen_v1_blanco} and \autoref{fig:info_offset_vs_winlen_v1_jack}, short windows of \SI{40}{\milli\second} and below are only transitively informative, with a narrow peak at \SI{50}{\milli\second} latency after the onset of the stimulus.
This temporally localised period of high information content coincides with the elevated firing rate of the stimulus-onset response, as shown in the rastergrams of \autoref{sec:pl_rasters}, which also occurs with a latency around \SI{50}{\milli\second}.
To directly compare the temporal profile of the information with the average firing rate, we plotted the average firing rate as a function of the latency and experimental session, shown in \autoref{fig:fr_hm}.
This was evaluated using windows \SI{5}{\milli\second} in duration, and \autoref{fig:info_offset_5ms} shows the amount of information contained in the firing rate using the same windows.


% blanco v1 firing rate in 5.000000ms
% Loaded all the Channel data
% Making channel-wise mean plots
% A = [6.4448359989157;27.197626851327;8.72077716717186;13.5270809203447;18.6215263231393;16.8651683547319;13.0706256109482;7.60076024544716;17.387821697594;18.0585709357057;15.851302397792;11.5581540534102;16.8490886090507;11.8450224664646]
% B = [5.50464320625613;23.8663745067919;7.24694080955942;9.17303627218242;13.8260142766784;13.6547947624798;7.84815147955567;6.67275218983001;17.5006879584678;15.5104686058197;13.8252270605212;8.36648197891085;15.1072427993681;9.90930585332864]
% n=14  h=1.000000  p=0.000038=3.821903e-05   delta = -2.541874+/-0.417163 = -17.478647%+/-143.897806%
% rule of thumb:  bandwidth=3.241169 bandwidth=3.072011 
% same bandwidth bw = 1.536 used for all cols
% YLIM4 = [3.33534484174905 29.3669252158341];
%
% jack v1 firing rate in 5.000000ms
% Loaded all the Channel data
% Making channel-wise mean plots
% A = [30.2470727783913;19.9542881851842;22.2151270165358;17.5006666710744;44.5958823303899;10.7953633532896;17.9211007724774;22.9917466044108;29.172275487144;20.0808858573528;38.4062136281149;26.5237178709516;24.3896769181022;19.5652760674284;47.0380912826588;13.015029351722;35.116938885777;8.52633207876679;11.459182688683;16.6515331499917]
% B = [25.4249198958617;18.7964720212918;20.2836418215785;14.7494004262055;41.1585314167964;9.14134347349127;14.0718796616547;18.5247656101126;21.0070638892891;15.3477288552027;33.7968606605223;19.0379905103392;22.005289296262;16.850209507992;33.0993628723547;11.5221454901191;28.3053666268001;7.33131213731874;8.95062051242176;14.2535333665457]
% n=20  h=1.000000  p=0.000009=9.299247e-06   delta = -4.125398+/-0.689461 = -17.327548%+/-242.708496%
% rule of thumb:  bandwidth=6.154781 bandwidth=5.064363 
% same bandwidth bw = 2.5322 used for all cols
% YLIM4 = [3.36063422278473 51.0087691971928];
%
% blanco v4 firing rate in 5.000000ms
% Loaded all the Channel data
% Making channel-wise mean plots
% A = [10.3993685653046;6.80751890873317;16.3916336750766;10.3301360318962;11.5039132584305;3.09829598067698;17.8535600035679;3.96541196449593;17.9568783727466;26.0270488348371;6.20374148243586;11.1064609886831;18.6042597171676;9.46786103122279;5.03951403597137;11.9540356675923;10.2990722698896;20.9079411587333;15.1727667842679;8.49194904307498;15.9101069220623;10.137442916628;4.34805600535966;8.61807830288219;9.57070730675394]
% B = [12.0780127357711;6.00270468718798;16.6605731476651;9.76250715339901;15.2573300034752;3.37968837123719;17.5516316583559;5.08455754218198;16.1032597732325;21.3782350384809;6.5763497049674;12.6533788721055;21.3377760971561;7.80353254521292;5.53731929204322;11.0296553789132;7.32422633822664;17.4663097370511;16.4795709555169;8.96045957915111;14.0298624193511;9.52694803411565;4.89224785423344;12.0414895876125;10.8338022115868]
% n=25  h=0.000000  p=0.967699=9.676993e-01   delta = -0.016573+/-0.405029 = -0.142791%+/-114.829491%
% rule of thumb:  bandwidth=3.128659 bandwidth=2.831439 
% same bandwidth bw = 1.4157 used for all cols
% YLIM4 = [0.805420695260959 28.3199241202532];
%
% jack v4 firing rate in 5.000000ms
% Loaded all the Channel data
% Making channel-wise mean plots
% A = [15.7853333875428;14.5279737388939;15.3406302322838;5.26786404166171;6.92619135053219;8.9045824260411;13.3061065247381;9.87861735998043;9.03059401433904;7.2010698376154;4.81799097453712;10.919020207403;6.45289029159828;7.55620786960711;8.1394321824322;7.12702628492076;6.8615243860502;7.09915886224321]
% B = [18.4579586274835;16.0468511534531;16.1882962668828;9.13315528169993;8.45936282995466;13.8233639607561;17.4574837404668;11.333427024326;10.4120160209273;9.05910723720686;5.74792109064066;15.7872248108008;8.44312383283422;8.05742343415539;10.0108128239953;11.7242517545944;8.08920397683781;8.2508461249824]
% n=18  h=1.000000  p=0.000005=4.990527e-06   delta = +2.296645+/-0.350858 = +25.032737%+/-80.778703%
% rule of thumb:  bandwidth=1.976821 bandwidth=2.219233 
% same bandwidth bw = 0.98841 used for all cols
% YLIM4 = [3.45399420924247 19.8219553927782];

\begin{figure}[htbp]%
    \centering
    \hspace*{\fill}
    \subfloat[][\ac{M1} \ac{V1}.\label{fig:fr_hm_v1_blanco}]{%
        \includegraphics[scale=.4]{%
figs/fr/fr_sessionwise_blanco_v1_chmean14_s343-359_oc0_Gbalanced_5ms_418off_rmvet2_rmvms2_imscn_clhot.eps}}
    \hspace*{\fill}\hspace{.2cm}\hspace*{\fill}
    \subfloat[][\ac{M2} \ac{V1}.\label{fig:fr_hm_v1_jack}]{%
        \includegraphics[scale=.4]{%
figs/fr/fr_sessionwise_jack_v1_chmean20_s51-72_oc0_Gbalanced_5ms_418off_rmvet2_rmvms2_imscn_clhot.eps}}
    \hspace*{\fill}
    \\
    \hspace*{\fill}
    \subfloat[][\ac{M1} \ac{V4}.\label{fig:fr_hm_v4_blanco}]{%
        \includegraphics[scale=.4]{%
figs/fr/fr_sessionwise_blanco_v4_chmean25_s307,308,311,313,314,317,318,320,321,329-341_oc0_Gbalanced_5ms_418off_rmvet2_rmvms2_imscn_clhot.eps}}
    \hspace*{\fill}\hspace{.2cm}\hspace*{\fill}
    \subfloat[][\ac{M2} \ac{V4}.\label{fig:fr_hm_v4_jack}]{%
        \includegraphics[scale=.4]{%
figs/fr/fr_sessionwise_jack_v4_chmean18_s24,25,27-38,40-49_oc0_Gbalanced_5ms_418off_rmvet2_rmvms2_imscn_clhot.eps}}
    \hspace*{\fill}
    \caption{\captionemph{Average firing rate over \SI{5}{\milli\second} windows.}
Windows were sampled at \SI{1.25}{\milli\second} intervals, shown with a latency corresponding to the middle of each window.
Information values which did not exceed \num{3} standard deviations over the corresponding bootstraps were deemed insignificant (shown in white; median significance threshold indicated by a line across the colour bar).
Above: overall firing rate during \SI{527}{\milli\second} of stimulus presentation, averaged over channels (black line), with standard error over channels shown (grey region).
Right: average over the first (\zonename{A}; blue) and last (\zonename{B}; purple) three sessions, averaged over channels with standard error indicated (shaded region).
Above right: distribution over channels of overall firing rate for \zonename{A} and \zonename{B}.
    \label{fig:fr_hm}
}
\end{figure}


% blanco v1 1x5.00ms
% dr pt
% Loaded all the Channel data
% Making channel-wise mean plots
% n=14  h=0.000000  p=0.067282=6.728205e-02   delta = -0.011889+/-0.005955 = -23.637917%+/-11.879502%
% same bandwidth bw = 0.010524 used for all cols
%
% jack v1 1x5.00ms
% dr pt
% Loaded all the Channel data
% Making channel-wise mean plots
% n=20  h=1.000000  p=0.000092=9.160860e-05   delta = -0.031460+/-0.006373 = -10.275927%+/-2.727501%
% same bandwidth bw = 0.022348 used for all cols
%
% blanco v4 1x5.00ms
% dr pt
% Loaded all the Channel data
% Making channel-wise mean plots
% n=25  h=0.000000  p=0.382092=3.820921e-01   delta = -0.001742+/-0.001956 = -8.333161%+/-9.365480%
% same bandwidth bw = 0.0045601 used for all cols
%
% jack v4 1x5.00ms
% dr pt
% Loaded all the Channel data
% Making channel-wise mean plots
% n=18  h=1.000000  p=0.022284=2.228433e-02   delta = +0.003227+/-0.001283 = +42.414208%+/-16.869162%
% same bandwidth bw = 0.00080329 used for all cols

\begin{figure}[htbp]%
    \centering
    \hspace*{\fill}
    \subfloat[][\ac{M1} \ac{V1}.\label{fig:info_offset_5ms_v1_blanco}]{%
        \includegraphics[scale=.4]{%
figs/info2/offsets/I_sessionwise_blanco_v1_chmean14_s343-359_oc0_Gclass-group-balanced_1bins_of_5ms_dr_pt_btsp20_rmvet2_rmvms2_imscn_clhot.eps}}
    \hspace*{\fill}\hspace{.2cm}\hspace*{\fill}
    \subfloat[][\ac{M2} \ac{V1}.\label{fig:info_offset_5ms_v1_jack}]{%
        \includegraphics[scale=.4]{%
figs/info2/offsets/I_sessionwise_jack_v1_chmean20_s51-72_oc0_Gclass-group-balanced_1bins_of_5ms_dr_pt_btsp20_rmvet2_rmvms2_imscn_clhot.eps}}
    \hspace*{\fill}
%     \\
%     \hspace*{\fill}
%     \subfloat[][\ac{M1} \ac{V4}.\label{fig:info_offset_5ms_v4_blanco}]{%
%         \includegraphics[scale=.4]{%
% figs/info2/offsets/I_sessionwise_blanco_v4_chmean25_s307,308,311,313,314,317,318,320,321,329-341_oc0_Gclass-group-balanced_1bins_of_5ms_dr_pt_btsp20_rmvet2_rmvms2_imscn_clhot.eps}}
%     \hspace*{\fill}\hspace{.2cm}\hspace*{\fill}
%     \subfloat[][\ac{M2} \ac{V4}.\label{fig:info_offset_5ms_v4_jack}]{%
%         \includegraphics[scale=.4]{%
% figs/info2/offsets/I_sessionwise_jack_v4_chmean18_s24,25,27-38,40-49_oc0_Gclass-group-balanced_1bins_of_5ms_dr_pt_btsp20_rmvet2_rmvms2_imscn_clhot.eps}}
%     \hspace*{\fill}
    \caption{\captionemph{Information encoded as firing rate over windows with \SI{5}{\milli\second} duration.}
Main panels: heatmap showing information in each experimental session with latencies, in \SI{1.25}{\milli\second} intervals, ranging from the start to end of the stimulus presentation.
The $y$-axis value corresponds to the centre of each window.
Above: maximum over all latencies and average over channels (black line), with standard error over channels shown (grey region).
Right: average over the first (\zonename{A}; blue) and last (\zonename{B}; purple) three sessions, averaged over channels, with standard error indicated (shaded region).
Above-right: for \zonename{A} and \zonename{B}, the distribution over channels of the maximum information over all latencies.
    \label{fig:info_offset_5ms}
}
\end{figure}


For both subjects, the sharp peak in the information contained in \ac{V1} coincides precisely with the maxima of the average firing rate, with a latency of approximately \SI{50}{\milli\second}.
The firing rate for \ac{V4} shows a large stimulus-onset response with \SI{100}{\milli\second} latency for \ac{M1} (see \autoref{fig:fr_hm_v4_blanco}), but this is not present for \ac{M2} (see \autoref{fig:fr_hm_v4_jack}).
However, for \ac{M2} the overall firing rate increased significantly ($p < 5 \times 10^{-6}$) with training by \SI{2.30\pm0.35}{Hz}.
These observations correspond to our sensitivity analysis (see \autoref{sec:pl_dprime}), where we observed almost all recording channels for \ac{M2} \ac{V4} were initially not tuned to the stimulus class.
The firing rate showed no change over training for \ac{M2} ($p=0.97$).
For \ac{V1}, the overall firing rate fell significantly during training for both subjects (\ac{M1}: \SI{-2.54\pm0.42}{Hz}, $p < 4 \times 10^{-5}$; \ac{M2} \SI{-4.13\pm0.69}{Hz}, $p < 1 \times 10^{-6}$).
As mentioned previously, we believe this effect is caused by a decline in signal quality for the recording electrodes over time.

Windows of only \SI{5}{\milli\second} were not informative enough to depict the distribution of information over latency for \ac{V4}.
Instead, we present results using \SI{50}{\milli\second} windows, depicted in \autoref{fig:info_offset}.
Here, we can again see a close correspondence between the average firing rate and encoded information against the time since the onset of the stimulus.

% 50ms windows at 10ms offset intervals
%
% blanco v1 1x50.00ms
% dr pt
% Loaded all the Channel data
% Making channel-wise mean plots
% A = [0.0869070160007024;0.0454360671797336;0.0122868496162529;0.0462414601481486;0.127034921899161;0.0627648640805788;0.123929885118711;0.101347196143745;0.10051199533031;0.0165435682713903;0.0172025619346488;0.0210902677347443;0.0201012031369372;0.0211061662839325]
% B = [0.0503639173352809;0.0394467204867789;0.0206854124751066;0.0341716218808717;0.0251309078185719;0.0381165141192398;0.0610695123686854;0.145147014926078;0.135315756859133;0.00884032269518068;0.0220806294888187;0.0160232735015603;0.0447503335906284;0.0205038552053085]
% n=14  h=0.000000  p=0.342245=3.422454e-01   delta = -0.010061+/-0.010207 = -17.552339%+/-17.842325%
% rule of thumb:  bandwidth=0.025643 bandwidth=0.025246 
% same bandwidth bw = 0.012623 used for all cols
% YLIM4 = [-0.00479034652790907 0.158777684149168];
%
% jack v1 1x50.00ms
% dr pt
% Loaded all the Channel data
% Making channel-wise mean plots
% A = [0.322273495541325;0.259836256743658;0.357236874823747;0.262738464437497;0.37032355287606;0.0989531964846166;0.324532810521044;0.401375126151464;0.352982554552941;0.199303642953066;0.410860755080856;0.416151727353204;0.325365149570532;0.362175919450819;0.345265518330353;0.192598218302092;0.269450258840796;0.195494716651627;0.263654934104346;0.254866832675228]
% B = [0.272293302450746;0.236444999673465;0.342196094513434;0.248801620404574;0.338399835551023;0.0856140359755171;0.31858584616958;0.407925398112034;0.307973757243471;0.200378408774723;0.349171888471342;0.353887899667208;0.295344628192377;0.347473738447734;0.273238404518912;0.200274354903163;0.281974489686517;0.198130852763054;0.256533975675753;0.242428364787178]
% n=20  h=1.000000  p=0.001182=1.182326e-03   delta = -0.021418+/-0.005622 = -7.156836%+/-2.661228%
% rule of thumb:  bandwidth=0.047808 bandwidth=0.041749 
% same bandwidth bw = 0.020874 used for all cols
% YLIM4 = [0.0525602668377485 0.449205496490972];
%
% blanco v4 1x50.00ms
% dr pt
% Loaded all the Channel data
% Making channel-wise mean plots
% A = [0.0734931507360141;0.0760230600326185;0.0208320974189938;0.0938849514535735;0.0403276023013184;0.0341634343702698;0.0072236222075404;0.00457240491090197;0.103401612021503;0.0231871705640539;0.0361243529405365;0.0105028281287047;0.0247163581072756;0.0211371004895599;0.0208251361679866;0.0626887881172645;0.0172492079859475;0.102917347008037;0.0385325393188616;0.0385401563486425;0.0434633676689983;0.0231177758967915;0.00443363789098708;0.137174889038085;0.0660706313701278]
% B = [0.0850302006224847;0.0260790225877802;0.0213294771444397;0.0515940236596652;0.103653969889904;0.0223973709156972;0.00902515985499454;0.0109967838298874;0.12505801392377;0.0168412453824922;0.0526333515711435;0.0201872046228789;0.0303458970503976;0.0117119426545876;0.0380313426817823;0.0582840277100112;0.031388438474312;0.0248674712862574;0.0442977607702742;0.0613845685858786;0.0761617164279482;0.030954628019024;0.00885341273471382;0.0928159243844079;0.0556890336384076]
% n=25  h=0.000000  p=0.918110=9.181101e-01   delta = -0.000600+/-0.005771 = -1.333024%+/-12.849196%
% rule of thumb:  bandwidth=0.019357 bandwidth=0.017281 
% same bandwidth bw = 0.0086407 used for all cols
% YLIM4 = [-0.00884048722372268 0.150449014152794];
%
% jack v4 1x50.00ms
% dr pt
% Loaded all the Channel data
% Making channel-wise mean plots
% A = [0.0110968907001249;0.0117254565932458;0.00672720623787957;0.00666062130791273;0.0188789835048239;0.0229611923582639;0.0176565210779671;0.00527226000158425;0.00516588609111442;0.00825514895878919;0.00613147106574422;0.0115561527620906;0.00644339646857685;0.00598483960701672;0.0118527005865035;0.0261116321699353;0.00672811631140849;0.0129973232450572]
% B = [0.0233242543817568;0.0332762897269617;0.0058262519536095;0.0481314385076406;0.0553182325494078;0.13029082057762;0.0446546069220868;0.0185275471500716;0.00351053676091566;0.0248266232683851;0.014334431247611;0.0513029111888599;0.0189386910815137;0.0207580289591665;0.0198700519286291;0.131117855867539;0.0358456891739579;0.0478677416465801]
% n=18  h=1.000000  p=0.000902=9.017282e-04   delta = +0.029195+/-0.007275 = +259.891757%+/-64.764879%
% rule of thumb:  bandwidth=0.003657 bandwidth=0.020949 
% same bandwidth bw = 0.0018284 used for all cols
% YLIM4 = [-0.00925019514974664 0.143878587778201];

\begin{figure}[htbp]%
    \centering
    \hspace*{\fill}
    \subfloat[][\ac{M1} \ac{V1}.\label{fig:info_offset_v1_blanco}]{%
        \includegraphics[scale=.4]{%
figs/info2/offsets/I_sessionwise_blanco_v1_chmean14_s343-359_oc0_Gclass-group-balanced_1bins_of_50ms_dr_pt_btsp20_rmvet2_rmvms2_imscn_clhot.eps}}
    \hspace*{\fill}\hspace{.2cm}\hspace*{\fill}
    \subfloat[][\ac{M2} \ac{V1}.\label{fig:info_offset_v1_jack}]{%
        \includegraphics[scale=.4]{%
figs/info2/offsets/I_sessionwise_jack_v1_chmean20_s51-72_oc0_Gclass-group-balanced_1bins_of_50ms_dr_pt_btsp20_rmvet2_rmvms2_imscn_clhot.eps}}
    \hspace*{\fill}
    \\
    \hspace*{\fill}
    \subfloat[][\ac{M1} \ac{V4}.\label{fig:info_offset_v4_blanco}]{%
        \includegraphics[scale=.4]{%
figs/info2/offsets/I_sessionwise_blanco_v4_chmean25_s307,308,311,313,314,317,318,320,321,329-341_oc0_Gclass-group-balanced_1bins_of_50ms_dr_pt_btsp20_rmvet2_rmvms2_imscn_clhot.eps}}
    \hspace*{\fill}\hspace{.2cm}\hspace*{\fill}
    \subfloat[][\ac{M2} \ac{V4}.\label{fig:info_offset_v4_jack}]{%
        \includegraphics[scale=.4]{%
figs/info2/offsets/I_sessionwise_jack_v4_chmean18_s24,25,27-38,40-49_oc0_Gclass-group-balanced_1bins_of_50ms_dr_pt_btsp20_rmvet2_rmvms2_imscn_clhot.eps}}
    \hspace*{\fill}
    \caption{\captionemph{Information encoded in the firing rate measured over \SI{50}{\milli\second} windows.}
Plots are arranged as per \autoref{fig:info_offset_5ms}, but with \SI{50}{\milli\second} windows sampled at latencies with intervals of \SI{10}{\milli\second}.
    \label{fig:info_offset}
}
\end{figure}

In \autoref{fig:info_offset_v1_jack}, we can see an increase in the amount of information encoded in the \ac{V1} firing rate towards the end of the stimulation presentation duration.
This observation is mirrored in \autoref{fig:info_offset_vs_winlen_v1_jack}, and a similar result for \ac{V4} in \autoref{fig:info_offset_vs_winlen_v4_blanco}, where (looking from top to bottom of the heatmaps) we find windows of duration \SIrange{50}{150}{\milli\second} yield a double-peak in the information as a function of latency.
The firing rate is most informative when sampled with low latency, but a second peak occurs for late latencies toward the end of the stimulus presentation.
% This also suggests a reason why information encoded rises again with window duration --- a sufficiently long window will include both of these signals.
However, \autoref{fig:info_offset_vs_winlen} only shows the average information over all sessions and we can not conclude from it whether the information changes with training.


\begin{figure}[htbp]%
    \centering
    \hspace*{\fill}
    \subfloat[][\ac{M1} \ac{V1}.\label{fig:info_offset_vs_winlen_dif_v1_blanco}]{%
        \includegraphics[scale=.4]{%
figs/info2/binlen/I_offsetVwinlenDif_blanco_v1_chmean14_s343-359_oc0_Gclass-group-balanced_1bins_4-fold-sampling_dr_pt_btsp20_rmvet2_rmvms2_imscn_clhot.eps}}
    \hspace*{\fill}\hspace{.2cm}\hspace*{\fill}
    \subfloat[][\ac{M2} \ac{V1}.\label{fig:info_offset_vs_winlen_dif_v1_jack}]{%
        \includegraphics[scale=.4]{%
figs/info2/binlen/I_offsetVwinlenDif_jack_v1_chmean20_s51-72_oc0_Gclass-group-balanced_1bins_4-fold-sampling_dr_pt_btsp20_rmvet2_rmvms2_imscn_clhot.eps}}
    \hspace*{\fill}
    \\
    \hspace*{\fill}
    \subfloat[][\ac{M1} \ac{V4}.\label{fig:info_offset_vs_winlen_dif_v4_blanco}]{%
        \includegraphics[scale=.4]{%
figs/info2/binlen/I_offsetVwinlenDif_blanco_v4_chmean25_s307,308,311,313,314,317,318,320,321,329-341_oc0_Gclass-group-balanced_1bins_4-fold-sampling_dr_pt_btsp20_rmvet2_rmvms2_imscn_clhot.eps}}
    \hspace*{\fill}\hspace{.2cm}\hspace*{\fill}
    \subfloat[][\ac{M2} \ac{V4}.\label{fig:info_offset_vs_winlen_dif_v4_jack}]{%
        \includegraphics[scale=.4]{%
figs/info2/binlen/I_offsetVwinlenDif_jack_v4_chmean18_s24,25,27-38,40-49_oc0_Gclass-group-balanced_1bins_4-fold-sampling_dr_pt_btsp20_rmvet2_rmvms2_imscn_clhot.eps}}
    \hspace*{\fill}
    \caption{\captionemph{Change in information with training, as a function of window latency.}
Similar to \autoref{fig:info_offset_vs_winlen}, here we show the difference in the average during the final and first three sessions.
For a given latency and window duration, the information value reported is the difference in the average over all windows of this duration which include that latency (see text for more details).
Information values with no significant change between the start and end of training (determined by \num{3} times the standard deviation over the difference in bootstrapped information values) are shown in white, with a typical threshold for significance indicated by two black lines across the colour bar.
    \label{fig:info_offset_vs_winlen_dif}
}
\end{figure}

To investigate what properties of the response profile change with training, we repeated the methodology used for \autoref{fig:info_offset_vs_winlen}, but took the difference between the average over the first and last three sessions.
The results are shown in \autoref{fig:info_offset_vs_winlen_dif}.
We found there was a significant increase in information in the final \SI{150}{\milli\second} for both \ac{M2} \ac{V1} and \ac{M1} \ac{V4}, with magnitude \SI{0.06}{bits} and \SI{0.009}{bits} (see \autoref{fig:info_offset_vs_winlen_dif_v1_jack} and \autoref{fig:info_offset_vs_winlen_dif_v4_blanco}).

For both subjects, we do not find an increase in the most informative part of the stimulus response profile for \ac{V1}.
On the contrary, we find a significant reduction in the information encoded by the narrow, sharp, peak in firing rate with \SI{50}{\milli\second} latency (of approximately \SI{0.01}{bits} and \SI{0.03}{bits}), which we had previously noted was the most informative part of the response to the stimulus.
This corresponds to the reduction in firing rate between the start and end of training.

For \ac{M2} \ac{V4}, there is an increase in information, primarily with a latency from \SIrange{150}{250}{\milli\second}.
Again, this corresponds to the increase in firing rate seen for this set of recordings.


\subsection{Discussion of information latency}

In this section, we have seen that almost all the information contained in the firing rate of \ac{V1} is provided in the first \SI{5}{\milli\second} at the start of a short burst of rapid firing in response to the onset of the stimulus.
With such a short window, we will only be able to detect one or possibly two spikes, yet the change in probability of this single spike is able to convey \SI{0.4}{bits} of information about the stimulus on a single recording channel of \ac{M2}.
Over the course of training, the stimulus-induced firing rate recorded in \ac{V1} fell for both subjects.
We believe this reduction in observed firing rate is not due to the firing rate actually falling, but is due to the deterioration in signal quality in the electrode array.
Since our spike detection threshold was set to have a consistent spontaneous firing rate (using the methodology and rationale described in \autoref{sec:pl_san}) an increase in noise can result in an increased detection threshold, subsequently reducing the stimulus modulated activity.
The amount of information encoded in the peak response also falls for both subjects, which is well explained by the reduction in firing rate.

We found that the amount of information encoded in the \ac{V1} firing rate fell as the duration of the window used to summate the neural activity increased above \SI{100}{\milli\second}.
This ran counter to our expectations, since a longer window duration should intuitively integrate over more signal, resulting in an increase in information.
However, this follows naturally from the fact that the sharp burst of activity triggered by the onset of the stimulus contains so much more information than the activity which subsequently follows it.
The activity later in the stimulus presentation period has an \ac{SNR} much lower than the preceding activity, so including this in the window will reduce the overall \ac{SNR} and hence the total information.
% An alternative interpretation is this that the number of spikes elicited during the sharp burst of activity triggered by the onset of the stimulus is \textemph{negatively correlated} with the number of spikes elicited later in the stimulus presentation.
% Such a negative correlation would have to be dispersed over a long duration, otherwise we detect it as another high-information content signal.
% But if it were dispersed, the effects would be manifest as a reduction in information with longer windows including the onset response because the two signals would partially cancel out.
% Such a phenomenon could be triggered by the natural dynamics of the neurons, which become harder to excite after repeated firing due to a decrease in the resting membrane potential, increase in sodium and decrease of potassium within the cell, and depletion of available neurotransmitters.

Despite this, there was an increase in the information encoded in \ac{V1} with longer windows for \ac{M1}, due to another increase in the amount of information about the stimulus contained in the firing rate during the final \SI{200}{\milli\second} of stimulus presentation (\autoref{fig:info_offset_vs_winlen_dif_v1_jack}).
This signal increased in information over training despite the firing rate at this latency after the onset of the stimulus remaining the same during training (\autoref{fig:fr_hm_v1_jack}).
The same result --- an increase in late-presentation information without an increase in firing rate --- was found in \ac{V4} for \ac{M1} (\autoref{fig:info_offset_vs_winlen_dif_v4_blanco}).

There are several possible explanations for this result.
It could be that \ac{V1} and \ac{V4} become better at encoding the contrast of the stimuli so that the subject can extract the information to perform the task.
However, this seems unlikely since the amount of information encoded remains small when compared to the information contained in the activity of the large burst of stimulus-onset activity.
The subject would seem to do better if they were to remember the intensity of the initial response instead of interpreting the activity later in the stimulus presentation.
Alternatively, the activity in \ac{V1} and \ac{V4} could become more informative due to top-down influences.
If the subject is thinking about their planned response, information about the contrast of the stimulus may be leaking back to the visual cortex from higher cortical regions.
This result leads us to ask whether there is information about the stimulus encoded in the activity after the stimulus is removed, since in this case there is no bottom-up stimulation and we are left only with the effects of internal activity.


%==============================================================================
\section{Information sustained in post-stimulation activity}
\label{sec:pl_poststim_info}

In \autoref{sec:pl_info_latency}, we described an increase in information late in the stimulus presentation for both \ac{M2} \ac{V1} and \ac{M1} \ac{V4}, which could hypothetically be caused by information projected back to the visual cortex from higher cortical regions.
Following on from this, we will next consider how much task-pertinent information about the stimulus is maintained in the neural activity after the stimulus is removed, to determine how much information about the stimulus is present in the visual cortex without the influence of the visual stimulation.


\subsection{Post-stimulation information about the stimulus}

We noted in \autoref{sec:pl_rasters} that there was a large increase in firing rate triggered by the onset of the stimulus, which is also shown in \autoref{fig:fr_hm}, with a latency of around \SI{50}{\milli\second}, corresponding to the latency of the signal from the cones of the retina to reach the visual cortex.
A similar burst of activity is triggered by the removal (or offset) of the stimulus.
The change in the visual stimulation over time is the negative of the stimulus, which is just as powerful a stimulant as the stimulus itself.
The offset-response also has a latency, occurring in \ac{V1} \SI{50}{\milli\second} after the stimulus is removed.
This offset-response will contain substantial information about the stimulus, driven by the change in visual stimulation.

In this section, we want to remove as much visually driven activity as possible, which includes the offset-response with its \SI{50}{\milli\second} delay to \ac{V1}.
Consequently, we ignored the first \SI{220}{\milli\second} of activity after the stimulus offset and restricted ourselves to studying the information encoded in the subsequent \SI{200}{\milli\second}.
These \SI{200}{\milli\second} were immediately followed by the removal of the fixation point and the appearance of the black and white targets with which the subject recorded their response by means of a saccade to the corresponding target.
We computed the amount of task-pertinent information encoded in the firing rate, correcting for the change in class balance (see \autoref{sec:pl_class_imbalance}), using the \ac{PT} bias correction, with further correction by subtracting the mean of \num{20} bootstrapped information values (see \autoref{sec:pl_bootstrapping}).

% Information about stimulus class <>30% in tp5
%
% blanco v1 1x200.00ms
% dr pt
% Loaded all the Channel data
% Making channel-wise mean plots
% A = [0.0233575934639817;0.0229659669060399;0.00290524259897068;-0.00390848405291057;-0.00122391351972209;-0.00194896722296958;0.0329264392487644;0.0189033228335365;0.00324026325312739;0.0113921428118645;-0.0133589339703114;-0.00414000141536333;0.0104402671955582;0.00493037492482272]
% B = [0.0027256101665956;0.012402706710173;0.0107761287307439;0.003373112578624;0.0596416071504502;0.0148479109500865;0.0070493371354122;-0.000825921098703675;0.00440520287313014;-0.00012935019499829;0.00760680325748853;0.00877667235100428;0.00809987642163209;0.00499778442646282]
% ttest A vs Gaussian distributed around 0
% n=14  h=1.000000  p=0.047690=4.768957e-02   mean = +0.007606+/-0.003479
% ttest B vs Gaussian distributed around 0
% n=14  h=1.000000  p=0.022917=2.291709e-02   mean = +0.010268+/-0.003982
% paired ttest (B-A) vs Gaussian distributed around 0
% n=14  h=0.000000  p=0.659535=6.595353e-01   delta = +0.002662+/-0.005904 = +34.997848%+/-77.629481%
% rule of thumb:  bandwidth=0.007838 bandwidth=0.008971
% same bandwidth bw = 0.0039188 used for all cols
% YLIM4 = [-0.0206589880823875 0.0669416612625263];
%
% jack v1 1x200.00ms
% dr pt
% Loaded all the Channel data
% Making channel-wise mean plots
% A = [0.000622601684121227;-0.00377716142746305;0.000146928420993301;-0.00192772902316576;0.00258351831184827;-0.000456099680281245;0.00220643882266428;0.000699031175279237;0.000950796514649758;-0.00203297889097576;-0.000927812894491287;0.000615608520692172;0.00224166945145728;0.00374239704716356;0.00158921503228145;0.00321252301021788;-0.00183919492811508;-0.0010443699818787;-0.00311210523564171;-0.00139064398133498]
% B = [0.0201502377246868;0.00107464750059979;0.00745904844650262;0.000481295567789686;0.000281414493905789;0.00416706242733134;0.00383202645037285;0.00236227171472044;0.0103358861715392;-5.57676606133817e-05;0.00267266157181786;0.00684839280423106;0.00726748930743422;4.82968534149013e-05;0.0101888994989491;0.00377186459833387;0.00235798270785171;-0.000647515272085941;0.00406271535856172;0.00437885111653911]
% ttest A vs Gaussian distributed around 0
% n=20  h=0.000000  p=0.826116=8.261163e-01   mean = +0.000105+/-0.000472
% ttest B vs Gaussian distributed around 0
% n=20  h=1.000000  p=0.000559=5.587835e-04   mean = +0.004552+/-0.001100
% paired ttest (B-A) vs Gaussian distributed around 0
% n=20  h=1.000000  p=0.000699=6.985186e-04   delta = +0.004447+/-0.001101 = +4229.705038%+/-1046.831355%
% rule of thumb:  bandwidth=0.001197 bandwidth=0.002790
% same bandwidth bw = 0.0005985 used for all cols
% YLIM4 = [-0.00616990134267804 0.0225429776399018];
%
% blanco v4 1x200.00ms
% dr pt
% Loaded all the Channel data
% Making channel-wise mean plots
% A = [0.00639307398696406;0.00273367831347081;0.00166924841323086;0.000536022337646103;-0.000519938318953731;0.00274823096670525;0.0114949538542239;-0.00146465535342946;-0.00234997259278723;-0.00742751758128479;0.0057163505920708;-0.00160738193718678;0.00676817126098566;0.00708714274375871;0.00902642917838984;0.00109904496508465;0.0110518289586536;-0.00163210157262226;0.00100031115810167;-0.00153798229549339;0.0127658130594333;0.00223778110305665;-0.000306711073705264;0.00326852594947238;-0.00140448473222365]
% B = [0.00501179835724334;-0.0032764062052256;0.00976871724298058;0.000954174761784788;0.00419701489188305;-0.000656572979103187;0.00447235240459626;0.00367272864029234;0.00237276492150963;0.000414493976175878;-0.00240581272712645;0.00158993860269889;0.00461792466720409;0.00711000530629776;0.0287818238435108;0.00181668692786558;0.00287113526648885;0.000808888128438815;0.00427262926363139;0.00271384094735968;0.0253965936464429;0.000486915045735584;0.00301626408344893;0.00633170787967848;0.0285621433918874]
% ttest A vs Gaussian distributed around 0
% n=25  h=1.000000  p=0.012404=1.240356e-02   mean = +0.002694+/-0.000996
% ttest B vs Gaussian distributed around 0
% n=25  h=1.000000  p=0.003212=3.211872e-03   mean = +0.005716+/-0.001746
% paired ttest (B-A) vs Gaussian distributed around 0
% n=25  h=0.000000  p=0.087175=8.717515e-02   delta = +0.003022+/-0.001695 = +112.190842%+/-62.908718%
% rule of thumb:  bandwidth=0.002716 bandwidth=0.004760
% same bandwidth bw = 0.001358 used for all cols
% YLIM4 = [-0.0110484517237643 0.0324027579859903];
%
% jack v4 1x200.00ms
% dr pt
% Loaded all the Channel data
% Making channel-wise mean plots
% A = [-0.00384213631362481;-0.0041201081524218;0.0016421063781633;-0.000616230963948605;0.00294527262879324;0.00562348883293977;-0.00402219562418447;0.00228479582306612;-0.00291523114373236;-0.00160090879312798;0.00454363047259413;0.00166283542669536;-0.00416435952306651;0.00512797487815549;-0.00126252832053819;-0.0012049026285684;-0.00600778760071798;-0.00420233797384284]
% B = [-0.00571205877080751;0.00824379690196132;-0.00244074329563682;0.0167310765450579;-0.00287962979283033;0.00277906686726981;0.00418897820736885;-0.00352205223968776;0.00174300152962058;-0.00107537059754607;0.00110315716667718;-0.00355328508081516;0.0136519671285957;0.00464203980117706;-0.00250658653920782;0.00954997272633986;0.00259440122196895;0.00360405486380255]
% ttest A vs Gaussian distributed around 0
% n=18  h=0.000000  p=0.521125=5.211253e-01   mean = -0.000563+/-0.000859
% ttest B vs Gaussian distributed around 0
% n=18  h=0.000000  p=0.090619=9.061851e-02   mean = +0.002619+/-0.001460
% paired ttest (B-A) vs Gaussian distributed around 0
% n=18  h=0.000000  p=0.106422=1.064222e-01   delta = +0.003182+/-0.001866 = -565.431367%+/-331.655086%
% rule of thumb:  bandwidth=0.002104 bandwidth=0.003577
% same bandwidth bw = 0.0010521 used for all cols
% YLIM4 = [-0.00828167401529557 0.0190049629596355];

\begin{figure}[htbp]%
    \centering
    \hspace*{\fill}
    \subfloat[][\ac{M1} \ac{V1}, post-stimulus information about stimulus.\label{fig:info_tp5_v1_blanco}]{%
        \includegraphics[scale=.45]{%
figs/info2/tp5/I_sessionwise_tp5_blanco_v1_chmean14_s343-359_oc0_Gclass-group-balanced_1bins_of_200ms_dr_pt_btsp20_rmvet2_rmvms2_imscn_clhot.eps}}
    \hspace*{\fill}\hspace{.2cm}\hspace*{\fill}
    \subfloat[][\ac{M2} \ac{V1}, post-stimulus information about stimulus.\label{fig:info_tp5_v1_jack}]{%
        \includegraphics[scale=.45]{%
figs/info2/tp5/I_sessionwise_tp5_jack_v1_chmean20_s51-72_oc0_Gclass-group-balanced_1bins_of_200ms_dr_pt_btsp20_rmvet2_rmvms2_imscn_clhot.eps}}
    \hspace*{\fill}
    \\
    \hspace*{\fill}
    \subfloat[][\ac{M1} \ac{V1}, post-stimulus information about response.\label{fig:respinfo_tp5_v1_blanco}]{%
        \includegraphics[scale=.45]{%
figs/info2/tp5/I_sessionwise_tp5_blanco_v1_chmean14_s343-359_oc0_Gresponse-group-balanced_1bins_of_200ms_dr_pt_btsp20_rmvet2_rmvms2_imscn_clhot.eps}}
    \hspace*{\fill}\hspace{.2cm}\hspace*{\fill}
    \subfloat[][\ac{M2} \ac{V1}, post-stimulus information about response.\label{fig:respinfo_tp5_v1_jack}]{%
        \includegraphics[scale=.45]{%
figs/info2/tp5/I_sessionwise_tp5_jack_v1_chmean20_s51-72_oc0_Gresponse-group-balanced_1bins_of_200ms_dr_pt_btsp20_rmvet2_rmvms2_imscn_clhot.eps}}
    \hspace*{\fill}
    \\
    \hspace*{\fill}
    \subfloat[][\ac{M1} \ac{V1}, pre-stimulus information about stimulus.\label{fig:info_tp3_v1_blanco}]{%
        \includegraphics[scale=.45]{%
figs/info2/tp5/I_sessionwise_tp3_blanco_v1_chmean14_s343-359_oc0_Gclass-group-balanced_1bins_of_200ms_dr_pt_btsp20_rmvet2_rmvms2_imscn_clhot.eps}}
    \hspace*{\fill}\hspace{.2cm}\hspace*{\fill}
    \subfloat[][\ac{M2} \ac{V1}, pre-stimulus information about stimulus.\label{fig:info_tp3_v1_jack}]{%
        \includegraphics[scale=.45]{%
figs/info2/tp5/I_sessionwise_tp3_jack_v1_chmean20_s51-72_oc0_Gclass-group-balanced_1bins_of_200ms_dr_pt_btsp20_rmvet2_rmvms2_imscn_clhot.eps}}
    \hspace*{\fill}
    \caption{\captionemph{Information about the stimulus encoded in \ac{V1} after stimulus is removed.}
In \protect\subref{fig:info_tp5_v1_blanco} and \protect\subref{fig:info_tp5_v1_jack}, the amount of information about whether the contrast of the stimulus exceeded \SI{30}{\percent} encoded in the firing rate during the window \SIrange{220}{420}{\milli\second} after the stimulus was removed.
In \protect\subref{fig:respinfo_tp5_v1_blanco} and \protect\subref{fig:respinfo_tp5_v1_jack}, the amount of information about the behavioural response given by the subject encoded in the firing rate during the window \SIrange{220}{420}{\milli\second} after the stimulus was removed.
In \protect\subref{fig:info_tp3_v1_blanco} and \protect\subref{fig:info_tp3_v1_jack}, the information about the stimulus encoded in the \SI{200}{\milli\second} before the stimulus was presented, shown here for comparison purposes only.
    \label{fig:info_tp5_v1}
}
\end{figure}


\begin{figure}[htbp]%
    \centering
    \hspace*{\fill}
    \subfloat[][\ac{M1} \ac{V4}, post-stimulus information about stimulus.\label{fig:info_tp5_v4_blanco}]{%
        \includegraphics[scale=.45]{%
figs/info2/tp5/I_sessionwise_tp5_blanco_v4_chmean25_s307,308,311,313,314,317,318,320,321,329-341_oc0_Gclass-group-balanced_1bins_of_200ms_dr_pt_btsp20_rmvet2_rmvms2_imscn_clhot.eps}}
    \hspace*{\fill}\hspace{.2cm}\hspace*{\fill}
    \subfloat[][\ac{M2} \ac{V4}, post-stimulus information about stimulus.\label{fig:info_tp5_v4_jack}]{%
        \includegraphics[scale=.45]{%
figs/info2/tp5/I_sessionwise_tp5_jack_v4_chmean18_s24,25,27-38,40-49_oc0_Gclass-group-balanced_1bins_of_200ms_dr_pt_btsp20_rmvet2_rmvms2_imscn_clhot.eps}}
    \hspace*{\fill}
    \\
    \hspace*{\fill}
    \subfloat[][\ac{M1} \ac{V4}, post-stimulus information about response.\label{fig:respinfo_tp5_v4_blanco}]{%
        \includegraphics[scale=.45]{%
figs/info2/tp5/I_sessionwise_tp5_blanco_v4_chmean25_s307,308,311,313,314,317,318,320,321,329-341_oc0_Gresponse-group-balanced_1bins_of_200ms_dr_pt_btsp20_rmvet2_rmvms2_imscn_clhot.eps}}
    \hspace*{\fill}\hspace{.2cm}\hspace*{\fill}
    \subfloat[][\ac{M2} \ac{V4}, post-stimulus information about response.\label{fig:respinfo_tp5_v4_jack}]{%
        \includegraphics[scale=.45]{%
figs/info2/tp5/I_sessionwise_tp5_jack_v4_chmean18_s24,25,27-38,40-49_oc0_Gresponse-group-balanced_1bins_of_200ms_dr_pt_btsp20_rmvet2_rmvms2_imscn_clhot.eps}}
    \hspace*{\fill}
    \\
    \hspace*{\fill}
    \subfloat[][\ac{M1} \ac{V4}, pre-stimulus information about stimulus.\label{fig:info_tp3_v4_blanco}]{%
        \includegraphics[scale=.45]{%
figs/info2/tp5/I_sessionwise_tp3_blanco_v4_chmean25_s307,308,311,313,314,317,318,320,321,329-341_oc0_Gclass-group-balanced_1bins_of_200ms_dr_pt_btsp20_rmvet2_rmvms2_imscn_clhot.eps}}
    \hspace*{\fill}\hspace{.2cm}\hspace*{\fill}
    \subfloat[][\ac{M2} \ac{V4}, pre-stimulus information about stimulus.\label{fig:info_tp3_v4_jack}]{%
        \includegraphics[scale=.45]{%
figs/info2/tp5/I_sessionwise_tp3_jack_v4_chmean18_s24,25,27-38,40-49_oc0_Gclass-group-balanced_1bins_of_200ms_dr_pt_btsp20_rmvet2_rmvms2_imscn_clhot.eps}}
    \hspace*{\fill}
    \caption{\captionemph{Information about the stimulus encoded in \ac{V4} after stimulus is removed.}
In \protect\subref{fig:info_tp5_v4_blanco} and \protect\subref{fig:info_tp5_v4_jack}, the amount of information about whether the contrast of the stimulus exceeded \SI{30}{\percent} encoded in the firing rate during the window \SIrange{220}{420}{\milli\second} after the stimulus was removed.
In \protect\subref{fig:respinfo_tp5_v4_blanco} and \protect\subref{fig:respinfo_tp5_v4_jack}, the amount of information about the behavioural response given by the subject encoded in the firing rate during the window \SIrange{220}{420}{\milli\second} after the stimulus was removed.
In \protect\subref{fig:info_tp3_v4_blanco} and \protect\subref{fig:info_tp3_v4_jack}, the information about the stimulus encoded in the \SI{200}{\milli\second} before the stimulus was presented, shown here for comparison purposes only.
    \label{fig:info_tp5_v4}
}
\end{figure}


For both \ac{V1} and \ac{V4}, we detected information about the stimulus encoded after it was removed with a small effect size, around a tenth of the amount of information present during the stimulus presentation (shown in Figures \ref{fig:info_tp5_v1_blanco}, \ref{fig:info_tp5_v1_jack}, \ref{fig:info_tp5_v4_blanco}, and \ref{fig:info_tp5_v4_jack}; amount of information can be compared with that present in \autoref{fig:info_offset_vs_winlen}).
To illustrate the effect size in comparison with the noise when measuring information for a non-informative event, we also computed the amount of information about the stimulus encoded in the firing rate during the \SI{200}{\milli\second} \textemph{before} the onset of the stimulus.
Since stimuli were presented in a random order, it is not possible for the activity before the onset of the stimulus to contain any information about it, and we find that, with bias correction, the measured information is very close to \num{0} (see Figures \ref{fig:info_tp3_v1_blanco}, \ref{fig:info_tp3_v1_jack}, \ref{fig:info_tp3_v4_blanco}, and \ref{fig:info_tp3_v4_jack}).

For \ac{V1}, subject \ac{M1}, there was, across channels, a significant amount of information about the stimulus encoded in the post-stimulation firing rate ($p=0.023$), but the increase in information between the first (\zonename{A}) and last (\zonename{B}) three sessions of \SI{0.0027\pm0.0059}{bits} was not significant ($p=0.66$).
For subject \ac{M2}, the increase over training of \SI{0.0044\pm0.0011}{bits} of information encoded post-stimulus was significant ($p=0.00070$).

For \ac{V4}, \ac{M1} again had, across channels, a significant amount of information encoded in the post-stimulus firing rate ($p=0.0032$) without a significant increase between the start and end of training (\SI{+0.0030\pm0.0017}{bits}, $p=0.087$).
With subject \ac{M2}, the amount of information was not significant ($p=0.091$) and did not increase significantly either (\SI{+0.0032\pm0.0019}{bits}, $p=0.11$).


Regarding \textemph{how} information about the stimulus could be encoded after it is removed, three potential causes for this are readily apparent: bottom-up effects driven by the retina, residual effects within the visual cortex itself, and top-down effects driven by feedback from higher cortical regions.

First, let us consider bottom-up effects driven by the retina.
During the experimental trial, the subject must keep their gaze fixated on the central target whilst the sample and test stimuli appear and disappear (see \autoref{sec:pl_task} for details of the experimental set-up).
Such unnatural fixation will mean the same rods and cones are exposed to the test stimulus whilst it is presented, and this will partially deplete their supply of photopigment.
This depletion of photopigment results in a negative afterimage, wherein the subject sees an internally generated inverse of the over-exposed stimulus at the same location of the visual field.
Such negative afterimages can be induced readily in humans, although for the effect to be clearly perceived the subject must fixate on the stimulus for some tens of seconds, in order fully deplete the photopigment.
Since our test stimulus is only presented for \SI{530}{\milli\second}, the amount of depleted photopigment will be much smaller, resulting a much less intense afterimage (potentially imperceivable), but it is still possible that there is an effect of the conditioning of the retina during the stimulus presentation which manifests itself as a change in retinal activity (triggering a change in the visual cortex upstream) after it is removed.

% INCLUDE AFTERIMAGE EXAMPLE STIMULUS

Secondly, there could be a residual effect residing in the visual cortex itself.
Possible mechanisms include activity patterns sustained in recurrent activity, delayed responses to the stimulus due to slow, long-range lateral connections, and desensitisation through depletion, which could result in effects either positively or negatively correlated with the contrast of the preceding stimulus.

Thirdly, there could be top-down effects driven by feedback from higher cortical regions.
The experimental paradigm we are using requires the subject to remember the stimulus, or properties of it, for \SI{425}{\milli\second} before they can give their response.
Consequently, the stimulus must remain in working memory in higher cortical regions involved with planning.
Since there are as many backward cortical projections as forward connections within the neocortex, it is possible for the memory of the stimulus residing in the higher regions to excite neurons in the visual cortex even after it is no longer present.


\subsection{Difference in post-stimulation firing rate}

To assist in distinguishing between these explanations, we investigated the difference in post-stimulation firing rate between stimuli with contrast above and below \SI{30}{\percent}.
If the effects providing information about the stimulus after its removal are due to the suppression of activity in the visual cortex from depletion of neurotransmitters, this will mean higher contrast stimuli reduce the subsequent activity by more than lower contrast stimuli.
Whereas if the effect is caused by feedback, we would expect to find the memory of the stimulus recreates the activity induced by the stimulus, with more actively responded stimuli also inducing more activity after the stimulus is removed.

For each test stimulus, we measured the average firing rate during the \SI{200}{\milli\second} window starting \SI{220}{\milli\second} after the stimulus presentation ended.
The change in stimulus class balance during training was not addressed using subsampling, as described in \autoref{sec:pl_class_imbalance}.
Instead, we took the average firing rate for each stimulus class, then took the average over the \num{7} stimulus classes below and above \SI{30}{\percent} contrast.
Next we took the difference between these two averages (referred to as ``Difference in firing rate'' along the $y$-axis in \autoref{fig:frdelta_tp5_v1} and \autoref{fig:frdelta_tp5_v4}).
Finally, we averaged the difference in firing rate over the first (\zonename{A}) and last (\zonename{B}) three sessions, taking a Student's $t$-test between the distribution over channels of each, and a paired Student's $t$-test between \zonename{A} and \zonename{B}.

% blanco v1
% Test to see if A is significantly different from 0
% n=14  h=1.000000  p=0.003165=3.164615e-03   delta = +1.161574+/-0.321677
% Test to see if B is significantly different from 0
% n=14  h=1.000000  p=0.000836=8.362285e-04   delta = +1.426079+/-0.330326
% Test to see if B is significantly different from A
% n=14  h=0.000000  p=0.365763=3.657627e-01   delta = +0.264505+/-0.282242 = +22.771281%+/-40.313343%
% same bandwidth bw = 0.36235 used for all cols
%
% jack v1
% Test to see if A is significantly different from 0
% n=20  h=0.000000  p=0.479064=4.790641e-01   delta = -0.056362+/-0.078059
% Test to see if B is significantly different from 0
% n=20  h=1.000000  p=0.000002=2.311642e-06   delta = +0.984330+/-0.147971
% Test to see if B is significantly different from A
% n=20  h=1.000000  p=0.000002=2.185237e-06   delta = +1.040692+/-0.155797 = -1846.451525%+/-276.534008%
% same bandwidth bw = 0.098981 used for all cols

\begin{figure}[htbp]%
    \centering
    \hspace*{\fill}
    \subfloat[][\ac{M1} \ac{V1}.\label{fig:frdelta_tp5_v1_blanco}]{%
        \includegraphics[scale=.45]{%
figs/frdelta/frdelta_tp5_220-420ms_blanco_v1.eps}}
    \hspace*{\fill}\hspace{.2cm}\hspace*{\fill}
    \subfloat[][\ac{M2} \ac{V1}.\label{fig:frdelta_tp5_v1_jack}]{%
        \includegraphics[scale=.45]{%
figs/frdelta/frdelta_tp5_220-420ms_jack_v1.eps}}
    \hspace*{\fill}
    \caption{\captionemph{For \ac{V1}, difference in post-stimulus firing rate between contrasts above and below \SI{30}{\percent}.}
    \label{fig:frdelta_tp5_v1}
}
\end{figure}


Broadly speaking, both \ac{V1} and \ac{V4} brain regions have higher neural activity following presentation of a higher contrast, and the difference in activity between contrasts above and below \SI{30}{\percent} increases with training.
However, these results, shown in \autoref{fig:frdelta_tp5_v1} and \autoref{fig:frdelta_tp5_v4}, were not significant for both animals.

Considering \ac{V1}, \ac{M1} (see \autoref{fig:frdelta_tp5_v1_blanco}) has a significantly non-zero difference in firing rate both before (\zonename{A}; $p=0.003$) and after (\zonename{B}; $p=0.0008$) training, which rises from \SI{+1.16\pm0.32}{Hz} to \SI{+1.43\pm0.33}{Hz}.
However the increase in firing rate difference between \zonename{A} and \zonename{B} of \SI{+0.26\pm0.28}{Hz} is not significant.
Subject \ac{M2} (see \autoref{fig:frdelta_tp5_v1_jack}) has a lower initial difference in firing rate for the two groups of stimuli, which does not show significant tuning ($p=0.48$).
From this lower starting point, there is a significant ($p < 3 \times 10^{-6}$) increase in difference in firing rate of \SI{+1.04\pm0.16}{Hz} during training.


% blanco v4
% Test to see if A is significantly different from 0
% n=25  h=0.000000  p=0.488018=4.880179e-01   delta = +0.135203+/-0.191965
% Test to see if B is significantly different from 0
% n=25  h=0.000000  p=0.335276=3.352756e-01   delta = +0.210304+/-0.213878
% Test to see if B is significantly different from A
% n=25  h=0.000000  p=0.618336=6.183362e-01   delta = +0.075101+/-0.148787 = +55.546692%+/-111.709205%
% same bandwidth bw = 0.26164 used for all cols
%
% jack v4
% Test to see if A is significantly different from 0
% n=18  h=0.000000  p=0.072094=7.209423e-02   delta = +0.182467+/-0.095144
% Test to see if B is significantly different from 0
% n=18  h=1.000000  p=0.010283=1.028336e-02   delta = +0.705477+/-0.244530
% Test to see if B is significantly different from A
% n=18  h=1.000000  p=0.032290=3.228994e-02   delta = +0.523010+/-0.224328 = +286.632665%+/-123.309243%
% same bandwidth bw = 0.11655 used for all cols

\begin{figure}[htbp]%
    \centering
    \hspace*{\fill}
    \subfloat[][\ac{M1} \ac{V4}.\label{fig:frdelta_tp5_v4_blanco}]{%
        \includegraphics[scale=.45]{%
figs/frdelta/frdelta_tp5_220-420ms_blanco_v4.eps}}
    \hspace*{\fill}\hspace{.2cm}\hspace*{\fill}
    \subfloat[][\ac{M2} \ac{V4}.\label{fig:frdelta_tp5_v4_jack}]{%
        \includegraphics[scale=.45]{%
figs/frdelta/frdelta_tp5_220-420ms_jack_v4.eps}}
    \hspace*{\fill}
    \caption{\captionemph{For \ac{V4}, difference in post-stimulus firing rate between contrasts above and below \SI{30}{\percent}.}
    \label{fig:frdelta_tp5_v4}
}
\end{figure}

For \ac{V4}, \ac{M1} (see \autoref{fig:frdelta_tp5_v4_blanco}) does not have significantly different post-stimulation firing rates for the two stimulus groups either before (\zonename{A}; $p=0.49$) or after (\zonename{B}; $p=0.34$) training.
Correspondingly, the small change in firing rate difference of \SI{+0.08\pm0.15}{Hz} was not significant either.
With \ac{M2} (see \autoref{fig:frdelta_tp5_v4_jack}), the difference in firing rate of \SI{+0.18\pm0.10}{Hz} was not initially significant (\zonename{A}; $p=0.072$) but was after training (\zonename{B}; $p=0.01$).
The change between \zonename{A} and \zonename{B} in firing rate difference was \SI{+0.52\pm0.22}{Hz}, also significant ($p=0.032$).


\subsection{Post-stimulation information about behavioural response}

In a similar manner to how we computed the amount of information about the group of the stimulus (higher or lower than \SI{30}{\percent} contrast), we can also compute the amount of information the neural activity contains about the behavioural response the animal is about to provide at the end of the trial.
Taking the firing rate during the activity \SIrange{220}{420}{\milli\second} after the stimulus was removed, we computed the amount of information about the behavioural response provided by the subject.

% Information about behavioural response in tp5
%
% blanco v1 1x200.00ms
% dr pt
% Loaded all the Channel data
% Making channel-wise mean plots
% A = [-0.011047446218932;0.0141056356409966;-0.000372316355064739;-0.00820767395225028;-0.00209378329715963;-0.00348661565047736;0.0170211552609991;0.000435295908049116;0.00732694792378737;-0.00572354649330999;-0.00946184986536632;0.00862312736305306;-0.00660623941984674;-0.00734165336650021]
% B = [0.00408117220767355;0.0146249638991533;0.00287185122145934;0.00689658768170972;0.065966989208784;0.0125244758148015;0.00421957359914111;-0.00137076457745485;0.00678457446609355;-0.00225783263956578;0.00424460171646187;0.0116589219186618;0.00764743312082476;0.00160232368150841]
% ttest A vs Gaussian distributed around 0
% n=14  h=0.000000  p=0.841434=8.414339e-01   mean = -0.000488+/-0.002390
% ttest B vs Gaussian distributed around 0
% n=14  h=1.000000  p=0.045431=4.543091e-02   mean = +0.009964+/-0.004503
% paired ttest (B-A) vs Gaussian distributed around 0
% n=14  h=0.000000  p=0.055307=5.530692e-02   delta = +0.010452+/-0.004965 = -2142.694932%+/-1017.901035%
% rule of thumb:  bandwidth=0.005384 bandwidth=0.010145
% same bandwidth bw = 0.002692 used for all cols
% YLIM4 = [-0.0187488897617036 0.0736684327515556];
%
% jack v1 1x200.00ms
% dr pt
% Loaded all the Channel data
% Making channel-wise mean plots
% A = [0.000168146079408552;-0.00314186032690518;0.0012369862504607;-0.000546658186837394;-0.00137260235490149;0.00312986383968005;-0.00152527509838459;0.0074026124212445;0.000622267258267943;-0.00230719098401821;-0.00585188310100346;0.00135927094651354;0.0014214817139191;0.00246647302757397;0.00504154910320404;-0.000816927116310055;0.000707033949429111;-0.000421670414236589;-0.00254241908585551;-0.000240284931948579]
% B = [0.0200898581331784;0.00434389166245904;0.00392225956804004;0.00153262417250928;0.000133988335917253;0.00315370378841668;0.00127423524905277;0.006929157186338;0.0126861021304208;0.0013038795113823;0.00197107751310079;0.011450758866011;0.00862004383115043;0.00302392918204344;0.0115760190867031;0.00385630900703328;0.00419038442197125;1.10045205514313e-05;0.00474843643512545;0.00464006857280844]
% ttest A vs Gaussian distributed around 0
% n=20  h=0.000000  p=0.718355=7.183545e-01   mean = +0.000239+/-0.000654
% ttest B vs Gaussian distributed around 0
% n=20  h=1.000000  p=0.000122=1.222396e-04   mean = +0.005473+/-0.001138
% paired ttest (B-A) vs Gaussian distributed around 0
% n=20  h=1.000000  p=0.000129=1.287577e-04   delta = +0.005233+/-0.001094 = +2185.648777%+/-456.777074%
% rule of thumb:  bandwidth=0.001659 bandwidth=0.002887
% same bandwidth bw = 0.00082941 used for all cols
% YLIM4 = [-0.00844605722442165 0.0226840322565966];
%
% blanco v4 1x200.00ms
% dr pt
% Loaded all the Channel data
% Making channel-wise mean plots
% A = [0.00129299596855357;-0.0008153152493244;0.00680456913860646;0.000573655515666546;0.00630862496086985;0.00504757079198956;0.0176244674147727;-0.00494558330802481;-0.00368863750532385;-0.00463194784027078;0.00618118133149749;-0.000156645640662104;0.00383816762835867;0.0103530026875842;0.00748283898037546;-0.000816772253550317;0.00264080271197834;0.00307848112418396;0.00396581165078792;-4.25652629610731e-05;0.00424685199779192;0.00167673010618652;-0.00125418419414406;0.00215069186734382;0.00299539950467608]
% B = [0.00559609479296754;-0.00193749017808397;0.00903133388498532;0.00405740729211072;0.00301368312389977;-0.000794531430808424;0.00193144064777676;0.0100128996081557;0.00355264349079207;-0.000679780558996971;-0.00253399801067992;-0.000200412429564649;0.009926353496706;0.00257875625639066;0.0372033378403053;0.000729054235841242;0.00709977904225714;0.00517136032556725;0.00492759589462891;0.00481391802189609;0.0204951627493886;-0.000880156705778989;0.00440905651663423;0.00548806426295648;0.0282709324728883]
% ttest A vs Gaussian distributed around 0
% n=25  h=1.000000  p=0.008647=8.647266e-03   mean = +0.002796+/-0.000978
% ttest B vs Gaussian distributed around 0
% n=25  h=1.000000  p=0.002135=2.135159e-03   mean = +0.006451+/-0.001875
% paired ttest (B-A) vs Gaussian distributed around 0
% n=25  h=0.000000  p=0.076941=7.694057e-02   delta = +0.003655+/-0.001978 = +130.699559%+/-70.719127%
% rule of thumb:  bandwidth=0.002666 bandwidth=0.005112
% same bandwidth bw = 0.001333 used for all cols
% YLIM4 = [-0.00916047542285782 0.0414182299551384];
%
% jack v4 1x200.00ms
% dr pt
% Loaded all the Channel data
% Making channel-wise mean plots
% A = [0.000429084846844793;-0.00462218723101513;0.000793198010844387;-0.00330222270165856;-0.0019879799053277;0.000413535379957045;0.00797872934630647;0.000543002459477249;-0.00415305017602079;0.0158512287650289;0.00503431986388431;-0.00223169092539794;-0.00292451510657656;-0.00367182934762696;0.00105824286862707;0.00559464714231955;-0.00210440902137029;-0.0038739665162588]
% B = [-0.000797810637495762;0.0113858025737635;0.00206355809340076;0.0264789177302091;0.000602134354592554;0.012718965163007;0.005613878537318;-0.00123822447834245;-0.00324294052295455;0.0015414356485149;-0.000844882772117509;0.00379649876469843;0.0241614907522384;0.00209224150718846;-3.93396977254416e-05;0.00790035371882656;-0.000214198515355912;0.00352093359051339]
% ttest A vs Gaussian distributed around 0
% n=18  h=0.000000  p=0.697216=6.972159e-01   mean = +0.000490+/-0.001239
% ttest B vs Gaussian distributed around 0
% n=18  h=1.000000  p=0.016415=1.641483e-02   mean = +0.005305+/-0.001993
% paired ttest (B-A) vs Gaussian distributed around 0
% n=18  h=0.000000  p=0.077124=7.712421e-02   delta = +0.004815+/-0.002559 = +982.245274%+/-522.019521%
% rule of thumb:  bandwidth=0.003035 bandwidth=0.004882
% same bandwidth bw = 0.0015174 used for all cols
% YLIM4 = [-0.00773229772713755 0.0295890282263315];


The results, shown in Figures \ref{fig:respinfo_tp5_v1_blanco}, \ref{fig:respinfo_tp5_v1_jack}, \ref{fig:respinfo_tp5_v4_blanco}, and \ref{fig:respinfo_tp5_v4_jack}, indicate the amount of information encoded about the behavioural response is comparable to that of the stimulus group.
This is inevitable: since the performance of the subjects is much higher than chance, exceeding \SI{85}{\percent} after training, the behavioural responses contain a lot of information about whether the contrast of the stimulus exceeds \SI{30}{\percent}.


Before training, \ac{V1} post-stimulus activity did not contain a significant amount of information about the behavioural response for either subject (\ac{M1}: $p=0.84$; \ac{M2}: $p=0.72$).
But after training, there was a significant information about the animal's behaviour for both subjects (\ac{M1}: $p=0.045$; \ac{M2}: $p < 0.0002$), even though the change in information with training was only significant for \ac{M2} (\ac{M1}: \SI{+0.0105\pm0.0050}{bits}, $p=0.055$; \ac{M2}: \SI{+0.0052\pm0.0011}{bits}, $p < 0.0002$).
There was not significantly more or less information about the behavioural response than the stimulus group (\ac{M1}: \SI{-0.0003\pm0.0010}{bits}, $p=0.76$; \ac{M2}: \SI{+0.0009\pm0.0005}{bits}, $p=0.062$).

For \ac{V4}, \ac{M1} showed a significant amount of information about the behavioural response both before ($p=0.009$) and after ($p=0.002$) training, without a significant change between the two (\SI{+0.0037\pm0.0020}{bits}, $p=0.077$).
Meanwhile \ac{M2} showed a significant amount only after training ($p=0.016$), without showing a significant difference after training compared to before (\SI{+0.0048\pm0.0026}{bits}, $p=0.077$).
There was significantly more information about the behavioural response for \ac{M2}, but this is not true for \ac{M1} (\ac{M1}: \SI{+0.0007\pm0.0006}{bits}, $p=0.26$; \ac{M2}: \SI{+0.0027\pm0.0011}{bits}, $p=0.024$).

% Comparing information about stimulus with information about neural response, in zone B
% blanco v1
% n=14  h=0.000000  p=0.762055=7.620546e-01   delta = -0.000304+/-0.000982 = -2.958389%+/-9.575557%
% jack v1
% n=20  h=0.000000  p=0.061736=6.173575e-02   delta = +0.000921+/-0.000464 = +20.233329%+/-10.192101%
% blanco v4
% n=25  h=0.000000  p=0.260174=2.601742e-01   delta = +0.000735+/-0.000638 = +12.862512%+/-11.154875%
% jack v4
% n=18  h=1.000000  p=0.024190=2.419040e-02   delta = +0.002687+/-0.001086 = +102.577841%+/-41.459297%


\subsection{Discussion of post-stimulus information}
\label{sec:pl_poststim_discuss}

In this section, we investigated the amount of information about the stimulus and about the behavioural response of the subject encoded in the post-stimulus activity within \ac{V1} and \ac{V4}.
We found that, after training, there was a significant amount of information about the behavioural response in both brain regions for both subjects.
The amount of information about the stimulus group was also significant in \ac{V1} for both subjects, and in \ac{V4} for \ac{M1}.
During training, there was an increase in information about both the stimulus and behavioural response in both \ac{V1} and \ac{V4} for both subjects, although the increase was only significant with \ac{M2} \ac{V1}.

For \ac{M2} \ac{V4}, there was significantly more information about the behavioural response than the actual group of the stimulus, and a non-significant increase was also seen for \ac{M1} in both \ac{V1} and \ac{V4}.
In addition to this, we found there was a higher post-stimulation firing rate following the presentation of higher contrast stimuli, which are associated with a higher firing rate during the stimulus presentation, though this phenomenon was not observed in \ac{V4} for \ac{M1}.

This information present after the stimulus presentation has ended can be explained either as an artifact from the activity from the recent stimulation which persists in affecting the visual cortex from the bottom-up, or a feedback signal indicating the memory of the stimulus while the subject waits to give their response.
It is hard to make strong conclusions about which scenario is most likely from our results in this section, since the magnitude of the information we are considering is small and its changes even smaller.
Since the difference in post-stimulus activity following higher and lower contrast stimuli increased with training, the effect is unlikely to be caused by forward connections from the retina.
As there is more information about the behavioural response than the group of the stimulus, it is tempting to conclude that the post-stimulus activity is modulated by feedback affects instead of conditioning to the preceding stimulus.
However, the difference between the two was small, and may be confounded by the fact that the subject's perception of the stimulus is provided by the neural activity in the visual cortex during stimulus presentation.
A change in the magnitude of this activity would simultaneously alter the probability of the behavioural response, and the conditioning within the visual cortex itself.


%==============================================================================
\section{Decoding information at the population level}
\label{sec:dec-meth-lin}
%------------------------------------------------------------------------------

So far, we have only considered the amount of information encoded in the spikes collected by a single electrode contact --- that is to say, the spikes from neurons surrounding a single electrode contact.
However, when the subject's brain is deciding how to respond to the stimulus on each trial, it potentially has available to it the spikes from every neuron in the brain simultaneously.
Consequently, it is more pertinent for us to consider how much information is encoded at the population level --- the firing measured from many neurons simultaneously.

% To consider the amount of information encoded across the population, let the variable $x_i$ denote the firing rate (measured over some finite duration) from neuron $i$.
% If we were, hypothetically, to measure the firing from every neuron in the visual cortex we would have some very large array $\vec{x} = [x_1, x_2 \ldots]$.

Whilst we cannot simultaneously measure the firing rate of every neuron in the visual cortex, we can consider the firing rates simultaneously observed on all our \numrange{20}{30} multi-unit recording channels (for exact values for each dataset, see \autoref{tab:nchannels_restricted}).
Computing the amount of information encoded in the vector of simultaneous responses across all the recording channels allows us to investigate how the encoded information scales as the number of neurons increases.
Since the neurons in a neighbouring region of cortex will encode the stimulus in a similar manner, there will be a reasonable amount of redundancy between the neurons.
Consequently, the total amount of information will rise sublinearly with respect to the number of channels included in the response vector.
However, even if the neurons are encoding visual stimulation using identical response functions, there is still a benefit to knowing the response across multiple channels since each will have an independent sample for (some of) the noise on each recording channel.

The noise on the sampling of the neurons will not be completely independent, since their inputs are correlated and they are connected to each other either directly or indirectly via other neurons in the network.
As discussed in \autoref{sec:bg-noisecorr}, the presence of correlated noise within a population of neurons is generally thought to hinder the amount of information encoded in the population.
This is certainly the case for a homogeneous population, since the correlated noise will cause neurons with the same tuning response to the stimulus to have the same, or similar, bias for any given sample.
In this case, we could do better by having decorrelated noise, so that the noise from each neuron cancels out when we average the response over the population.
However, for a heterogeneous population, it is possible for noise correlations to increase the amount of information encoded at the population level, if the noise correlations are in direction which helps disambiguate between potential responses \citep{Averbeck2006,Moreno-Bote2014}.

We could compute the amount of information in the vector of simultaneously recorded responses from all our electrode channels from the differential entropy, \autoref{eq:info}, as before.
However, the number of possible response vectors rises exponentially with its dimensionality, and, as discussed in \autoref{sec:info-bias}, the available bias correction techniques will not be able to match this.
Consequently, directly computing the amount of information encoded in such a large response vector will not yield any meaningful results.
Instead, we trained a classification model on the high-dimensional responses.
The performance of the model --- the proportion of samples which it correctly classifies --- provides a lower-bound on the amount of information present in the data \citep{Quiroga2009}.

% COULD PUT EXAMPLE CONFUSION MATRICES HERE?

In line with our findings about task-pertinent information in \autoref{sec:task-info}, we will group together all the contrasts on one side of the \SI{30}{\percent} contrast task separation line.
This means objective function for the classification model we will train on the data will match the objective function which the subject was tasked with during the experiments.


\subsection{Methods for decoding population activity}

Our input to the model is the vector of multi-unit firing rates recorded from each electrode contact over the initial \SI{527}{\milli\second} of test-stimulus presentation.


\subsubsection{Linear discriminant classifier}

To evaluate the amount of information contained in the data, we trained a Fisher linear discriminant classifier to distinguish between the two groups of stimuli.
Given a training dataset of labelled data-points with $m$-dimensions for each training sample, the linear classifier fits an $(m-1)$-dimensional hyperplane to separate the classes of the training samples optimally, under the assumption that the two clusters to be separated are multivariate normal distributions.

The vector normal to the hyperplane is 
\begin{equation}
\vec{w} = \Sigma^{-1}\left(\vec{\mu_1}-\vec{\mu_0}\right)
\end{equation}
where $\Sigma$ is the covariance matrix between the two populations, as determined from the labelled training data, and $\vec{\mu_0}$ and $\vec{\mu_1}$ are the means of the two distributions, for class $0$ (for our data, contrast \SI{<30}{\percent}) and class $1$ (contrast \SI{>30}{\percent}).

After training the model to define a separating hyperplane, test data-points can be classified by inspecting which side of the hyperplane they fall upon.
For a new data point, $\vec{x}$, we classify $\vec{x}$ as group $1$ if
\begin{equation}
\vec{w}\cdot\vec{x}>c
,\end{equation}
otherwise we classify it as the group labelled $0$.

Example linear classifiers are shown in Figures \ref{fig:pl_lin_discrim_example_v1} and \ref{fig:pl_lin_discrim_example_v4}.
Note that for illustrative purposes, these figures show classifiers which were trained using only two recording channels, but for the results discussed later in this section our classifiers were trained on all recording channels.
In these preliminary figures, we can see that the separating plane fit by the linear model does a good job at separating the two classes, given the observed dataset.
After the animal has been trained on the task and the changes due to perceptual learning have saturated, the samples with contrast \SI{<30}{\percent} and \SI{>30}{\percent} are more easily separable.


% For blanco v1, session 343, ch 31 vs 44, training accuracy is 64.212488%
% For blanco v1, session 359, ch 31 vs 44, training accuracy is 73.389950%
% For jack v1, session 51, ch 12 vs 19, training accuracy is 78.521940%
% For jack v1, session 72, ch 12 vs 19, training accuracy is 83.840304%

\begin{figure}[htbp]
    \centering
    %\hspace*{\fill}
    \subfloat[][\ac{M1} \ac{V1}, session \num{1}.\label{fig:pl_lin_discrim_example_v1_blanco_pre}]{%
        \includegraphics[scale=.4]{figs/decoding/lindiscrimexLCH-RG-log_cbl_v1_blanco_343_31vs44.eps}}
    \hspace*{\fill}\hspace{.2cm}\hspace*{\fill}
    \subfloat[][\ac{M2} \ac{V1}, session \num{1}.\label{fig:pl_lin_discrim_example_v1_jack_pre}]{%
        \includegraphics[scale=.4]{figs/decoding/lindiscrimexLCH-RG-log_cbl_v1_jack_51_12vs19.eps}}
    %\hspace*{\fill}
    \\
    %\hspace*{\fill}
    \subfloat[][\ac{M1} \ac{V1}, session \num{17}.\label{fig:pl_lin_discrim_example_v1_blanco_post}]{%
        \includegraphics[scale=.4]{figs/decoding/lindiscrimexLCH-RG-log_cbl_v1_blanco_359_31vs44.eps}}
    \hspace*{\fill}\hspace{.2cm}\hspace*{\fill}
    \subfloat[][\ac{M2} \ac{V1}, session \num{22}.\label{fig:pl_lin_discrim_example_v1_jack_post}]{%
        \includegraphics[scale=.4]{figs/decoding/lindiscrimexLCH-RG-log_cbl_v1_jack_72_12vs19.eps}}
    %\hspace*{\fill}
    \caption{
    \captionemph{Exemplar linear discriminators for pairs of \ac{V1} channels.}
    The number of paired observations of firing rates for two channels is shown on a two-dimensional colour bar scale.
    The hue of each pixel indicates the fraction of observations of the firing rate pair $(x,y)$ which were recorded with a stimulus above or below \SI{30}{\percent} contrast (red: below; green above).
    Lightness and chroma (saturation) indicate the total number of observations of $(x,y)$ using a logarithmic scaling (a doubling of the number of samples results in the same absolute change in lightness and chroma).
    Pairs of firing rates which were never observed to co-occurr are shown in black.
    The separating hyperplane fit by the model is superimposed in white.
    In each case, the model was trained on the data from only two recording channels, for illustrative purposes.
    For each subject, each pair of channels was evaluated and we selected the pair which gave the highest classification performance during the final recording session.
    For \ac{M1} \ac{V1}, this pair of channels permitted \SI{64.2}{\percent} training accuracy for the na\"{i}ve animal and \SI{73.4}{\percent} during the final experimental session, shown in \protect\subref{fig:pl_lin_discrim_example_v1_blanco_pre} and \protect\subref{fig:pl_lin_discrim_example_v1_blanco_post} respectively.
    For \ac{M2} \ac{V1}, this pair of channels permitted \SI{78.5}{\percent} training accuracy for the na\"{i}ve animal and \SI{83.8}{\percent} during the final experimental session, shown in \protect\subref{fig:pl_lin_discrim_example_v1_jack_pre} and \protect\subref{fig:pl_lin_discrim_example_v1_jack_post} respectively.
}
    \label{fig:pl_lin_discrim_example_v1}
\end{figure}


% For blanco v4, session 307, ch 12 vs 51, training accuracy is 65.440000%
% For blanco v4, session 341, ch 12 vs 51, training accuracy is 74.115456%
% For jack v4, session 24, ch 10 vs 53, training accuracy is 54.143019%
% For jack v4, session 48, ch 10 vs 53, training accuracy is 73.445212%

\begin{figure}[htbp]
    \centering
    %\hspace*{\fill}
    \subfloat[][\ac{M1} \ac{V4}, session \num{1}.\label{fig:pl_lin_discrim_example_v4_blanco_pre}]{%
        \includegraphics[scale=.4]{figs/decoding/lindiscrimexLCH-RG-log_cbl_v4_blanco_307_12vs51.eps}}
    \hspace*{\fill}\hspace{.2cm}\hspace*{\fill}
    \subfloat[][\ac{M2} \ac{V4}, session \num{1}.\label{fig:pl_lin_discrim_example_v4_jack_pre}]{%
        \includegraphics[scale=.4]{figs/decoding/lindiscrimexLCH-RG-log_cbl_v4_jack_24_10vs53.eps}}
    %\hspace*{\fill}
    \\
    %\hspace*{\fill}
    \subfloat[][\ac{M1} \ac{V4}, session \num{35}.\label{fig:pl_lin_discrim_example_v4_blanco_post}]{%
        \includegraphics[scale=.4]{figs/decoding/lindiscrimexLCH-RG-log_cbl_v4_blanco_341_12vs51.eps}}
    \hspace*{\fill}\hspace{.2cm}\hspace*{\fill}
    \subfloat[][\ac{M2} \ac{V4}, session \num{25}.\label{fig:pl_lin_discrim_example_v4_jack_post}]{%
        \includegraphics[scale=.4]{figs/decoding/lindiscrimexLCH-RG-log_cbl_v4_jack_48_10vs53.eps}}
    %\hspace*{\fill}
    \caption{
    \captionemph{Exemplar linear discriminators for pairs of \ac{V4} channels.}
    The number of paired observations of firing rates for two channels is shown on a two-dimensional colour bar scale, as per \autoref{fig:pl_lin_discrim_example_v1}.
    The separating hyperplane fit by the model is superimposed in white.
    We selected the pair of channels which provided the highest classifier performance during the final recording session.
    For \ac{M1} \ac{V4}, this pair of channels permitted \SI{65.4}{\percent} training accuracy for the na\"{i}ve animal and \SI{74.1}{\percent} during the final experimental session, shown in \protect\subref{fig:pl_lin_discrim_example_v4_blanco_pre} and \protect\subref{fig:pl_lin_discrim_example_v4_blanco_post} respectively.
    For \ac{M2} \ac{V4}, this pair of channels permitted \SI{54.1}{\percent} training accuracy for the na\"{i}ve animal and  \SI{73.4}{\percent} during the final experimental session, shown in \protect\subref{fig:pl_lin_discrim_example_v4_jack_pre} and \protect\subref{fig:pl_lin_discrim_example_v4_jack_post} respectively.
}
    \label{fig:pl_lin_discrim_example_v4}
\end{figure}


The linear discriminant model was fit using MATLAB's \texttt{classify} function (with type `linear').
We also tested a quadratic model, and using Mahalanobis distances for the discrimination (not shown).
However, neither of these models resulted in better performance than the linear model.

Restricting ourselves to a linear model of the data imposes the assumption that the contrast response tuning curves are monotonic for all neurons under observation.
This is a gross reduction of the space of possible encoding schemes and will prevent many theoretically possible stimulus codes from giving any information about the stimuli.
For instance if the firing rate is \SI{10}{Hz} for \SIrange{0}{20}{\percent} contrast, \SI{30}{Hz} for \SIrange{20}{30}{\percent} contrast, and \SI{20}{Hz} for \SI{>30}{\percent} contrast: this would give considerable task-pertinent information about the stimulus but it is entirely lost when we are restricted to using a linear decoder.
However, in practice our neurons nearly all have monotonically increasing response curves (as discussed in \autoref{sec:pl_response_curves}) and thus making such an imposition on the model does not appear to hinder its performance, as demonstrated by the similarity of performance for linear and quadratic decoder models.


\subsubsection{Performance evaluation}
\label{sec:pl_decoder_evaluation}

To investigate the performance of the classifier on the data from a single session, we used leave-one-out cross-validation.
Under leave-one-out cross-validation, given a dataset with $n$ samples, the decoder is trained on the labelled data from $(n-1)$ samples and we then check whether the decoder classifies the remaining trial correctly.
This is repeated, so that each of the $n$ samples takes a turn at being the singular test sample, and then the performance is defined as the proportion of trials which are identified correctly.

In the machine learning literature, leave-one-out is regarded as a poor method of cross-validation in order to evaluate and compare models against one another.
This is because the models trained in each leave-one-out fold of the data will have almost identical sets of training data.
Consequently each classifier will be almost identical --- with a linear classifier, the learned hyperplane will be almost exactly the same for each test-step --- and the evaluation will not indicate the variance of performance which would be expected across a diversity of sample sets.
Such problems result in suboptimal model selection criteria, however these need not concern us since our task is to most accurately estimate the performance of the model.
For this, leave-one-out has low bias and variance \citep{Zhang2015}, which is most appropriate to us since we are interested in how the data changes over training.

However, we also need to address the change in class balance over training, as described in \autoref{sec:pl_class_imbalance}.
Instead of using the same balanced subsample we randomly selected and used across previous sections, we randomly subsampled the data (such that the same number of each stimulus contrast was included) independently on every fold of the leave-one-out validation.%
\footnote{We also tried training the model using leave-one-out validation without subsampling and our findings were not notably different.}
To ensure the measured performance was robust against changes in the class balance, we determined the classification accuracy for each of the \num{14} stimulus classes and then reported the performance as the average of these \num{14} accuracies.


\subsubsection{Information estimate}
\label{sec:pl_decode_info}

We also computed the amount of information about the target response encoded in the decoded response.
As with the overall model performance measurement, the class balance was corrected \textit{post hoc} by weighting each stimulus class equally while deriving the probability of the response to each stimulus group.
That is to say, the probability of each response given the stimulus was in the lower (or higher) group was set to be equal to the average over all stimuli conditions within the group.
The mutual information between the response and the true label of the group was then derived using \autoref{eq:info}.
Since we only have \num{2} stimulus and \num{2} response conditions, the bias correction routine to account for the finite-sampling is simpler than the full \ac{PT} method.
We estimated the bias using Equation~7 of \citet{Panzeri1996}, which we restate here as
\begin{equation}
\I_\text{bias} = \frac{1}{2 N \ln 2}
,\end{equation}
where $N$ is the total number of samples, under the assumption that each of the \num{4} stimulus-response pairs can occur in practice.
This estimate of the bias was subtracted from our information calculations.


\subsubsection{Shuffling to destroy noise correlations}
\label{sec:pl_dec_shuffle}

We wanted to investigate whether correlations in the noise between the neurons which we recorded helped or hindered the total information across the population.
In order to do this, we first measured the performance of the decoder with the original data recorded simultaneously from each channel, and then measured the performance again using a copy of the data where the responses from each channel were shuffled between trials.
Our shuffling was conditioned on the contrast of the test stimulus, so that responses from each channel still corresponded to the same stimulus (and the stimulus correlations were preserved), but any correlations in the noise of the recorded neurons were destroyed.
We repeated the analysis of decoder performance for \num{20} different shuffles of the data and report the overall average accuracy.
Finally, we compared the average accuracy of the decoders trained on shuffled responses with the decoder trained on the original responses using a paired Student's $t$-test across experimental sessions.

%------------------------------------------------------------------------------
% \subsection{Results}
%
% \autoref{fig:dec_singles} shows how well the decoder does based only on data from individual channels.
% The performance was measured as described in \autoref{sec:dec-meth-lin} for each session, and then averaged over all sessions.
%
% \autoref{fig:dec_nbest} indicates how the performance of the decoder improves as more channels are added.
% We can see that the decoder performance saturates after around 10 channels are included in the training data, but at a perforance which is still far from the ideal.
% After this, including additional channels yields only a slight increase in performance, suggesting nearly all the information contained in the remaining channels is redundant, as it has already been given in the first 10 channels.
% [would be better to look at how the decoding performance is distributed across all possible sets of $n$ channels, rather than just the best set of $n$ channels] [this should be compared with shuffled data to see what the impact is and whether performance does not saturate when correlations are removed as per some previous papers [cite]]
%
% NB: the order in which channels were added in \autoref{fig:dec_nbest} is not the same ordering as they are shown in \autoref{fig:dec_singles}.
%
% \begin{figure}[htbp]
%     \centering
%     \hspace*{\fill}
%     \subfloat[][\label{fig:dec_singles}]{
%         \centering
%         \includegraphics[width=0.47\linewidth]{%
% figs/decoding/2FC_singles.eps}
%     }
%     \hspace*{\fill}\hspace{.2cm}\hspace*{\fill}
%     \subfloat[][\label{fig:dec_nbest}]{
%         \centering
%         \includegraphics[width=0.47\linewidth]{%
% figs/decoding/2FC_nbest_all.eps}
%     }
%     \hspace*{\fill}
%     \caption{
% \protect\subref{fig:dec_singles}: Distribution of decoder performance based on spike rate for individual channels, sorted by performance.
% \protect\subref{fig:dec_nbest}: Decoding performance versus number of channels included in spiking data.
% Channels were added one at a time, chosen so they maximise the decoder performance for that number of channels whilst keeping all the channels which had come before.
% }
%     \label{fig:dec_n}
% \end{figure}
%
% For each of the datasets, the performance decreases as the last \num{3} channels are added (\autoref{fig:dec_nbest}).
% I speculate that this is because these channels only contain redundant information, and the increase in dimensionality decreases the quality of the classifier selected from the finite training data available.


%------------------------------------------------------------------------------
\subsection{Results of decoding population activity}


For \ac{V1}, there is a decline in the performance of the \ac{M1} decoder over time and a small increase in the performance for \ac{M2}, shown in \autoref{fig:dec_all_v1}.
Our results from the population-level decoder correspond to our findings about the information encoded in \SI{527}{\milli\second} activity, taken for individual channels and then averaged across them, depicted in \autoref{fig:info_sess_1x527_final}.

% PERCENTAGE
%
% blanco v1
% Behavioural accuracy from 69.4% 70.9% 73.4% (71.20%) to 88.1% 87.2% 87.1% (87.50%)
% Decoder accuracy     from 75.0% 73.6% 73.4% (73.97%) to 72.0% 67.7% 77.0% (72.21%)
% Shuff decoder accur  from 78.8% 76.8% 75.6% (77.07%) to 70.5% 70.3% 79.7% (73.49%)
% Shuff decoder diff   from 3.8% 3.2% 2.3% (3.1%) to -1.5% 2.6% 2.7% (1.3%)
% n=17  h=1.000000  p=0.000612=6.120856e-04   delta = +1.941965+/-0.457008 = +2.708694%+/-72.363911%
%
% jack v1
% Behavioural accuracy from 66.6% 72.9% 79.2% (72.92%) to 88.5% 88.7% 89.8% (89.00%)
% Decoder accuracy     from 82.5% 83.1% 81.8% (82.48%) to 86.5% 87.7% 87.9% (87.37%)
% Shuff decoder accur  from 88.7% 88.3% 88.1% (88.36%) to 91.7% 91.4% 93.5% (92.18%)
% Shuff decoder diff   from 6.2% 5.1% 6.3% (5.9%) to 5.2% 3.7% 5.6% (4.8%)
% n=22  h=1.000000  p=0.000000=3.703396e-17   delta = +5.488296+/-0.218307 = +6.433440%+/-44.531150%

% INFORMATION
%
% blanco v1
% Behavioural accuracy from 0.110bits 0.133bits 0.164bits (0.1358bits) to 0.474bits 0.451bits 0.445bits (0.4567bits)
% Decoder accuracy     from 0.195bits 0.165bits 0.163bits (0.1742bits) to 0.144bits 0.091bits 0.227bits (0.1544bits)
% Shuff decoder accur  from 0.264bits 0.220bits 0.199bits (0.2278bits) to 0.126bits 0.123bits 0.284bits (0.1774bits)
% Shuff decoder diff   from 0.070bits 0.055bits 0.036bits (0.0535bits) to -0.018bits 0.031bits 0.056bits (0.0230bits)
% n=17  h=1.000000  p=0.000308=3.075496e-04   delta = +0.030706+/-0.006703 bits = +21.284896%+/-4.749643%
%
% jack v1
% Behavioural accuracy from 0.081bits 0.170bits 0.261bits (0.1707bits) to 0.485bits 0.490bits 0.525bits (0.5000bits)
% Decoder accuracy     from 0.337bits 0.347bits 0.317bits (0.3336bits) to 0.432bits 0.466bits 0.473bits (0.4569bits)
% Shuff decoder accur  from 0.492bits 0.480bits 0.476bits (0.4826bits) to 0.591bits 0.582bits 0.664bits (0.6125bits)
% Shuff decoder diff   from 0.155bits 0.133bits 0.159bits (0.1490bits) to 0.160bits 0.116bits 0.191bits (0.1556bits)
% n=22  h=1.000000  p=0.000000=8.568485e-18   delta = +0.160952+/-0.005959 bits = +39.859827%+/-1.858461%

\begin{figure}[htbp]
    \centering
    \hspace*{\fill}
    \subfloat[][\ac{M1} \ac{V1}.\label{fig:dec_b1_allp}]{
        \centering
	\includegraphics[scale=0.45]{figs/decoding/perf_percentage_v1_blanco_leg.eps}
    }
    \hspace*{\fill}\hspace{.2cm}\hspace*{\fill}
    \subfloat[][\ac{M2} \ac{V1}.\label{fig:dec_j1_allp}]{
        \centering
	\includegraphics[scale=0.45]{figs/decoding/perf_percentage_v1_jack.eps}
    }
    \hspace*{\fill}
    \\
    \hspace*{\fill}
    \subfloat[][\ac{M1} \ac{V1}.\label{fig:dec_b1_info}]{
        \centering
	\includegraphics[scale=0.45]{figs/decoding/perf_information_v1_blanco.eps}
    }
    \hspace*{\fill}\hspace{.2cm}\hspace*{\fill}
    \subfloat[][\ac{M2} \ac{V1}.\label{fig:dec_j1_info}]{
        \centering
	\includegraphics[scale=0.45]{figs/decoding/perf_information_v1_jack.eps}
    }
    \hspace*{\fill}
    \caption{
    \captionemph{Classifying the stimulus using \ac{V1} population activity.}
    We report the accuracy of the linear decoder at classifying the group of each stimulus (greater or less than \SI{30}{\percent} contrast) after training on the population activity (blue; \protect\subref{fig:dec_b1_allp}~\ac{M1}, \num{14} channels; \protect\subref{fig:dec_j1_allp}~\ac{M2}, \num{20} channels).
    In \protect\subref{fig:dec_b1_allp} and \protect\subref{fig:dec_j1_allp}, performance was evaluated as the average accuracy across each of the \num{14} stimulus classes (main $y$-axis, left-side).
    A second $y$-axis (right-side) shows the corresponding amount of information about the stimulus group which would be attained if the average accuracy for stimuli lower than \SI{30}{\percent} contrast and the accuracy for stimuli higher than \SI{30}{\percent} contrast were equal.
    We also report the accuracy of the linear decoder when trained on a copy of the data with responses recorded from each channel matched at random such that noise correlations are removed (red; see \autoref{sec:pl_dec_shuffle}).
    For comparison, the behavioural performance of the subject is also shown for each recording session (black).
    In \protect\subref{fig:dec_b1_info} and \protect\subref{fig:dec_j1_info}, we show the information about the stimulus group (higher or lower than \SI{30}{\percent} contrast) contained in the responses from the behaviour and decoders (main $y$-axis, left-side).
    A second $y$-axis (right-side) shows the overall accuracy which would illicit this information (assuming the same accuracy for every stimulus).
}
    \label{fig:dec_all_v1}
\end{figure}

The change in performance of the decoder over time does not correspond to the change in subject's performance in either case.
For \ac{M2} (see \autoref{fig:dec_j1_allp}), the subject's behavioural performance increases rapidly initially for the first few sessions and after that it increases steadily until reaching a plateau after around \num{12} recording sessions, rising from \SI{67}{\percent} accuracy at the beginning to \SI{89}{\percent} accuracy after training.
In comparison, the decoder performance rises from an initial \SI{83}{\percent} accuracy only to \SI{88}{\percent}.
When expressed in terms of information, the increase is larger, from \SI{0.33}{bits} to \SI{0.46}{bits}.
The behavioural performance increases similarly for \ac{M1} (rising from \SI{69}{\percent} to \SI{87}{\percent}, shown in \autoref{fig:dec_b1_allp}), whilst the performance of the decoder declines slightly over time (falling from \SI{74}{\percent} to \SI{72}{\percent}).
As stated previously, we expect this decline in performance is due to a decline in signal quality over time and is not due to a reduction of information encoded within the cortex.

Destroying the noise correlations between the responses from each channel increased the performance of the decoder significantly for both subjects (\ac{M1}: $p=0.0006$; \ac{M2}: $p < 4 \times 10^{-17}$).
However this effect was larger for \ac{M2} (an improvement in performance of \SI{5.4\pm0.2}{\percent}) than \ac{M1} (\SI{+1.9\pm0.5}{\percent}).
Additionally, the effect of removing noise correlations on \ac{M1} declined as experimental training progressed, falling from \SI{3.1}{\percent} to \SI{1.3}{\percent} (average of first and last three sessions respectively).
This corroborates our notion that the decline in information and hence performance for the decoder is due to a gradual degradation of signal quality in the apparatus.
% As the extrinsic, observational noise increases it will dominate over the intrinsic noise within the cortex, and if the noise from the apparatus is generated independently for each recording channel then decorrelating the noise on the signals we observe will become decreasingly useful.
For \ac{M2}, the performance advantage for a decoder trained without noise correlations also fell, but only not as much, decreasing from \SI{5.9}{\percent} to \SI{4.8}{\percent} (average of first and last three sessions).
However, this marginal decrease seems to be due to saturation of the model performance.
The decoder trained on data with noise correlations removed attains \SI{94}{\percent} accuracy by the final session, which leaves little room for improvement, and the difference in the amount of information encoded by the two decoders is stable at \SI{0.15}{bits} through training.

% PERCENTAGE
%
% blanco v4
% Behavioural accuracy from 80.1% 75.7% 79.6% (78.49%) to 84.9% 85.3% 84.4% (84.88%)
% Decoder accuracy     from 78.9% 78.5% 79.4% (78.95%) to 78.7% 80.4% 81.1% (80.09%)
% Shuff decoder accur  from 79.5% 78.5% 80.0% (79.33%) to 81.4% 82.9% 79.6% (81.33%)
% Shuff decoder diff   from 0.6% -0.1% 0.5% (0.4%) to 2.7% 2.5% -1.5% (1.2%)
% n=22  h=1.000000  p=0.000433=4.326213e-04   delta = +1.434306+/-0.343950 = +1.805622%+/-46.846957%
%
% jack v4
% Behavioural accuracy from 56.9% 56.0% 56.8% (56.56%) to 75.4% 80.1% 79.2% (78.23%)
% Decoder accuracy     from 58.9% 56.5% 63.7% (59.71%) to 71.2% 78.0% 75.0% (74.70%)
% Shuff decoder accur  from 61.2% 55.8% 67.8% (61.58%) to 74.9% 83.0% 79.2% (79.03%)
% Shuff decoder diff   from 2.3% -0.8% 4.1% (1.9%) to 3.8% 5.0% 4.2% (4.3%)
% n=24  h=1.000000  p=0.000000=3.786770e-08   delta = +3.224602+/-0.400164 = +4.543608%+/-117.623395%

% INFORMATION
%
% blanco v4
% Behavioural accuracy from 0.281bits 0.199bits 0.274bits (0.2512bits) to 0.387bits 0.399bits 0.376bits (0.3874bits)
% Decoder accuracy     from 0.260bits 0.255bits 0.271bits (0.2618bits) to 0.260bits 0.297bits 0.308bits (0.2883bits)
% Shuff decoder accur  from 0.275bits 0.255bits 0.285bits (0.2717bits) to 0.321bits 0.353bits 0.277bits (0.3170bits)
% Shuff decoder diff   from 0.016bits -0.000bits 0.014bits (0.0100bits) to 0.060bits 0.056bits -0.031bits (0.0286bits)
% n=22  h=1.000000  p=0.000180=1.798737e-04   delta = +0.032967+/-0.007266 bits = +12.035857%+/-2.807251%
%
% jack v4
% Behavioural accuracy from 0.013bits 0.010bits 0.013bits (0.0117bits) to 0.195bits 0.279bits 0.261bits (0.2452bits)
% Decoder accuracy     from 0.022bits 0.012bits 0.055bits (0.0299bits) to 0.133bits 0.244bits 0.191bits (0.1892bits)
% Shuff decoder accur  from 0.037bits 0.009bits 0.096bits (0.0473bits) to 0.190bits 0.357bits 0.269bits (0.2722bits)
% Shuff decoder diff   from 0.014bits -0.003bits 0.041bits (0.0174bits) to 0.057bits 0.114bits 0.079bits (0.0830bits)
% n=24  h=1.000000  p=0.000000=1.163857e-07   delta = +0.055772+/-0.007396 bits = +38.742552%+/-5.306497%

\begin{figure}[htbp]
    \centering
    \hspace*{\fill}
    \subfloat[][\ac{M1} \ac{V4}.\label{fig:dec_b4_allp}]{
        \centering
	\includegraphics[scale=0.45]{figs/decoding/perf_percentage_v4_blanco_leg.eps}
    }
    \hspace*{\fill}\hspace{.2cm}\hspace*{\fill}
    \subfloat[][\ac{M2} \ac{V4}.\label{fig:dec_j4_allp}]{
        \centering
	\includegraphics[scale=0.45]{figs/decoding/perf_percentage_v4_jack.eps}
    }
    \hspace*{\fill}
    \\
    \hspace*{\fill}
    \subfloat[][\ac{M1} \ac{V4}.\label{fig:dec_b4_info}]{
        \centering
	\includegraphics[scale=0.45]{figs/decoding/perf_information_v4_blanco.eps}
    }
    \hspace*{\fill}\hspace{.2cm}\hspace*{\fill}
    \subfloat[][\ac{M2} \ac{V4}.\label{fig:dec_j4_info}]{
        \centering
	\includegraphics[scale=0.45]{figs/decoding/perf_information_v4_jack.eps}
    }
    \hspace*{\fill}
    \caption{%
    \captionemph{Classifying the stimulus group from \ac{V4} population activity.}
    We report the accuracy of the linear decoder classifying the group of each stimulus (greater or less than \SI{30}{\percent} contrast) after training on the population activity (blue; \protect\subref{fig:dec_b4_allp}~\ac{M1}, \num{25} channels; \protect\subref{fig:dec_j4_allp}~\ac{M2}, \num{18} channels).
    For details, see caption \autoref{fig:dec_all_v1}.
}
    \label{fig:dec_all_v4}
\end{figure}

For both subjects, the decoder trained on the \ac{V4} population activity yielded a surprisingly similar level of accuracy as the subject's behavioural responses across all experimental sessions (shown in \autoref{fig:dec_j4_allp}, blue and black lines).
However, for \ac{M1} the decoder performance increased less than the subject's performance --- a negligible increase from \SI{79}{\percent} to \SI{81}{\percent} whilst the subject's responses improved from \SI{79}{\percent} to \SI{85}{\percent} accuracy.
For \ac{M2} the trends with learning were well matched, with the decoder's accuracy increasing from \SI{59}{\percent} to \SI{75}{\percent} whilst the subject's behavioural accuracy increased from \SI{57}{\percent} to \SI{79}{\percent}.

Again, destroying the noise correlations between channels by shuffling the responses across trials improved the accuracy attained with the decoder.
For both subjects the effect was statistically significant ($p=0.0004$ and $p < 4 \times 10^{-8}$, respectively), with a larger difference of \SI{+3.2\pm0.4}{\percent} accuracy for \ac{M2} than for \ac{M1} (\SI{+1.4\pm0.3}{\percent}).
Over time, the advantage for the decoder trained on data with the noise correlations removed increased for both subjects, increasing marginally from \SI{0.4}{\percent} to \SI{1.2}{\percent} for \ac{M1} and more notably for \ac{M2} from \SI{1.9}{\percent} to \SI{4.3}{\percent}.


%------------------------------------------------------------------------------
\subsection{Discussion on decoding population activity}

By training a linear discriminator to classify the stimuli, we investigated the task-pertinent information about the stimulus encoded in the population-level activity.
% We trained the model when also using the firing rate from the full \SI{527}{\milli\second} stimulus presentation period
Our results here corroborated our findings about the amount of information encoded on average in each channel, described in \autoref{sec:pl_initial_final}.

With \ac{V4}, our decoder gives a surprisingly similar performance to the subject's behavioural response.
If the subject is deciding how to respond based solely on the activity in its \ac{V4}, this means the information contained in the neurons of \ac{V4} are highly redundant since the information encoded at the population level must saturate when fewer than \num{30} neurons are considered.
We will test how closely the classifications of the decoder match the behavioural responses given by the subject next, in \autoref{sec:pl_agreement}.

With \ac{V1} \ac{M2}, the performance of the decoder starts high and does not make much improvement over time, whilst the performance of the subject improves to match the accuracy of the decoder.
This means that the information needed to complete the task accurately was present in the primary visual cortex from the start, but the subject needed to rewire higher cortical regions in order to access this information when making its decision about the stimulus.

The performance of the decoder always \textemph{increased} when we removed noise correlations between channels by shuffling the data across trials.
This suggests that noise correlations hinder the ability of the brain to perceive the contrast of the stimulus correctly, and the subject's performance would potentially improve if the visual cortex learnt to decouple the noise for its neurons \citep{Cohen2008}.
However, there was no particular decline in the difference between the decoder trained on the original data and the decoder trained on shuffled data.
The decline in difference with and without noise correlations in \ac{V1} for \ac{M1} is most likely due to a decline in recording signal quality since the accuracy of the model falls over time.
For \ac{M2}, the marginal decrease in difference is most likely due to saturation of the model performance --- the decoder trained on data with noise correlations removed attains \SI{94}{\percent} accuracy by the final session, which leaves little room for improvement, and there was no notable decrease in the difference when we considered the amount of information encoded.
The dataset which shows the largest improvement in decoder accuracy is \ac{M2} \ac{V4}, which also has an \textemph{increase} in the gap between decoders trained without and with noise correlations, so a reduction in noise correlation over time is certainly not the cause for the improved behavioural performance.


%==============================================================================
\section{Agreement between decoder and behavioural responses}
\label{sec:pl_agreement}

Previously, we speculated about the possibility of the subject's responses on each trial being mediated by the activity in \ac{V4}.
Should this hypothesis be correct, the classifications made by a decoder trained on the activity within \ac{V4} should, right or wrong, be the same as the responses given by the subject.
We tested this by evaluating the response coincidence (agreement) between the classifications made by the decoder and the behavioural responses of the subject.

The response coincidence, $\xi$, was defined as the proportion of trials on which the two responses matched.
However, to avoid changes in the response coincidence over time due to changes in the class balance, we measured the response coincidence for each stimulus class individually and then averaged over all the classes to find the overall response coincidence rate.
If we express the behavioural response to a trial $t$ as $y_t$, and the decoder response $x_t$, then the response coincidence is given by
\begin{equation}
\label{eq:agreement}
\xi = \frac{1}{|\SET{C}|} \sum_{c \in \SET{C}} \left( \frac{1}{|\SET{T_c}|} \sum_{t \in \SET{T_c}} \delta(x_t - y_t) \right)
,\end{equation}
where $\SET{C}$ is the set of all stimulus classes, and $\SET{T_c}$ is the set of trials where stimulus $c$ was presented.
This methodology is similar to how the response accuracy was reported in the previous section.


%------------------------------------------------------------------------------
\subsection{Methods for comparing decoding and behavioural responses}
\label{sec:dec-meth-prob}

In order to evaluate whether the response coincidence was significant, we must first construct a \acf{NH} model.
This is important because the expected response coincidence rate is highly dependent on the accuracy of the two classifiers under consideration.
For instance, if the behaviour and decoder are both \SI{50}{\percent} accurate, we na\"ively expect them to agree with each other \SI{50}{\percent} of the time.
But if both are \SI{100}{\percent} accurate, by construction they must agree with each other \SI{100}{\percent} of the time as well.
If we take an intermediate accuracy, the expected rate of agreement between the two classifiers will also be intermediate.
For instance, if both are \SI{75}{\percent} accurate, they will both agree on the correct classification $0.75 \times 0.75 = 0.5625$ of the time and agree on the incorrect classification $0.25 \times 0.25 = 0.0625$, yielding a total expected response coincidence rate of \SI{62.5}{\percent}.

In order to construct our \ac{NH} model, we assumed that the classifications made by the subject's behaviour and our decoder are sampled from a Bernoulli distribution, each with a fixed probability of being correct.
(This assumption was implicitly made in the statements of the previous paragraph.)
More specifically, we used \num{14} Bernoulli distributions, one for each stimulus class, since we know the accuracy for either decoder or behaviour varies depending on the stimulus class.

Let the probability that the behavioural response is correct when a stimulus from class $c$ is presented by $p_c$, and the probability that the decoder trained on the population activity is correct by $q_c$.
It then follows that the expected agreement rate under this \acf{NH} is given by
\begin{equation}
\label{eq:agreement_NH}
\xi_\text{NH} = \frac{1}{|\SET{C}|} \sum_{c \in \SET{C}} \left( p_c \, q_c + (1 - p_c) \, (1 - q_c) \right)
,\end{equation}
where $\SET{C}$ is the set of all stimulus classes, and $|\SET{C}|$ is the number of stimulus classes.
We determined $p_c$ and $q_c$ empirically by measuring the accuracy of the subject's behavioural and decoder responses for each condition.
The expected agreement $\xi_\text{NH}$ was then determined from these values using \autoref{eq:agreement_NH}.

In order to test for significance whether the observed agreement deviated significantly from the \ac{NH}, we used bootstrapping.
For each bootstrap, we generated a synthetic classification from both the behaviour and decoder for every trial of the experiment.
The response for an individual trial was generated by randomly sampling two Bernoulli distributions with probabilities $p_c$ and $q_c$ respectively.
Having generated synthetic responses for every trial, the bootstrapped agreement was found using \autoref{eq:agreement}.
We repeated this for \num{100000} bootstraps, and extracted the 5th percentile of the bootstraps as the one-sided $p < 0.05$ confidence interval.

To evaluate whether the level of agreement was significant at the beginning and the end of the experiment, we took the average response agreement over the first and last three sessions respectively. 
Correspondingly, to find the confidence interval under the \ac{NH}, we averaged the bootstraps also (one bootstrap from each of the sessions at once), then we identified the significance threshold as the 5th percentile over the distribution of \num{100000} bootstrapped average agreement rates.


\subsubsection{Conditional information}

Measuring the response coincidence rate alone is problematic, because the rate at which the decoder and behavioural responses agree with each other trivially increases as their individual accuracies increase.
In \autoref{sec:dec-meth-prob}, we described how to test whether the response coincidence rate is significantly more than expected under a null-hypothesis assuming independent responses conditioned on the class of the stimulus.
An alternative solution to this is to measure the mutual information between the behaviour and decoder responses conditioned on the class of the stimulus.

\begin{figure}[htbp]
\centering
\includegraphics[scale=.5]{figs/venn/conditional-information-diagram.pdf}
\caption{
\captionemph{Venn diagram of the mutual information between three random variables, $X$, $Y$, and $Z$.}
The three black circles represent the entropies of $X$, $Y$, and $Z$ ($\HH(X)$, $\HH(Y)$, and $\HH(Z)$); their total area is the joint uncertainty over all three variables, $\HH(X, Y, Z)$.
The intersection between all three circles (grey) is $\I{X;Y;Z}$, the entropy (or information) mutually shared by all three variables.
The area covered only by a single circle (red, blue, or green regions) represents the entropy unique to a single variable.
Of particular interest to us is the area covered by precisely two circles, which denotes the entropy shared exclusively by two variables, such as the magenta region (and similarly also yellow and cyan).
This is equivalent to the mutual information between two random variables ($X$ and $Y$) conditioned on the simultaneous observation of a third ($Z$), and is given by $\I(X;Y|Z)$ as described in \autoref{eq:conditional-info}.
Similar to \autoref{fig:bg_info_venn}, in this diagram all regions are non-empty and as such all three variables are partially but incompletely redundant.
}
\label{fig:pl_cond_info_venn}
\end{figure}

Conditional mutual information is the expected mutual information between two variables conditioned on a third,
\begin{align}
\I(X;Y|Z)
  &= \E_{z\sim Z} \left[ I(X;Y|Z) \right] \notag
\\&= \EE_{x\sim X, \, y\sim Y, \, z\sim Z} \left[ \log_2 \frac{p(x,y|z)}{p(x|z)p(y|z)} \right] \notag
\\&= \sum_{z \in \SET{Z}} p(z) \sum_{x \in \SET{X}, \, y \in \SET{Y}} p(x,y|z) \, \log_2 \frac{p(x,y|z)}{p(x|z)p(y|z)}
\label{eq:conditional-info}
.\end{align}
This relationship between the three variables and the associated joint entropies is conceptually illustrated in \autoref{fig:pl_cond_info_venn}.
We computed the amount of information about the behavioural response encoded in the decoder classifications, conditioned on the correct response to the stimulus using \autoref{eq:conditional-info}.
The methodology was the same as described in \autoref{sec:pl_decode_info}, but we measured the amount of information about the behavioural response contained in the decoder responses for each of the two stimulus groups and then combined the two values with equal weighting.


\subsection{Results for response agreement rate}

The response coincidence rate and conditional information were not statistically significant at the start or the end of training for \ac{M1} \ac{V1} (\autoref{fig:decag_b1_allp} and \autoref{fig:decag_b1_condinfo}).
The conditional information fell from \SI{0.0065}{bits} above baseline to equal the baseline \ac{NH} after training.
However for \ac{M2}, shown in \autoref{fig:decag_j1_allp} and \autoref{fig:decag_j1_condinfo}, the information about the behaviour conditioned on the stimulus was not initially different from the \ac{NH} and rose to \SI{0.0137}{bits}, which was significantly different from the \ac{NH}.

% PERCENTAGE
%
% blanco v1
% Behaviour/Decoder agreement from 64.9% 65.7% 64.7% (65.1%) to 69.3% 64.6% 74.4% (69.4%)
% Expected agreement          from 63.8% 62.7% 63.7% (63.4%) to 69.9% 66.4% 73.0% (69.8%)
% NH for expected agreement   from 61.5% 66.0% 57.9% (61.8%) to 69.0% 71.2% 74.8% (71.7%)
% Agreement vs expected diff  from 1.2% 3.0% 0.9% (1.7%) to -0.6% -1.8% 1.4% (-0.3%)
% n=17  h=1.000000  p=0.023671=2.367118e-02   delta = +0.866846+/-0.346729 = +1.284861%+/-68.545093%
% Test 0 for agreement in A 65.11% vs 95.00% NH of 65.62%
% Test 0 for agreement in B 69.44% vs 95.00% NH of 71.21%
%
% jack v1
% Behaviour/Decoder agreement from 63.5% 68.4% 73.8% (68.5%) to 84.7% 84.5% 83.4% (84.2%)
% Expected agreement          from 63.5% 68.4% 73.9% (68.6%) to 82.5% 83.2% 83.0% (82.9%)
% NH for expected agreement   from 60.9% 66.0% 66.2% (64.4%) to 84.5% 81.4% 84.7% (83.5%)
% Agreement vs expected diff  from 0.0% -0.0% -0.2% (-0.1%) to 2.2% 1.3% 0.3% (1.3%)
% n=22  h=1.000000  p=0.000028=2.766509e-05   delta = +0.896309+/-0.168188 = +1.130669%+/-108.520777%
% Test 0 for agreement in A 68.54% vs 95.00% NH of 70.03%
% Test 1 for agreement in B 84.20% vs 95.00% NH of 83.81%

% INFORMATION
%
% blanco v1
% Behaviour/Decoder agreement from 0.065bits 0.080bits 0.066bits (0.0703bits) to 0.112bits 0.060bits 0.183bits (0.1185bits)
% Expected agreement          from 0.055bits 0.053bits 0.058bits (0.0551bits) to 0.120bits 0.077bits 0.162bits (0.1196bits)
% NH for expected agreement   from 0.035bits 0.079bits 0.016bits (0.0432bits) to 0.110bits 0.132bits 0.195bits (0.1456bits)
% Agreement vs expected diff  from 0.010bits 0.028bits 0.008bits (0.0152bits) to -0.008bits -0.017bits 0.021bits (-0.0011bits)
% n=17  h=1.000000  p=0.022739=2.273929e-02   delta = +0.009620+/-0.003817 = +10.360743%+/-4.178021%
% Test 0 for agreement in A 0.070bits vs 95.0% NH of 0.076bits
% Test 0 for agreement in A 0.119bits vs 95.0% NH of 0.138bits
%
% jack v1
% Behaviour/Decoder agreement from 0.058bits 0.119bits 0.170bits (0.1154bits) to 0.385bits 0.379bits 0.355bits (0.3728bits)
% Expected agreement          from 0.058bits 0.119bits 0.173bits (0.1166bits) to 0.334bits 0.347bits 0.348bits (0.3428bits)
% NH for expected agreement   from 0.035bits 0.087bits 0.089bits (0.0701bits) to 0.385bits 0.304bits 0.394bits (0.3608bits)
% Agreement vs expected diff  from 0.000bits -0.001bits -0.003bits (-0.0012bits) to 0.051bits 0.031bits 0.007bits (0.0300bits)
% n=22  h=1.000000  p=0.000038=3.824840e-05   delta = +0.019429+/-0.003743 = +6.980632%+/-2.176605%
% Test 0 for agreement in A 0.115bits vs 95.0% NH of 0.135bits
% Test 1 for agreement in A 0.373bits vs 95.0% NH of 0.364bits

% CONDITIONAL INFORMATION
%
% blanco v1
% Behaviour/Decoder agreement from 0.011bits 0.016bits 0.006bits (0.0109bits) to 0.004bits -0.001bits 0.019bits (0.0075bits)
% Expected agreement          from 0.006bits 0.003bits 0.004bits (0.0044bits) to 0.008bits 0.006bits 0.008bits (0.0076bits)
% NH for expected agreement   from 0.000bits 0.017bits -0.005bits (0.0040bits) to 0.018bits 0.002bits 0.018bits (0.0126bits)
% Agreement vs expected diff  from 0.004bits 0.013bits 0.002bits (0.0065bits) to -0.004bits -0.007bits 0.010bits (-0.0001bits)
% n=17  h=1.000000  p=0.033587=3.358707e-02   delta = +0.004083+/-0.001756 = +57.755586%+/-24.846771%
% Test 0 for agreement in A 0.011bits vs 95.0% NH of 0.015bits
% Test 0 for agreement in A 0.008bits vs 95.0% NH of 0.014bits
%
% jack v1
% Behaviour/Decoder agreement from 0.005bits 0.010bits 0.019bits (0.0112bits) to 0.048bits 0.035bits 0.015bits (0.0326bits)
% Expected agreement          from 0.005bits 0.011bits 0.020bits (0.0122bits) to 0.023bits 0.021bits 0.012bits (0.0189bits)
% NH for expected agreement   from -0.001bits 0.017bits 0.002bits (0.0060bits) to 0.035bits 0.003bits 0.027bits (0.0216bits)
% Agreement vs expected diff  from -0.001bits -0.001bits -0.001bits (-0.0009bits) to 0.025bits 0.014bits 0.002bits (0.0137bits)
% n=22  h=1.000000  p=0.000159=1.588718e-04   delta = +0.008618+/-0.001878 = +46.859666%+/-10.211049%
% Test 0 for agreement in A 0.011bits vs 95.0% NH of 0.020bits
% Test 1 for agreement in A 0.033bits vs 95.0% NH of 0.026bits

\begin{figure}[htbp]
    \centering
    \hspace*{\fill}
    \subfloat[][\ac{M1} \ac{V1}.\label{fig:decag_b1_allp}]{
        \centering
	\includegraphics[scale=0.45]{figs/decoding/agree_percentage_v1_blanco.eps}
    }
    \hspace*{\fill}\hspace{.2cm}\hspace*{\fill}
    \subfloat[][\ac{M2} \ac{V1}.\label{fig:decag_j1_allp}]{
        \centering
	\includegraphics[scale=0.45]{figs/decoding/agree_percentage_v1_jack_leg.eps}
    }
    \hspace*{\fill}
    \\
    \hspace*{\fill}
    \subfloat[][\ac{M1} \ac{V1}.\label{fig:decag_b1_condinfo}]{
        \centering
	\includegraphics[scale=0.45]{figs/decoding/agree_conditional-information_v1_blanco.eps}
    }
    \hspace*{\fill}\hspace{.2cm}\hspace*{\fill}
    \subfloat[][\ac{M2} \ac{V1}.\label{fig:decag_j1_condinfo}]{
        \centering
	\includegraphics[scale=0.45]{figs/decoding/agree_conditional-information_v1_jack.eps}
    }
    \hspace*{\fill}
    \caption{
    \captionemph{Response coincidence rate for \ac{V1}.}
    In \protect\subref{fig:decag_b1_allp} and \protect\subref{fig:decag_j1_allp}, the response coincidence rate, $\xi$, is the average probability that the classifications given by the model trained on the population activity will match those given by the subject's behavioural response (main $y$-axis, left-side).
    A second $y$-axis (right-side) shows the corresponding amount of information about the stimulus group which would be attained if the average accuracy for stimuli lower than \SI{30}{\percent} contrast and the accuracy for stimuli higher than \SI{30}{\percent} contrast were equal.
    The shaded region indicates the \SI{95}{\percent} \acf{CI} of the \acf{NH} constructed for each session (see \autoref{sec:dec-meth-prob} for details).
    In \protect\subref{fig:decag_b1_condinfo} and \protect\subref{fig:decag_j1_condinfo}, the amount of information about the behavioural response given by the decoder, conditioned on the correct experimental response to the stimulus.
}
    \label{fig:decag_all_v1}
\end{figure}


For \ac{V4}, there was an increase in agreement between the behaviour and decoder responses during training for both subjects.
With \ac{M1}, the conditional information between the two was not initially significant at \SI{0.0045}{bits} above the expected level, but increased to \SI{0.0190}{bits} which was significant.
For \ac{M2}, the conditional information was significant throughout training and also increased from \SI{0.0072}{bits} to \SI{0.0477}{bits}.


% PERCENTAGE
%
% blanco v4
% Behaviour/Decoder agreement from 73.5% 68.4% 73.1% (71.7%) to 78.9% 77.0% 77.8% (77.9%)
% Expected agreement          from 72.7% 68.8% 71.5% (71.0%) to 75.4% 76.2% 75.7% (75.8%)
% NH for expected agreement   from 71.2% 74.2% 65.4% (70.3%) to 77.9% 73.1% 78.3% (76.4%)
% Agreement vs expected diff  from 0.8% -0.4% 1.6% (0.7%) to 3.4% 0.8% 2.1% (2.1%)
% n=22  h=1.000000  p=0.000001=1.029691e-06   delta = +1.907054+/-0.280921 = +2.583520%+/-40.980324%
% Test 0 for agreement in A 71.67% vs 95.00% NH of 72.38%
% Test 1 for agreement in B 77.88% vs 95.00% NH of 76.92%
%
% jack v4
% Behaviour/Decoder agreement from 57.8% 56.9% 58.1% (57.6%) to 69.1% 78.2% 76.8% (74.7%)
% Expected agreement          from 54.5% 54.6% 55.2% (54.7%) to 64.4% 71.6% 70.8% (69.0%)
% NH for expected agreement   from 51.7% 57.3% 52.0% (53.7%) to 73.7% 68.7% 72.9% (71.8%)
% Agreement vs expected diff  from 3.3% 2.4% 3.0% (2.9%) to 4.7% 6.5% 6.0% (5.7%)
% n=24  h=1.000000  p=0.000000=1.537291e-13   delta = +5.331259+/-0.348748 = +8.290577%+/-106.980638%
% Test 1 for agreement in A 57.61% vs 95.00% NH of 56.28%
% Test 1 for agreement in B 74.69% vs 95.00% NH of 70.21%

% INFORMATION
%
% blanco v4
% Behaviour/Decoder agreement from 0.165bits 0.106bits 0.174bits (0.1482bits) to 0.256bits 0.224bits 0.247bits (0.2422bits)
% Expected agreement          from 0.154bits 0.111bits 0.150bits (0.1381bits) to 0.195bits 0.210bits 0.210bits (0.2046bits)
% NH for expected agreement   from 0.129bits 0.180bits 0.068bits (0.1258bits) to 0.245bits 0.160bits 0.264bits (0.2232bits)
% Agreement vs expected diff  from 0.011bits -0.005bits 0.024bits (0.0101bits) to 0.061bits 0.014bits 0.037bits (0.0376bits)
% n=22  h=1.000000  p=0.000001=9.716119e-07   delta = +0.031480+/-0.004619 = +17.878470%+/-2.692137%
% Test 0 for agreement in A 0.148bits vs 95.0% NH of 0.157bits
% Test 1 for agreement in A 0.242bits vs 95.0% NH of 0.225bits
%
% jack v4
% Behaviour/Decoder agreement from 0.017bits 0.015bits 0.019bits (0.0171bits) to 0.108bits 0.243bits 0.221bits (0.1908bits)
% Expected agreement          from 0.005bits 0.006bits 0.007bits (0.0063bits) to 0.061bits 0.139bits 0.129bits (0.1098bits)
% NH for expected agreement   from -0.000bits 0.017bits 0.000bits (0.0056bits) to 0.174bits 0.099bits 0.164bits (0.1457bits)
% Agreement vs expected diff  from 0.012bits 0.008bits 0.012bits (0.0107bits) to 0.047bits 0.104bits 0.092bits (0.0809bits)
% n=24  h=1.000000  p=0.000000=2.026008e-09   delta = +0.060664+/-0.006391 = +87.388447%+/-9.242726%
% Test 1 for agreement in A 0.017bits vs 95.0% NH of 0.012bits
% Test 1 for agreement in A 0.191bits vs 95.0% NH of 0.125bits

% CONDITIONAL INFORMATION
%
% blanco v4
% Behaviour/Decoder agreement from 0.023bits 0.006bits 0.025bits (0.0181bits) to 0.052bits 0.022bits 0.034bits (0.0360bits)
% Expected agreement          from 0.017bits 0.010bits 0.014bits (0.0136bits) to 0.019bits 0.016bits 0.016bits (0.0170bits)
% NH for expected agreement   from 0.009bits 0.028bits -0.002bits (0.0115bits) to 0.030bits 0.002bits 0.039bits (0.0236bits)
% Agreement vs expected diff  from 0.006bits -0.003bits 0.011bits (0.0045bits) to 0.033bits 0.006bits 0.018bits (0.0190bits)
% n=22  h=1.000000  p=0.000005=4.622595e-06   delta = +0.015945+/-0.002610 = +103.142297%+/-16.884265%
% Test 0 for agreement in A 0.018bits vs 95.0% NH of 0.022bits
% Test 1 for agreement in A 0.036bits vs 95.0% NH of 0.025bits
%
% jack v4
% Behaviour/Decoder agreement from 0.012bits 0.019bits 0.012bits (0.0142bits) to 0.030bits 0.075bits 0.080bits (0.0616bits)
% Expected agreement          from 0.005bits 0.010bits 0.006bits (0.0071bits) to 0.006bits 0.014bits 0.022bits (0.0139bits)
% NH for expected agreement   from -0.001bits 0.017bits 0.002bits (0.0060bits) to 0.029bits 0.009bits 0.039bits (0.0257bits)
% Agreement vs expected diff  from 0.007bits 0.009bits 0.006bits (0.0072bits) to 0.024bits 0.060bits 0.058bits (0.0477bits)
% n=24  h=1.000000  p=0.000000=7.945480e-10   delta = +0.039892+/-0.003997 = +305.858005%+/-30.648611%
% Test 1 for agreement in A 0.014bits vs 95.0% NH of 0.013bits
% Test 1 for agreement in A 0.062bits vs 95.0% NH of 0.021bits

\begin{figure}[htbp]
    \centering
    \hspace*{\fill}
    \subfloat[][\ac{M1} \ac{V4}.\label{fig:decag_b4_allp}]{
        \centering
	\includegraphics[scale=0.45]{figs/decoding/agree_percentage_v4_blanco_leg.eps}
    }
    \hspace*{\fill}\hspace{.2cm}\hspace*{\fill}
    \subfloat[][\ac{M2} \ac{V4}.\label{fig:decag_j4_allp}]{
        \centering
	\includegraphics[scale=0.45]{figs/decoding/agree_percentage_v4_jack.eps}
    }
    \hspace*{\fill}
    \\
    \hspace*{\fill}
    \subfloat[][\ac{M1} \ac{V4}.\label{fig:decag_b4_condinfo}]{
        \centering
	\includegraphics[scale=0.45]{figs/decoding/agree_conditional-information_v4_blanco.eps}
    }
    \hspace*{\fill}\hspace{.2cm}\hspace*{\fill}
    \subfloat[][\ac{M2} \ac{V4}.\label{fig:decag_j4_condinfo}]{
        \centering
	\includegraphics[scale=0.45]{figs/decoding/agree_conditional-information_v4_jack.eps}
    }
    \hspace*{\fill}
    \caption{
    \captionemph{Response coincidence rate for \ac{V4}.}
    Same as \autoref{fig:decag_all_v1}, but for \ac{V4}.
}
    \label{fig:decag_all_v4}
\end{figure}


\subsection{Discussion of response agreement rate}

For all our data except \ac{V1} in \ac{M1}, there was an increase in the amount of information about the behavioural responses contained in the responses of the decoder of \autoref{sec:dec-meth-lin} trained on the firing rate from all simultaneously recorded channels.
Furthermore, this increase was not explained by an increase in performance of the two classifiers.
We controlled for this by conditioning our information calculation on the target response and by comparing with the distribution of samples under a \ac{NH} model of conditional independence.

The increase in response coincidence rate over the course of training could be explained by the higher cortical regions in the subject's brain getting better at interpreting the information encoded in the visual cortex, and hence becoming more reliant on the signals which we recorded to construct our linear classifier.
Alternatively, feedback from the higher cortical regions could increase, causing information about the subject's response to propagate into the visual cortical regions after the decision has been made (but before it is given).
The increase in agreement was larger for \ac{V4} than \ac{V1}.
