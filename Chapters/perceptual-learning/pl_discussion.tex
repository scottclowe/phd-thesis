%------------------------------------------------------------------------------
\section{Discussions}

We now discuss the findings of the analysis described in the previous chapter, and suggest ways in which this work may proceed in the future.

%------------------------------------------------------------------------------
\subsection{Validity of results}

From \autoref{fig:b1-trialwise}--\ref{fig:j4-trialwise}, we can conclude several things about the reliability of our other results.
Firstly, it seems the data for \ac{M2} is more trustworthy than that of \ac{M1}.
Secondly, from the information measured in the spontaneous activity, it seems the results for the spike timing code cannot be trusted, certainly not any changes which seem to occur with learning.
Thirdly, this latter point may call into jeopardy the reliability of the results for the spike count code, since these problems seem to be inherent to the raw data, though the information in the spike count code is more robust due to its fewer possible response vectors.

%------------------------------------------------------------------------------
\subsection{Information in individual neurons}

The analysis has demonstrated there is far more information given by the onset transient response, which is in keeping with previous findings \citep{Muller2001}.

The finding that information increases more rapidly with learning in \ac{V4} than \ac{V1} is in line with our hypothesis made earlier.

The result that the peak in information in \ac{V4} neurons moves to being sooner after stimulus onset (\autoref{fig:j4-1x20tp4}) is an entirely novel finding.
Although the values for the information here are very low --- only \SI{0.02}{bits} --- this is the average over many channels, only a couple of which exhibit the increase with time.
The more responsive channels have information peaking at around \SI{0.65}{bits}, but the non-responsive channels pull this average down.
I have also done some work to identify which channels should be excluded on the basis of their $d'$, but this is not presented here.


% %------------------------------------------------------------------------------
% \subsection{Future Work}
%
% Further work will need to be done on this analysis to try and fix the inconsistencies in data between days so they can be studied together more easily.
% Also, work will need to be done to establish if any of the results presented here are genuinely statistically significant.
%
% Here we describe some follow-up work which could be performed, either by myself or the perceptual learning lab group.
%
% %------------------------------------------------------------------------------
% \subsubsection{Elimination of artifacts from continuous data}
%
% \autoref{fig:mahist-j1s56} shows that the current method of correcting for the monitor artifact is flawed.
% If the monitor artifact were an artifact similar to previously known artifacts, such as the ``reward artifact'' generated by the water dispenser, a large potential is induced in the electrode, which can be registered as a spike since it exceeds the threshold.
% However, this sort of behaviour would not cause a reduction in the number of spikes preceding the artifact incident, as seen here and in many of the sessions for other channels too.
%
% To create the preceding reduction in spikes over a period of around \SI{0.2}{ms}, the measured potential must be reduced, suppressing the spikes which are being elicited so they are not passing threshold and being detected.
% A positive electric potential following this could increase the proportion of spikes meeting threshold, and resulting in the problematic sharp peak in the number of spikes.
% Lending credence to this theory is the way the spikes detected as the monitor artifact have the same waveform as the usual spike, but have an amplitude towards the lower end of what would be expected.
%
% If this is the effect we are witnessing, this can be fixed in a manner similar to the way the monitor artifacts were removed in this paper.
% Instead of considering the spiking data, we will need to look at the continuous data.
% We can take the modulo of the times with respect to the monitor refresh rate again, and bin the data points together with a bin width the reciprocal of the sampling frequency, but instead of taking the number of data points in each bin (which will be the same since there is always a continuous voltage value even if there isn't a spike), we take the mean of the voltages.
% The amount of modification made on each trial to the voltages should then appear as a fluctuation in the mean voltage recorded and can consequently be subtracted from the original data.
%
% %------------------------------------------------------------------------------
% \subsubsection{Normalisation of firing rates}
%
% Combining trials from different sessions in one analysis has problems because the recording quality varies from day to day.
% Can possibly be normalised by adjusting the spike detection threshold so that there is always the same spontaneous activity exceeding the threshold
% This is justifiable because even if neuronal firing rates change greatly due to perceptual learning, homeostasis should keep the spontaneous activity rates relatively consistent.
%
% This will hopefully make the measured information content of the spontaneous activity be consistent throughout training.
% If this is the case, the result will be much more trustworthy results.
% This will be especially important in improving the potential of the results for \ac{M1}, and for the spike-timing code, potentially yielding some more interesting results.
%
% %------------------------------------------------------------------------------
% \subsubsection{Comparison with psychometrics}
%
% An interesting comparison would be to see how the information correlates with the behaviour of the monkey.
% In particular, it is suspected that there might be a correlation between the magnitude of the maximum information available to the animal in \ac{V4} and the performance of the monkey in the task.
% Also, there is reason to suspect there might be a correlation between the latency of the information in \ac{V4} and the response time of the monkey, and I tentatively hypothesise this will be the case.
%
% %------------------------------------------------------------------------------
% \subsubsection{Statistical analysis of significance of results}
%
% It will be very important to clarify the statistical significance, if any, of the results tentatively presented here.
% The statistical significance of mutual information can be estimated by using bootstrapping, which is where the stimuli and response vectors are shuffled and paired together at random \citep{Ince2011}.
% Because some combinations will happen to provide more discriminability than others, the distributed of the mutual information fits a Gaussian distribution with a certain mean and standard deviation.
% By taking the distribution of information with bootstrapping, the mean and variance can be computed, and the actual value of the information from the data can be compared with this to see if its distance above the mean is statistically significant.
%
% Using this method, we can also pick out a value of information which is statistically significant and see how long after test presentation it takes for the information about the test stimulus to become significant.
% This will provide a metric for information latency.
%
% %------------------------------------------------------------------------------
% \subsubsection{Further directions}
%
% There are several different routes down which the project could be more broadly extended.
%
% \begin{itemize}
% \item Analysis of information about the test contrast contained in the \ac{MUA} and \ac{LFP} signals contained in the raw recordings from which the spiking data was extracted.
% \item Analysis of roving task.
%       This could be done by considering the activity during test presentation identifying the trial condition as being dependent on both test and sample contrasts.
%       To see how important the sample stimulus is to the brain activity during the test presentation, we would subtract from this an estimate of the information where condition is changed by keeping the test contrasts the same, but shuffling the sample contrasts.
% \item Information rate in bits per spike \citep{Rolls2011}.
% \item Population wide information, using a decoding approach.
%       There are too many channels to use a direct information theoretic approach \citep{Quiroga2009}.
%       If we were to use information theory directly, even with binary bins for every channel, there are $2^{20}$ possible responses and we would need in excess of 2 million trials per condition to have a reasonable estimate of the information content.
%       The dataset is not large enough for this, and even if it were we would have missed the changes due to perceptual learning as they only occur in the first 20,000 trials.
% \item Examining correlations between neurons.
% \item Investigate whether firing rate for different contrasts becomes more discriminable due to the means becoming more distant or due to the variability in rate for each contrast being reduced.
% \end{itemize}

% 

%------------------------------------------------------------------------------
\subsection{Decoding}
%------------------------------------------------------------------------------

Based on data from \ac{M2} \ac{V4}, one might conclude our results to offer some corroboration with those of \citet{Gu2011}, since we find a decrease in noise correlations and in increase in decoder performance.
However, comparing the performance of the decoder to a decoder based on shuffled data without the noise correlations present suggests that the improvement in decoder performance is not due to the relatively small reduction in noise correlation observed, but is from other sources.

The data from \ac{M2} \ac{V1} does not support a ``reduction in noise correlation'' hypothesis either, and indicates that neural spike rates across the \ac{V1} population recorded from are no more informative after training than they were before.
Together, results from \ac{M2} \ac{V1} and \ac{V4} suggest that information in \ac{V1} is consistent throughout training, but the ability of \ac{V4} to read out the information in \ac{V1} improves over the same period, leading to an improvement in behavioural performance.

However, these findings are not supported by the data from \ac{M1}.

% In addition to this, the increase in reponse agreement between our rate-based decoder and the animal's behavioural responses for \ac{M2} \ac{V4} (\autoref{fig:dec_j4_alla}) indicates the monkey is increasingly relying on the activity from the channels which were recorded from in \ac{V4} in order to make its decisions about the presented stimulus contrast.

For both animals, from the data from \ac{V4} we find there is a statistically significant level of agreement between decoded and behavioural trial-to-trial responses after training but not before, which shows the neural activity in \ac{V4} and the behavioural responses are correlated.
This implies that the monkey becomes dependent on the activity of the population of neurons for which the recordings are representative.
That the agreement is better without shuffling could be taken to mean the neural correlations are important in the determination of the animal's response, however shuffling does by its very nature destroy the correspondence between the trials given to the decoder and those experienced by the animal.

%------------------------------------------------------------------------------
\subsection{Summary}
%------------------------------------------------------------------------------

The project has expanded on existing literature and demonstrated that the millisecond-level timing of spikes from individual neurons, both in \ac{V1} and \ac{V4}, is not important for contrast discrimination tasks, but the firing rate is important.
It has also been demonstrated that little information regarding the discrimination between similar contrasts can be gained from the spiking activity of individual neurons, even during/after perceptual learning has occurred.
In \ac{V1}, there is no discernible change in contrast information in individual neurons at all, but in \ac{V4} there is an increase with perceptual learning in the magnitude of the peak information after stimulus onset, and the peak occurs sooner after stimulus onset as well.

However, the analysis indicates the quality of the results is good for one monkey (\ac{M2}), but not so good for the other (\ac{M1}).
The discrepancy between the two datasets needs further investigation, and the conclusions made here need to be validated against other studies.
